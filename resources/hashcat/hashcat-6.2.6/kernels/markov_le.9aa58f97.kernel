//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Unknown Toolkit Version
// Based on NVVM 7.0.1
//

.version 9.0
.target sm_86, texmode_independent
.address_size 64

	// .globl	l_markov

.entry l_markov(
	.param .u64 .ptr .global .align 4 l_markov_param_0,
	.param .u64 .ptr .global .align 4 l_markov_param_1,
	.param .u64 .ptr .global .align 4 l_markov_param_2,
	.param .u64 l_markov_param_3,
	.param .u32 l_markov_param_4,
	.param .u32 l_markov_param_5,
	.param .u32 l_markov_param_6,
	.param .u32 l_markov_param_7,
	.param .u32 l_markov_param_8,
	.param .u64 l_markov_param_9
)
{
	.local .align 4 .b8 	__local_depot0[260];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .b32 	%r<126>;
	.reg .b64 	%rd<129>;


	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd57, [l_markov_param_0];
	ld.param.u64 	%rd58, [l_markov_param_1];
	ld.param.u64 	%rd59, [l_markov_param_2];
	ld.param.u64 	%rd60, [l_markov_param_3];
	ld.param.u32 	%r24, [l_markov_param_4];
	ld.param.u32 	%r124, [l_markov_param_5];
	ld.param.u32 	%r26, [l_markov_param_6];
	ld.param.u32 	%r27, [l_markov_param_7];
	ld.param.u32 	%r28, [l_markov_param_8];
	ld.param.u64 	%rd61, [l_markov_param_9];
	add.u64 	%rd127, %SPL, 0;
	mov.u32 	%r29, %ctaid.x;
	mov.u32 	%r30, %ntid.x;
	mov.u32 	%r31, %tid.x;
	mov.b32 	%r32, %envreg3;
	add.s32 	%r33, %r31, %r32;
	mad.lo.s32 	%r34, %r30, %r29, %r33;
	cvt.s64.s32 	%rd2, %r34;
	setp.ge.u64 	%p1, %rd2, %rd61;
	@%p1 bra 	$L__BB0_29;

	mov.u32 	%r35, 0;
	st.local.u32 	[%rd127], %r35;
	st.local.u32 	[%rd127+4], %r35;
	st.local.u32 	[%rd127+8], %r35;
	st.local.u32 	[%rd127+12], %r35;
	st.local.u32 	[%rd127+16], %r35;
	st.local.u32 	[%rd127+20], %r35;
	st.local.u32 	[%rd127+24], %r35;
	st.local.u32 	[%rd127+28], %r35;
	st.local.u32 	[%rd127+32], %r35;
	st.local.u32 	[%rd127+36], %r35;
	st.local.u32 	[%rd127+40], %r35;
	st.local.u32 	[%rd127+44], %r35;
	st.local.u32 	[%rd127+48], %r35;
	st.local.u32 	[%rd127+52], %r35;
	st.local.u32 	[%rd127+56], %r35;
	st.local.u32 	[%rd127+60], %r35;
	st.local.u32 	[%rd127+64], %r35;
	st.local.u32 	[%rd127+68], %r35;
	st.local.u32 	[%rd127+72], %r35;
	st.local.u32 	[%rd127+76], %r35;
	st.local.u32 	[%rd127+80], %r35;
	st.local.u32 	[%rd127+84], %r35;
	st.local.u32 	[%rd127+88], %r35;
	st.local.u32 	[%rd127+92], %r35;
	st.local.u32 	[%rd127+96], %r35;
	st.local.u32 	[%rd127+100], %r35;
	st.local.u32 	[%rd127+104], %r35;
	st.local.u32 	[%rd127+108], %r35;
	st.local.u32 	[%rd127+112], %r35;
	st.local.u32 	[%rd127+116], %r35;
	st.local.u32 	[%rd127+120], %r35;
	st.local.u32 	[%rd127+124], %r35;
	st.local.u32 	[%rd127+128], %r35;
	st.local.u32 	[%rd127+132], %r35;
	st.local.u32 	[%rd127+136], %r35;
	st.local.u32 	[%rd127+140], %r35;
	st.local.u32 	[%rd127+144], %r35;
	st.local.u32 	[%rd127+148], %r35;
	st.local.u32 	[%rd127+152], %r35;
	st.local.u32 	[%rd127+156], %r35;
	st.local.u32 	[%rd127+160], %r35;
	st.local.u32 	[%rd127+164], %r35;
	st.local.u32 	[%rd127+168], %r35;
	st.local.u32 	[%rd127+172], %r35;
	st.local.u32 	[%rd127+176], %r35;
	st.local.u32 	[%rd127+180], %r35;
	st.local.u32 	[%rd127+184], %r35;
	st.local.u32 	[%rd127+188], %r35;
	st.local.u32 	[%rd127+192], %r35;
	st.local.u32 	[%rd127+196], %r35;
	st.local.u32 	[%rd127+200], %r35;
	st.local.u32 	[%rd127+204], %r35;
	st.local.u32 	[%rd127+208], %r35;
	st.local.u32 	[%rd127+212], %r35;
	st.local.u32 	[%rd127+216], %r35;
	st.local.u32 	[%rd127+220], %r35;
	st.local.u32 	[%rd127+224], %r35;
	st.local.u32 	[%rd127+228], %r35;
	st.local.u32 	[%rd127+232], %r35;
	st.local.u32 	[%rd127+236], %r35;
	st.local.u32 	[%rd127+240], %r35;
	st.local.u32 	[%rd127+244], %r35;
	st.local.u32 	[%rd127+248], %r35;
	st.local.u32 	[%rd127+252], %r35;
	add.s32 	%r1, %r124, %r24;
	st.local.u32 	[%rd127+256], %r1;
	add.s64 	%rd112, %rd2, %rd60;
	setp.eq.s32 	%p2, %r24, 0;
	@%p2 bra 	$L__BB0_23;

	mul.wide.u32 	%rd63, %r124, 1028;
	add.s64 	%rd121, %rd58, %rd63;
	add.s32 	%r37, %r24, -1;
	and.b32  	%r123, %r24, 3;
	setp.lt.u32 	%p3, %r37, 3;
	@%p3 bra 	$L__BB0_17;

	sub.s32 	%r118, %r24, %r123;
	shl.b32 	%r38, %r124, 3;
	and.b32  	%r4, %r38, 24;
	add.s32 	%r39, %r38, 8;
	and.b32  	%r5, %r39, 24;
	xor.b32  	%r6, %r4, 16;
	add.s32 	%r40, %r38, -8;
	and.b32  	%r7, %r40, 24;

$L__BB0_4:
	ld.global.u32 	%rd8, [%rd121+1024];
	and.b64  	%rd64, %rd112, -4294967296;
	setp.eq.s64 	%p4, %rd64, 0;
	@%p4 bra 	$L__BB0_6;

	div.u64 	%rd113, %rd112, %rd8;
	mul.lo.s64 	%rd65, %rd113, %rd8;
	sub.s64 	%rd114, %rd112, %rd65;
	bra.uni 	$L__BB0_7;

$L__BB0_6:
	cvt.u32.u64 	%r41, %rd8;
	cvt.u32.u64 	%r42, %rd112;
	div.u32 	%r43, %r42, %r41;
	mul.lo.s32 	%r44, %r43, %r41;
	sub.s32 	%r45, %r42, %r44;
	cvt.u64.u32 	%rd113, %r43;
	cvt.u64.u32 	%rd114, %r45;

$L__BB0_7:
	shl.b64 	%rd66, %rd114, 2;
	add.s64 	%rd67, %rd121, %rd66;
	ld.global.u32 	%r46, [%rd67];
	shl.b32 	%r47, %r46, %r4;
	and.b32  	%r48, %r124, -4;
	cvt.u64.u32 	%rd68, %r48;
	add.s64 	%rd69, %rd127, %rd68;
	ld.local.u32 	%r49, [%rd69];
	or.b32  	%r50, %r49, %r47;
	st.local.u32 	[%rd69], %r50;
	shl.b32 	%r51, %r124, 8;
	add.s32 	%r52, %r46, %r51;
	cvt.u64.u32 	%rd15, %r52;
	mul.wide.u32 	%rd70, %r52, 1028;
	add.s64 	%rd71, %rd59, %rd70;
	ld.global.u32 	%rd16, [%rd71+1024];
	and.b64  	%rd72, %rd113, -4294967296;
	setp.eq.s64 	%p5, %rd72, 0;
	@%p5 bra 	$L__BB0_9;

	div.u64 	%rd115, %rd113, %rd16;
	mul.lo.s64 	%rd73, %rd115, %rd16;
	sub.s64 	%rd116, %rd113, %rd73;
	bra.uni 	$L__BB0_10;

$L__BB0_9:
	cvt.u32.u64 	%r53, %rd16;
	cvt.u32.u64 	%r54, %rd113;
	div.u32 	%r55, %r54, %r53;
	mul.lo.s32 	%r56, %r55, %r53;
	sub.s32 	%r57, %r54, %r56;
	cvt.u64.u32 	%rd115, %r55;
	cvt.u64.u32 	%rd116, %r57;

$L__BB0_10:
	add.s32 	%r58, %r124, 1;
	mul.lo.s64 	%rd74, %rd15, 1028;
	add.s64 	%rd75, %rd59, %rd74;
	shl.b64 	%rd76, %rd116, 2;
	add.s64 	%rd77, %rd75, %rd76;
	ld.global.u32 	%r59, [%rd77];
	shl.b32 	%r60, %r59, %r5;
	and.b32  	%r61, %r58, -4;
	cvt.u64.u32 	%rd78, %r61;
	add.s64 	%rd79, %rd127, %rd78;
	ld.local.u32 	%r62, [%rd79];
	or.b32  	%r63, %r62, %r60;
	st.local.u32 	[%rd79], %r63;
	shl.b32 	%r64, %r58, 8;
	add.s32 	%r65, %r59, %r64;
	cvt.u64.u32 	%rd23, %r65;
	mul.wide.u32 	%rd80, %r65, 1028;
	add.s64 	%rd81, %rd59, %rd80;
	ld.global.u32 	%rd24, [%rd81+1024];
	and.b64  	%rd82, %rd115, -4294967296;
	setp.eq.s64 	%p6, %rd82, 0;
	@%p6 bra 	$L__BB0_12;

	div.u64 	%rd117, %rd115, %rd24;
	mul.lo.s64 	%rd83, %rd117, %rd24;
	sub.s64 	%rd118, %rd115, %rd83;
	bra.uni 	$L__BB0_13;

$L__BB0_12:
	cvt.u32.u64 	%r66, %rd24;
	cvt.u32.u64 	%r67, %rd115;
	div.u32 	%r68, %r67, %r66;
	mul.lo.s32 	%r69, %r68, %r66;
	sub.s32 	%r70, %r67, %r69;
	cvt.u64.u32 	%rd117, %r68;
	cvt.u64.u32 	%rd118, %r70;

$L__BB0_13:
	add.s32 	%r71, %r124, 2;
	mul.lo.s64 	%rd84, %rd23, 1028;
	add.s64 	%rd85, %rd59, %rd84;
	shl.b64 	%rd86, %rd118, 2;
	add.s64 	%rd87, %rd85, %rd86;
	ld.global.u32 	%r72, [%rd87];
	shl.b32 	%r73, %r72, %r6;
	and.b32  	%r74, %r71, -4;
	cvt.u64.u32 	%rd88, %r74;
	add.s64 	%rd89, %rd127, %rd88;
	ld.local.u32 	%r75, [%rd89];
	or.b32  	%r76, %r75, %r73;
	st.local.u32 	[%rd89], %r76;
	shl.b32 	%r77, %r71, 8;
	add.s32 	%r78, %r72, %r77;
	cvt.u64.u32 	%rd31, %r78;
	mul.wide.u32 	%rd90, %r78, 1028;
	add.s64 	%rd91, %rd59, %rd90;
	ld.global.u32 	%rd32, [%rd91+1024];
	and.b64  	%rd92, %rd117, -4294967296;
	setp.eq.s64 	%p7, %rd92, 0;
	@%p7 bra 	$L__BB0_15;

	div.u64 	%rd112, %rd117, %rd32;
	mul.lo.s64 	%rd93, %rd112, %rd32;
	sub.s64 	%rd120, %rd117, %rd93;
	bra.uni 	$L__BB0_16;

$L__BB0_15:
	cvt.u32.u64 	%r79, %rd32;
	cvt.u32.u64 	%r80, %rd117;
	div.u32 	%r81, %r80, %r79;
	mul.lo.s32 	%r82, %r81, %r79;
	sub.s32 	%r83, %r80, %r82;
	cvt.u64.u32 	%rd112, %r81;
	cvt.u64.u32 	%rd120, %r83;

$L__BB0_16:
	add.s32 	%r84, %r124, 3;
	mul.lo.s64 	%rd94, %rd31, 1028;
	add.s64 	%rd95, %rd59, %rd94;
	shl.b64 	%rd96, %rd120, 2;
	add.s64 	%rd97, %rd95, %rd96;
	ld.global.u32 	%r85, [%rd97];
	shl.b32 	%r86, %r85, %r7;
	and.b32  	%r87, %r84, -4;
	cvt.u64.u32 	%rd98, %r87;
	add.s64 	%rd99, %rd127, %rd98;
	ld.local.u32 	%r88, [%rd99];
	or.b32  	%r89, %r88, %r86;
	st.local.u32 	[%rd99], %r89;
	shl.b32 	%r90, %r84, 8;
	add.s32 	%r91, %r85, %r90;
	mul.wide.u32 	%rd100, %r91, 1028;
	add.s64 	%rd121, %rd59, %rd100;
	add.s32 	%r124, %r124, 4;
	add.s32 	%r118, %r118, -4;
	setp.ne.s32 	%p8, %r118, 0;
	@%p8 bra 	$L__BB0_4;

$L__BB0_17:
	setp.eq.s32 	%p9, %r123, 0;
	@%p9 bra 	$L__BB0_23;

	shl.b32 	%r121, %r124, 8;

$L__BB0_19:
	.pragma "nounroll";
	ld.global.u32 	%rd44, [%rd121+1024];
	and.b64  	%rd101, %rd112, -4294967296;
	setp.eq.s64 	%p10, %rd101, 0;
	@%p10 bra 	$L__BB0_21;

	div.u64 	%rd45, %rd112, %rd44;
	mul.lo.s64 	%rd102, %rd45, %rd44;
	sub.s64 	%rd126, %rd112, %rd102;
	mov.u64 	%rd112, %rd45;
	bra.uni 	$L__BB0_22;

$L__BB0_21:
	cvt.u32.u64 	%r92, %rd44;
	cvt.u32.u64 	%r93, %rd112;
	div.u32 	%r94, %r93, %r92;
	mul.lo.s32 	%r95, %r94, %r92;
	sub.s32 	%r96, %r93, %r95;
	cvt.u64.u32 	%rd112, %r94;
	cvt.u64.u32 	%rd126, %r96;

$L__BB0_22:
	shl.b32 	%r97, %r124, 3;
	and.b32  	%r98, %r97, 24;
	shl.b64 	%rd103, %rd126, 2;
	add.s64 	%rd104, %rd121, %rd103;
	ld.global.u32 	%r99, [%rd104];
	shl.b32 	%r100, %r99, %r98;
	and.b32  	%r101, %r124, -4;
	cvt.u64.u32 	%rd105, %r101;
	add.s64 	%rd106, %rd127, %rd105;
	ld.local.u32 	%r102, [%rd106];
	or.b32  	%r103, %r102, %r100;
	st.local.u32 	[%rd106], %r103;
	add.s32 	%r104, %r121, %r99;
	mul.wide.u32 	%rd107, %r104, 1028;
	add.s64 	%rd121, %rd59, %rd107;
	add.s32 	%r124, %r124, 1;
	add.s32 	%r121, %r121, 256;
	add.s32 	%r123, %r123, -1;
	setp.ne.s32 	%p11, %r123, 0;
	@%p11 bra 	$L__BB0_19;

$L__BB0_23:
	shl.b32 	%r105, %r124, 3;
	and.b32  	%r106, %r105, 24;
	mov.u32 	%r107, 255;
	shl.b32 	%r108, %r107, %r106;
	and.b32  	%r109, %r108, %r26;
	and.b32  	%r110, %r124, -4;
	cvt.u64.u32 	%rd108, %r110;
	add.s64 	%rd109, %rd127, %rd108;
	ld.local.u32 	%r111, [%rd109];
	or.b32  	%r112, %r111, %r109;
	st.local.u32 	[%rd109], %r112;
	setp.eq.s32 	%p12, %r27, 0;
	@%p12 bra 	$L__BB0_25;

	shl.b32 	%r113, %r1, 3;
	st.local.u32 	[%rd127+56], %r113;

$L__BB0_25:
	setp.eq.s32 	%p13, %r28, 0;
	@%p13 bra 	$L__BB0_27;

	shl.b32 	%r114, %r1, 3;
	st.local.u32 	[%rd127+60], %r114;

$L__BB0_27:
	mul.lo.s64 	%rd110, %rd2, 260;
	add.s64 	%rd128, %rd57, %rd110;
	mov.u32 	%r125, 0;

$L__BB0_28:
	ld.local.u32 	%r116, [%rd127];
	st.global.u32 	[%rd128], %r116;
	add.s64 	%rd128, %rd128, 4;
	add.s64 	%rd127, %rd127, 4;
	add.s32 	%r125, %r125, 1;
	setp.lt.u32 	%p14, %r125, 65;
	@%p14 bra 	$L__BB0_28;

$L__BB0_29:
	ret;

}
	// .globl	r_markov
.entry r_markov(
	.param .u64 .ptr .global .align 4 r_markov_param_0,
	.param .u64 .ptr .global .align 4 r_markov_param_1,
	.param .u64 .ptr .global .align 4 r_markov_param_2,
	.param .u64 r_markov_param_3,
	.param .u32 r_markov_param_4,
	.param .u32 r_markov_param_5,
	.param .u32 r_markov_param_6,
	.param .u32 r_markov_param_7,
	.param .u64 r_markov_param_8
)
{
	.local .align 4 .b8 	__local_depot1[260];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<12>;
	.reg .b32 	%r<98>;
	.reg .b64 	%rd<120>;


	mov.u64 	%SPL, __local_depot1;
	ld.param.u64 	%rd50, [r_markov_param_0];
	ld.param.u64 	%rd114, [r_markov_param_1];
	ld.param.u64 	%rd52, [r_markov_param_2];
	ld.param.u64 	%rd53, [r_markov_param_3];
	ld.param.u32 	%r17, [r_markov_param_4];
	ld.param.u64 	%rd54, [r_markov_param_8];
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %ntid.x;
	mov.u32 	%r20, %tid.x;
	mov.b32 	%r21, %envreg3;
	add.s32 	%r22, %r20, %r21;
	mad.lo.s32 	%r23, %r19, %r18, %r22;
	cvt.s64.s32 	%rd2, %r23;
	setp.ge.u64 	%p1, %rd2, %rd54;
	@%p1 bra 	$L__BB1_24;

	mov.u32 	%r94, 0;
	st.local.u32 	[%rd1], %r94;
	st.local.u32 	[%rd1+4], %r94;
	st.local.u32 	[%rd1+8], %r94;
	st.local.u32 	[%rd1+12], %r94;
	st.local.u32 	[%rd1+16], %r94;
	st.local.u32 	[%rd1+20], %r94;
	st.local.u32 	[%rd1+24], %r94;
	st.local.u32 	[%rd1+28], %r94;
	st.local.u32 	[%rd1+32], %r94;
	st.local.u32 	[%rd1+36], %r94;
	st.local.u32 	[%rd1+40], %r94;
	st.local.u32 	[%rd1+44], %r94;
	st.local.u32 	[%rd1+48], %r94;
	st.local.u32 	[%rd1+52], %r94;
	st.local.u32 	[%rd1+56], %r94;
	st.local.u32 	[%rd1+60], %r94;
	st.local.u32 	[%rd1+64], %r94;
	st.local.u32 	[%rd1+68], %r94;
	st.local.u32 	[%rd1+72], %r94;
	st.local.u32 	[%rd1+76], %r94;
	st.local.u32 	[%rd1+80], %r94;
	st.local.u32 	[%rd1+84], %r94;
	st.local.u32 	[%rd1+88], %r94;
	st.local.u32 	[%rd1+92], %r94;
	st.local.u32 	[%rd1+96], %r94;
	st.local.u32 	[%rd1+100], %r94;
	st.local.u32 	[%rd1+104], %r94;
	st.local.u32 	[%rd1+108], %r94;
	st.local.u32 	[%rd1+112], %r94;
	st.local.u32 	[%rd1+116], %r94;
	st.local.u32 	[%rd1+120], %r94;
	st.local.u32 	[%rd1+124], %r94;
	st.local.u32 	[%rd1+128], %r94;
	st.local.u32 	[%rd1+132], %r94;
	st.local.u32 	[%rd1+136], %r94;
	st.local.u32 	[%rd1+140], %r94;
	st.local.u32 	[%rd1+144], %r94;
	st.local.u32 	[%rd1+148], %r94;
	st.local.u32 	[%rd1+152], %r94;
	st.local.u32 	[%rd1+156], %r94;
	st.local.u32 	[%rd1+160], %r94;
	st.local.u32 	[%rd1+164], %r94;
	st.local.u32 	[%rd1+168], %r94;
	st.local.u32 	[%rd1+172], %r94;
	st.local.u32 	[%rd1+176], %r94;
	st.local.u32 	[%rd1+180], %r94;
	st.local.u32 	[%rd1+184], %r94;
	st.local.u32 	[%rd1+188], %r94;
	st.local.u32 	[%rd1+192], %r94;
	st.local.u32 	[%rd1+196], %r94;
	st.local.u32 	[%rd1+200], %r94;
	st.local.u32 	[%rd1+204], %r94;
	st.local.u32 	[%rd1+208], %r94;
	st.local.u32 	[%rd1+212], %r94;
	st.local.u32 	[%rd1+216], %r94;
	st.local.u32 	[%rd1+220], %r94;
	st.local.u32 	[%rd1+224], %r94;
	st.local.u32 	[%rd1+228], %r94;
	st.local.u32 	[%rd1+232], %r94;
	st.local.u32 	[%rd1+236], %r94;
	st.local.u32 	[%rd1+240], %r94;
	st.local.u32 	[%rd1+244], %r94;
	st.local.u32 	[%rd1+248], %r94;
	st.local.u32 	[%rd1+252], %r94;
	add.s64 	%rd105, %rd2, %rd53;
	setp.eq.s32 	%p2, %r17, 0;
	@%p2 bra 	$L__BB1_23;

	add.s32 	%r26, %r17, -1;
	and.b32  	%r97, %r17, 3;
	setp.lt.u32 	%p3, %r26, 3;
	@%p3 bra 	$L__BB1_17;

	sub.s32 	%r93, %r17, %r97;
	mov.u32 	%r91, 0;
	mov.u32 	%r94, %r91;

$L__BB1_4:
	ld.global.u32 	%rd6, [%rd114+1024];
	and.b64  	%rd56, %rd105, -4294967296;
	setp.eq.s64 	%p4, %rd56, 0;
	@%p4 bra 	$L__BB1_6;

	div.u64 	%rd106, %rd105, %rd6;
	mul.lo.s64 	%rd57, %rd106, %rd6;
	sub.s64 	%rd107, %rd105, %rd57;
	bra.uni 	$L__BB1_7;

$L__BB1_6:
	cvt.u32.u64 	%r29, %rd6;
	cvt.u32.u64 	%r30, %rd105;
	div.u32 	%r31, %r30, %r29;
	mul.lo.s32 	%r32, %r31, %r29;
	sub.s32 	%r33, %r30, %r32;
	cvt.u64.u32 	%rd106, %r31;
	cvt.u64.u32 	%rd107, %r33;

$L__BB1_7:
	cvt.u64.u32 	%rd58, %r94;
	add.s64 	%rd59, %rd1, %rd58;
	ld.local.u32 	%r34, [%rd59];
	shl.b64 	%rd60, %rd107, 2;
	add.s64 	%rd61, %rd114, %rd60;
	ld.global.u32 	%r35, [%rd61];
	or.b32  	%r36, %r34, %r35;
	st.local.u32 	[%rd59], %r36;
	add.s32 	%r37, %r91, %r35;
	cvt.u64.u32 	%rd13, %r37;
	mul.wide.u32 	%rd62, %r37, 1028;
	add.s64 	%rd63, %rd52, %rd62;
	ld.global.u32 	%rd14, [%rd63+1024];
	and.b64  	%rd64, %rd106, -4294967296;
	setp.eq.s64 	%p5, %rd64, 0;
	@%p5 bra 	$L__BB1_9;

	div.u64 	%rd108, %rd106, %rd14;
	mul.lo.s64 	%rd65, %rd108, %rd14;
	sub.s64 	%rd109, %rd106, %rd65;
	bra.uni 	$L__BB1_10;

$L__BB1_9:
	cvt.u32.u64 	%r38, %rd14;
	cvt.u32.u64 	%r39, %rd106;
	div.u32 	%r40, %r39, %r38;
	mul.lo.s32 	%r41, %r40, %r38;
	sub.s32 	%r42, %r39, %r41;
	cvt.u64.u32 	%rd108, %r40;
	cvt.u64.u32 	%rd109, %r42;

$L__BB1_10:
	mul.lo.s64 	%rd66, %rd13, 1028;
	add.s64 	%rd67, %rd52, %rd66;
	shl.b64 	%rd68, %rd109, 2;
	add.s64 	%rd69, %rd67, %rd68;
	ld.global.u32 	%r43, [%rd69];
	shl.b32 	%r44, %r43, 8;
	add.s32 	%r45, %r94, 1;
	and.b32  	%r46, %r45, -4;
	cvt.u64.u32 	%rd70, %r46;
	add.s64 	%rd71, %rd1, %rd70;
	ld.local.u32 	%r47, [%rd71];
	or.b32  	%r48, %r47, %r44;
	st.local.u32 	[%rd71], %r48;
	add.s32 	%r49, %r91, %r43;
	add.s32 	%r50, %r49, 256;
	cvt.u64.u32 	%rd21, %r50;
	mul.wide.u32 	%rd72, %r50, 1028;
	add.s64 	%rd73, %rd52, %rd72;
	ld.global.u32 	%rd22, [%rd73+1024];
	and.b64  	%rd74, %rd108, -4294967296;
	setp.eq.s64 	%p6, %rd74, 0;
	@%p6 bra 	$L__BB1_12;

	div.u64 	%rd110, %rd108, %rd22;
	mul.lo.s64 	%rd75, %rd110, %rd22;
	sub.s64 	%rd111, %rd108, %rd75;
	bra.uni 	$L__BB1_13;

$L__BB1_12:
	cvt.u32.u64 	%r51, %rd22;
	cvt.u32.u64 	%r52, %rd108;
	div.u32 	%r53, %r52, %r51;
	mul.lo.s32 	%r54, %r53, %r51;
	sub.s32 	%r55, %r52, %r54;
	cvt.u64.u32 	%rd110, %r53;
	cvt.u64.u32 	%rd111, %r55;

$L__BB1_13:
	mul.lo.s64 	%rd76, %rd21, 1028;
	add.s64 	%rd77, %rd52, %rd76;
	shl.b64 	%rd78, %rd111, 2;
	add.s64 	%rd79, %rd77, %rd78;
	ld.global.u32 	%r56, [%rd79];
	shl.b32 	%r57, %r56, 16;
	add.s32 	%r58, %r94, 2;
	and.b32  	%r59, %r58, -4;
	cvt.u64.u32 	%rd80, %r59;
	add.s64 	%rd81, %rd1, %rd80;
	ld.local.u32 	%r60, [%rd81];
	or.b32  	%r61, %r60, %r57;
	st.local.u32 	[%rd81], %r61;
	add.s32 	%r62, %r91, %r56;
	add.s32 	%r63, %r62, 512;
	cvt.u64.u32 	%rd29, %r63;
	mul.wide.u32 	%rd82, %r63, 1028;
	add.s64 	%rd83, %rd52, %rd82;
	ld.global.u32 	%rd30, [%rd83+1024];
	and.b64  	%rd84, %rd110, -4294967296;
	setp.eq.s64 	%p7, %rd84, 0;
	@%p7 bra 	$L__BB1_15;

	div.u64 	%rd105, %rd110, %rd30;
	mul.lo.s64 	%rd85, %rd105, %rd30;
	sub.s64 	%rd113, %rd110, %rd85;
	bra.uni 	$L__BB1_16;

$L__BB1_15:
	cvt.u32.u64 	%r64, %rd30;
	cvt.u32.u64 	%r65, %rd110;
	div.u32 	%r66, %r65, %r64;
	mul.lo.s32 	%r67, %r66, %r64;
	sub.s32 	%r68, %r65, %r67;
	cvt.u64.u32 	%rd105, %r66;
	cvt.u64.u32 	%rd113, %r68;

$L__BB1_16:
	mul.lo.s64 	%rd86, %rd29, 1028;
	add.s64 	%rd87, %rd52, %rd86;
	shl.b64 	%rd88, %rd113, 2;
	add.s64 	%rd89, %rd87, %rd88;
	ld.global.u32 	%r69, [%rd89];
	shl.b32 	%r70, %r69, 24;
	add.s32 	%r71, %r94, 3;
	and.b32  	%r72, %r71, -4;
	cvt.u64.u32 	%rd90, %r72;
	add.s64 	%rd91, %rd1, %rd90;
	ld.local.u32 	%r73, [%rd91];
	or.b32  	%r74, %r73, %r70;
	st.local.u32 	[%rd91], %r74;
	add.s32 	%r75, %r91, %r69;
	add.s32 	%r76, %r75, 768;
	mul.wide.u32 	%rd92, %r76, 1028;
	add.s64 	%rd114, %rd52, %rd92;
	add.s32 	%r94, %r94, 4;
	add.s32 	%r91, %r91, 1024;
	add.s32 	%r93, %r93, -4;
	setp.ne.s32 	%p8, %r93, 0;
	@%p8 bra 	$L__BB1_4;

$L__BB1_17:
	setp.eq.s32 	%p9, %r97, 0;
	@%p9 bra 	$L__BB1_23;

	shl.b32 	%r95, %r94, 8;

$L__BB1_19:
	.pragma "nounroll";
	ld.global.u32 	%rd42, [%rd114+1024];
	and.b64  	%rd93, %rd105, -4294967296;
	setp.eq.s64 	%p10, %rd93, 0;
	@%p10 bra 	$L__BB1_21;

	div.u64 	%rd43, %rd105, %rd42;
	mul.lo.s64 	%rd94, %rd43, %rd42;
	sub.s64 	%rd119, %rd105, %rd94;
	mov.u64 	%rd105, %rd43;
	bra.uni 	$L__BB1_22;

$L__BB1_21:
	cvt.u32.u64 	%r77, %rd42;
	cvt.u32.u64 	%r78, %rd105;
	div.u32 	%r79, %r78, %r77;
	mul.lo.s32 	%r80, %r79, %r77;
	sub.s32 	%r81, %r78, %r80;
	cvt.u64.u32 	%rd105, %r79;
	cvt.u64.u32 	%rd119, %r81;

$L__BB1_22:
	shl.b32 	%r82, %r94, 3;
	and.b32  	%r83, %r82, 24;
	shl.b64 	%rd95, %rd119, 2;
	add.s64 	%rd96, %rd114, %rd95;
	ld.global.u32 	%r84, [%rd96];
	shl.b32 	%r85, %r84, %r83;
	and.b32  	%r86, %r94, -4;
	cvt.u64.u32 	%rd97, %r86;
	add.s64 	%rd98, %rd1, %rd97;
	ld.local.u32 	%r87, [%rd98];
	or.b32  	%r88, %r87, %r85;
	st.local.u32 	[%rd98], %r88;
	add.s32 	%r89, %r95, %r84;
	mul.wide.u32 	%rd99, %r89, 1028;
	add.s64 	%rd114, %rd52, %rd99;
	add.s32 	%r94, %r94, 1;
	add.s32 	%r95, %r95, 256;
	add.s32 	%r97, %r97, -1;
	setp.ne.s32 	%p11, %r97, 0;
	@%p11 bra 	$L__BB1_19;

$L__BB1_23:
	ld.local.u32 	%r90, [%rd1];
	shl.b64 	%rd102, %rd2, 2;
	add.s64 	%rd103, %rd50, %rd102;
	st.global.u32 	[%rd103], %r90;

$L__BB1_24:
	ret;

}
	// .globl	C_markov
.entry C_markov(
	.param .u64 .ptr .global .align 4 C_markov_param_0,
	.param .u64 .ptr .global .align 4 C_markov_param_1,
	.param .u64 .ptr .global .align 4 C_markov_param_2,
	.param .u64 C_markov_param_3,
	.param .u32 C_markov_param_4,
	.param .u32 C_markov_param_5,
	.param .u32 C_markov_param_6,
	.param .u32 C_markov_param_7,
	.param .u64 C_markov_param_8
)
{
	.local .align 4 .b8 	__local_depot2[260];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .b32 	%r<122>;
	.reg .b64 	%rd<130>;


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd55, [C_markov_param_0];
	ld.param.u64 	%rd122, [C_markov_param_1];
	ld.param.u64 	%rd57, [C_markov_param_2];
	ld.param.u64 	%rd58, [C_markov_param_3];
	ld.param.u32 	%r21, [C_markov_param_4];
	ld.param.u32 	%r22, [C_markov_param_5];
	ld.param.u32 	%r23, [C_markov_param_6];
	ld.param.u32 	%r24, [C_markov_param_7];
	ld.param.u64 	%rd59, [C_markov_param_8];
	add.u64 	%rd60, %SP, 0;
	add.u64 	%rd128, %SPL, 0;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r26, %ntid.x;
	mov.u32 	%r27, %tid.x;
	mov.b32 	%r28, %envreg3;
	add.s32 	%r29, %r27, %r28;
	mad.lo.s32 	%r30, %r26, %r25, %r29;
	cvt.s64.s32 	%rd2, %r30;
	setp.ge.u64 	%p1, %rd2, %rd59;
	@%p1 bra 	$L__BB2_29;

	mov.u32 	%r120, 0;
	st.local.u32 	[%rd128], %r120;
	st.local.u32 	[%rd128+4], %r120;
	st.local.u32 	[%rd128+8], %r120;
	st.local.u32 	[%rd128+12], %r120;
	st.local.u32 	[%rd128+16], %r120;
	st.local.u32 	[%rd128+20], %r120;
	st.local.u32 	[%rd128+24], %r120;
	st.local.u32 	[%rd128+28], %r120;
	st.local.u32 	[%rd128+32], %r120;
	st.local.u32 	[%rd128+36], %r120;
	st.local.u32 	[%rd128+40], %r120;
	st.local.u32 	[%rd128+44], %r120;
	st.local.u32 	[%rd128+48], %r120;
	st.local.u32 	[%rd128+52], %r120;
	st.local.u32 	[%rd128+56], %r120;
	st.local.u32 	[%rd128+60], %r120;
	st.local.u32 	[%rd128+64], %r120;
	st.local.u32 	[%rd128+68], %r120;
	st.local.u32 	[%rd128+72], %r120;
	st.local.u32 	[%rd128+76], %r120;
	st.local.u32 	[%rd128+80], %r120;
	st.local.u32 	[%rd128+84], %r120;
	st.local.u32 	[%rd128+88], %r120;
	st.local.u32 	[%rd128+92], %r120;
	st.local.u32 	[%rd128+96], %r120;
	st.local.u32 	[%rd128+100], %r120;
	st.local.u32 	[%rd128+104], %r120;
	st.local.u32 	[%rd128+108], %r120;
	st.local.u32 	[%rd128+112], %r120;
	st.local.u32 	[%rd128+116], %r120;
	st.local.u32 	[%rd128+120], %r120;
	st.local.u32 	[%rd128+124], %r120;
	st.local.u32 	[%rd128+128], %r120;
	st.local.u32 	[%rd128+132], %r120;
	st.local.u32 	[%rd128+136], %r120;
	st.local.u32 	[%rd128+140], %r120;
	st.local.u32 	[%rd128+144], %r120;
	st.local.u32 	[%rd128+148], %r120;
	st.local.u32 	[%rd128+152], %r120;
	st.local.u32 	[%rd128+156], %r120;
	st.local.u32 	[%rd128+160], %r120;
	st.local.u32 	[%rd128+164], %r120;
	st.local.u32 	[%rd128+168], %r120;
	st.local.u32 	[%rd128+172], %r120;
	st.local.u32 	[%rd128+176], %r120;
	st.local.u32 	[%rd128+180], %r120;
	st.local.u32 	[%rd128+184], %r120;
	st.local.u32 	[%rd128+188], %r120;
	st.local.u32 	[%rd128+192], %r120;
	st.local.u32 	[%rd128+196], %r120;
	st.local.u32 	[%rd128+200], %r120;
	st.local.u32 	[%rd128+204], %r120;
	st.local.u32 	[%rd128+208], %r120;
	st.local.u32 	[%rd128+212], %r120;
	st.local.u32 	[%rd128+216], %r120;
	st.local.u32 	[%rd128+220], %r120;
	st.local.u32 	[%rd128+224], %r120;
	st.local.u32 	[%rd128+228], %r120;
	st.local.u32 	[%rd128+232], %r120;
	st.local.u32 	[%rd128+236], %r120;
	st.local.u32 	[%rd128+240], %r120;
	st.local.u32 	[%rd128+244], %r120;
	st.local.u32 	[%rd128+248], %r120;
	st.local.u32 	[%rd128+252], %r120;
	st.local.u32 	[%rd128+256], %r21;
	add.s64 	%rd113, %rd2, %rd58;
	setp.eq.s32 	%p2, %r21, 0;
	@%p2 bra 	$L__BB2_23;

	add.s32 	%r34, %r21, -1;
	setp.lt.u32 	%p3, %r34, 3;
	mov.u32 	%r120, 0;
	@%p3 bra 	$L__BB2_17;

	and.b32  	%r37, %r21, 3;
	sub.s32 	%r114, %r21, %r37;
	mov.u32 	%r112, 0;
	mov.u32 	%r120, %r112;

$L__BB2_4:
	ld.global.u32 	%rd6, [%rd122+1024];
	and.b64  	%rd61, %rd113, -4294967296;
	setp.eq.s64 	%p4, %rd61, 0;
	@%p4 bra 	$L__BB2_6;

	div.u64 	%rd114, %rd113, %rd6;
	mul.lo.s64 	%rd62, %rd114, %rd6;
	sub.s64 	%rd115, %rd113, %rd62;
	bra.uni 	$L__BB2_7;

$L__BB2_6:
	cvt.u32.u64 	%r38, %rd6;
	cvt.u32.u64 	%r39, %rd113;
	div.u32 	%r40, %r39, %r38;
	mul.lo.s32 	%r41, %r40, %r38;
	sub.s32 	%r42, %r39, %r41;
	cvt.u64.u32 	%rd114, %r40;
	cvt.u64.u32 	%rd115, %r42;

$L__BB2_7:
	cvt.u64.u32 	%rd63, %r120;
	add.s64 	%rd64, %rd128, %rd63;
	ld.local.u32 	%r43, [%rd64];
	shl.b64 	%rd65, %rd115, 2;
	add.s64 	%rd66, %rd122, %rd65;
	ld.global.u32 	%r44, [%rd66];
	or.b32  	%r45, %r43, %r44;
	st.local.u32 	[%rd64], %r45;
	add.s32 	%r46, %r112, %r44;
	cvt.u64.u32 	%rd13, %r46;
	mul.wide.u32 	%rd67, %r46, 1028;
	add.s64 	%rd68, %rd57, %rd67;
	ld.global.u32 	%rd14, [%rd68+1024];
	and.b64  	%rd69, %rd114, -4294967296;
	setp.eq.s64 	%p5, %rd69, 0;
	@%p5 bra 	$L__BB2_9;

	div.u64 	%rd116, %rd114, %rd14;
	mul.lo.s64 	%rd70, %rd116, %rd14;
	sub.s64 	%rd117, %rd114, %rd70;
	bra.uni 	$L__BB2_10;

$L__BB2_9:
	cvt.u32.u64 	%r47, %rd14;
	cvt.u32.u64 	%r48, %rd114;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd116, %r49;
	cvt.u64.u32 	%rd117, %r51;

$L__BB2_10:
	mul.lo.s64 	%rd71, %rd13, 1028;
	add.s64 	%rd72, %rd57, %rd71;
	shl.b64 	%rd73, %rd117, 2;
	add.s64 	%rd74, %rd72, %rd73;
	ld.global.u32 	%r52, [%rd74];
	shl.b32 	%r53, %r52, 8;
	add.s32 	%r54, %r120, 1;
	and.b32  	%r55, %r54, -4;
	cvt.u64.u32 	%rd75, %r55;
	add.s64 	%rd76, %rd128, %rd75;
	ld.local.u32 	%r56, [%rd76];
	or.b32  	%r57, %r56, %r53;
	st.local.u32 	[%rd76], %r57;
	add.s32 	%r58, %r112, %r52;
	add.s32 	%r59, %r58, 256;
	cvt.u64.u32 	%rd21, %r59;
	mul.wide.u32 	%rd77, %r59, 1028;
	add.s64 	%rd78, %rd57, %rd77;
	ld.global.u32 	%rd22, [%rd78+1024];
	and.b64  	%rd79, %rd116, -4294967296;
	setp.eq.s64 	%p6, %rd79, 0;
	@%p6 bra 	$L__BB2_12;

	div.u64 	%rd118, %rd116, %rd22;
	mul.lo.s64 	%rd80, %rd118, %rd22;
	sub.s64 	%rd119, %rd116, %rd80;
	bra.uni 	$L__BB2_13;

$L__BB2_12:
	cvt.u32.u64 	%r60, %rd22;
	cvt.u32.u64 	%r61, %rd116;
	div.u32 	%r62, %r61, %r60;
	mul.lo.s32 	%r63, %r62, %r60;
	sub.s32 	%r64, %r61, %r63;
	cvt.u64.u32 	%rd118, %r62;
	cvt.u64.u32 	%rd119, %r64;

$L__BB2_13:
	mul.lo.s64 	%rd81, %rd21, 1028;
	add.s64 	%rd82, %rd57, %rd81;
	shl.b64 	%rd83, %rd119, 2;
	add.s64 	%rd84, %rd82, %rd83;
	ld.global.u32 	%r65, [%rd84];
	shl.b32 	%r66, %r65, 16;
	add.s32 	%r67, %r120, 2;
	and.b32  	%r68, %r67, -4;
	cvt.u64.u32 	%rd85, %r68;
	add.s64 	%rd86, %rd128, %rd85;
	ld.local.u32 	%r69, [%rd86];
	or.b32  	%r70, %r69, %r66;
	st.local.u32 	[%rd86], %r70;
	add.s32 	%r71, %r112, %r65;
	add.s32 	%r72, %r71, 512;
	cvt.u64.u32 	%rd29, %r72;
	mul.wide.u32 	%rd87, %r72, 1028;
	add.s64 	%rd88, %rd57, %rd87;
	ld.global.u32 	%rd30, [%rd88+1024];
	and.b64  	%rd89, %rd118, -4294967296;
	setp.eq.s64 	%p7, %rd89, 0;
	@%p7 bra 	$L__BB2_15;

	div.u64 	%rd113, %rd118, %rd30;
	mul.lo.s64 	%rd90, %rd113, %rd30;
	sub.s64 	%rd121, %rd118, %rd90;
	bra.uni 	$L__BB2_16;

$L__BB2_15:
	cvt.u32.u64 	%r73, %rd30;
	cvt.u32.u64 	%r74, %rd118;
	div.u32 	%r75, %r74, %r73;
	mul.lo.s32 	%r76, %r75, %r73;
	sub.s32 	%r77, %r74, %r76;
	cvt.u64.u32 	%rd113, %r75;
	cvt.u64.u32 	%rd121, %r77;

$L__BB2_16:
	mul.lo.s64 	%rd91, %rd29, 1028;
	add.s64 	%rd92, %rd57, %rd91;
	shl.b64 	%rd93, %rd121, 2;
	add.s64 	%rd94, %rd92, %rd93;
	ld.global.u32 	%r78, [%rd94];
	shl.b32 	%r79, %r78, 24;
	add.s32 	%r80, %r120, 3;
	and.b32  	%r81, %r80, -4;
	cvt.u64.u32 	%rd95, %r81;
	add.s64 	%rd96, %rd128, %rd95;
	ld.local.u32 	%r82, [%rd96];
	or.b32  	%r83, %r82, %r79;
	st.local.u32 	[%rd96], %r83;
	add.s32 	%r84, %r112, %r78;
	add.s32 	%r85, %r84, 768;
	mul.wide.u32 	%rd97, %r85, 1028;
	add.s64 	%rd122, %rd57, %rd97;
	add.s32 	%r120, %r120, 4;
	add.s32 	%r112, %r112, 1024;
	add.s32 	%r114, %r114, -4;
	setp.ne.s32 	%p8, %r114, 0;
	@%p8 bra 	$L__BB2_4;

$L__BB2_17:
	and.b32  	%r119, %r21, 3;
	setp.eq.s32 	%p9, %r119, 0;
	@%p9 bra 	$L__BB2_23;

	shl.b32 	%r117, %r120, 8;

$L__BB2_19:
	.pragma "nounroll";
	ld.global.u32 	%rd42, [%rd122+1024];
	and.b64  	%rd98, %rd113, -4294967296;
	setp.eq.s64 	%p10, %rd98, 0;
	@%p10 bra 	$L__BB2_21;

	div.u64 	%rd43, %rd113, %rd42;
	mul.lo.s64 	%rd99, %rd43, %rd42;
	sub.s64 	%rd127, %rd113, %rd99;
	mov.u64 	%rd113, %rd43;
	bra.uni 	$L__BB2_22;

$L__BB2_21:
	cvt.u32.u64 	%r87, %rd42;
	cvt.u32.u64 	%r88, %rd113;
	div.u32 	%r89, %r88, %r87;
	mul.lo.s32 	%r90, %r89, %r87;
	sub.s32 	%r91, %r88, %r90;
	cvt.u64.u32 	%rd113, %r89;
	cvt.u64.u32 	%rd127, %r91;

$L__BB2_22:
	shl.b32 	%r92, %r120, 3;
	and.b32  	%r93, %r92, 24;
	shl.b64 	%rd100, %rd127, 2;
	add.s64 	%rd101, %rd122, %rd100;
	ld.global.u32 	%r94, [%rd101];
	shl.b32 	%r95, %r94, %r93;
	and.b32  	%r96, %r120, -4;
	cvt.u64.u32 	%rd102, %r96;
	add.s64 	%rd103, %rd128, %rd102;
	ld.local.u32 	%r97, [%rd103];
	or.b32  	%r98, %r97, %r95;
	st.local.u32 	[%rd103], %r98;
	add.s32 	%r99, %r117, %r94;
	mul.wide.u32 	%rd104, %r99, 1028;
	add.s64 	%rd122, %rd57, %rd104;
	add.s32 	%r120, %r120, 1;
	add.s32 	%r117, %r117, 256;
	add.s32 	%r119, %r119, -1;
	setp.ne.s32 	%p11, %r119, 0;
	@%p11 bra 	$L__BB2_19;

$L__BB2_23:
	shl.b32 	%r100, %r120, 3;
	and.b32  	%r101, %r100, 24;
	mov.u32 	%r102, 255;
	shl.b32 	%r103, %r102, %r101;
	and.b32  	%r104, %r103, %r22;
	and.b32  	%r105, %r120, -4;
	cvt.u64.u32 	%rd105, %r105;
	add.s64 	%rd106, %rd128, %rd105;
	ld.local.u32 	%r106, [%rd106];
	or.b32  	%r107, %r106, %r104;
	st.local.u32 	[%rd106], %r107;
	setp.eq.s32 	%p12, %r23, 0;
	@%p12 bra 	$L__BB2_25;

	shl.b32 	%r108, %r21, 3;
	cvta.to.local.u64 	%rd108, %rd60;
	st.local.u32 	[%rd108+56], %r108;

$L__BB2_25:
	setp.eq.s32 	%p13, %r24, 0;
	@%p13 bra 	$L__BB2_27;

	shl.b32 	%r109, %r21, 3;
	cvta.to.local.u64 	%rd110, %rd60;
	st.local.u32 	[%rd110+60], %r109;

$L__BB2_27:
	mul.lo.s64 	%rd111, %rd2, 260;
	add.s64 	%rd129, %rd55, %rd111;
	mov.u32 	%r121, 0;

$L__BB2_28:
	ld.local.u32 	%r111, [%rd128];
	st.global.u32 	[%rd129], %r111;
	add.s64 	%rd129, %rd129, 4;
	add.s64 	%rd128, %rd128, 4;
	add.s32 	%r121, %r121, 1;
	setp.lt.u32 	%p14, %r121, 65;
	@%p14 bra 	$L__BB2_28;

$L__BB2_29:
	ret;

}

  