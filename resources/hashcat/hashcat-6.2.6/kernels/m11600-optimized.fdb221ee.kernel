//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Unknown Toolkit Version
// Based on NVVM 7.0.1
//

.version 9.0
.target sm_86, texmode_independent
.address_size 64

	// .globl	m11600_init
.const .align 4 .b8 k_sha256[256] = {152, 47, 138, 66, 145, 68, 55, 113, 207, 251, 192, 181, 165, 219, 181, 233, 91, 194, 86, 57, 241, 17, 241, 89, 164, 130, 63, 146, 213, 94, 28, 171, 152, 170, 7, 216, 1, 91, 131, 18, 190, 133, 49, 36, 195, 125, 12, 85, 116, 93, 190, 114, 254, 177, 222, 128, 167, 6, 220, 155, 116, 241, 155, 193, 193, 105, 155, 228, 134, 71, 190, 239, 198, 157, 193, 15, 204, 161, 12, 36, 111, 44, 233, 45, 170, 132, 116, 74, 220, 169, 176, 92, 218, 136, 249, 118, 82, 81, 62, 152, 109, 198, 49, 168, 200, 39, 3, 176, 199, 127, 89, 191, 243, 11, 224, 198, 71, 145, 167, 213, 81, 99, 202, 6, 103, 41, 41, 20, 133, 10, 183, 39, 56, 33, 27, 46, 252, 109, 44, 77, 19, 13, 56, 83, 84, 115, 10, 101, 187, 10, 106, 118, 46, 201, 194, 129, 133, 44, 114, 146, 161, 232, 191, 162, 75, 102, 26, 168, 112, 139, 75, 194, 163, 81, 108, 199, 25, 232, 146, 209, 36, 6, 153, 214, 133, 53, 14, 244, 112, 160, 106, 16, 22, 193, 164, 25, 8, 108, 55, 30, 76, 119, 72, 39, 181, 188, 176, 52, 179, 12, 28, 57, 74, 170, 216, 78, 79, 202, 156, 91, 243, 111, 46, 104, 238, 130, 143, 116, 111, 99, 165, 120, 20, 120, 200, 132, 8, 2, 199, 140, 250, 255, 190, 144, 235, 108, 80, 164, 247, 163, 249, 190, 242, 120, 113, 198};

.entry m11600_init(
	.param .u64 .ptr .global .align 4 m11600_init_param_0,
	.param .u64 .ptr .global .align 4 m11600_init_param_1,
	.param .u64 .ptr .global .align 4 m11600_init_param_2,
	.param .u64 .ptr .const .align 4 m11600_init_param_3,
	.param .u64 .ptr .global .align 4 m11600_init_param_4,
	.param .u64 .ptr .global .align 4 m11600_init_param_5,
	.param .u64 .ptr .global .align 4 m11600_init_param_6,
	.param .u64 .ptr .global .align 4 m11600_init_param_7,
	.param .u64 .ptr .global .align 4 m11600_init_param_8,
	.param .u64 .ptr .global .align 4 m11600_init_param_9,
	.param .u64 .ptr .global .align 4 m11600_init_param_10,
	.param .u64 .ptr .global .align 4 m11600_init_param_11,
	.param .u64 .ptr .global .align 4 m11600_init_param_12,
	.param .u64 .ptr .global .align 4 m11600_init_param_13,
	.param .u64 .ptr .global .align 8 m11600_init_param_14,
	.param .u64 .ptr .global .align 4 m11600_init_param_15,
	.param .u64 .ptr .global .align 4 m11600_init_param_16,
	.param .u64 .ptr .global .align 4 m11600_init_param_17,
	.param .u64 .ptr .global .align 1 m11600_init_param_18,
	.param .u64 .ptr .global .align 4 m11600_init_param_19,
	.param .u64 .ptr .global .align 1 m11600_init_param_20,
	.param .u64 .ptr .global .align 1 m11600_init_param_21,
	.param .u64 .ptr .global .align 1 m11600_init_param_22,
	.param .u64 .ptr .global .align 1 m11600_init_param_23,
	.param .u64 .ptr .global .align 8 m11600_init_param_24
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd2, [m11600_init_param_4];
	ld.param.u64 	%rd3, [m11600_init_param_24];
	mov.b32 	%r1, %envreg3;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r4, %r1;
	mad.lo.s32 	%r6, %r3, %r2, %r5;
	cvt.s64.s32 	%rd1, %r6;
	ld.global.u64 	%rd4, [%rd3+56];
	setp.le.u64 	%p1, %rd4, %rd1;
	@%p1 bra 	$L__BB0_2;

	mul.lo.s64 	%rd5, %rd1, 100;
	add.s64 	%rd6, %rd2, %rd5;
	mov.u32 	%r7, 1779033703;
	st.global.u32 	[%rd6], %r7;
	mov.u32 	%r8, -1150833019;
	st.global.u32 	[%rd6+4], %r8;
	mov.u32 	%r9, 1013904242;
	st.global.u32 	[%rd6+8], %r9;
	mov.u32 	%r10, -1521486534;
	st.global.u32 	[%rd6+12], %r10;
	mov.u32 	%r11, 1359893119;
	st.global.u32 	[%rd6+16], %r11;
	mov.u32 	%r12, -1694144372;
	st.global.u32 	[%rd6+20], %r12;
	mov.u32 	%r13, 528734635;
	st.global.u32 	[%rd6+24], %r13;
	mov.u32 	%r14, 1541459225;
	st.global.u32 	[%rd6+28], %r14;
	mov.u32 	%r15, 0;
	st.global.u32 	[%rd6+96], %r15;

$L__BB0_2:
	ret;

}
	// .globl	m11600_loop
.entry m11600_loop(
	.param .u64 .ptr .global .align 4 m11600_loop_param_0,
	.param .u64 .ptr .global .align 4 m11600_loop_param_1,
	.param .u64 .ptr .global .align 4 m11600_loop_param_2,
	.param .u64 .ptr .const .align 4 m11600_loop_param_3,
	.param .u64 .ptr .global .align 4 m11600_loop_param_4,
	.param .u64 .ptr .global .align 4 m11600_loop_param_5,
	.param .u64 .ptr .global .align 4 m11600_loop_param_6,
	.param .u64 .ptr .global .align 4 m11600_loop_param_7,
	.param .u64 .ptr .global .align 4 m11600_loop_param_8,
	.param .u64 .ptr .global .align 4 m11600_loop_param_9,
	.param .u64 .ptr .global .align 4 m11600_loop_param_10,
	.param .u64 .ptr .global .align 4 m11600_loop_param_11,
	.param .u64 .ptr .global .align 4 m11600_loop_param_12,
	.param .u64 .ptr .global .align 4 m11600_loop_param_13,
	.param .u64 .ptr .global .align 8 m11600_loop_param_14,
	.param .u64 .ptr .global .align 4 m11600_loop_param_15,
	.param .u64 .ptr .global .align 4 m11600_loop_param_16,
	.param .u64 .ptr .global .align 4 m11600_loop_param_17,
	.param .u64 .ptr .global .align 1 m11600_loop_param_18,
	.param .u64 .ptr .global .align 4 m11600_loop_param_19,
	.param .u64 .ptr .global .align 1 m11600_loop_param_20,
	.param .u64 .ptr .global .align 1 m11600_loop_param_21,
	.param .u64 .ptr .global .align 1 m11600_loop_param_22,
	.param .u64 .ptr .global .align 1 m11600_loop_param_23,
	.param .u64 .ptr .global .align 8 m11600_loop_param_24
)
{
	.local .align 16 .b8 	__local_depot1[3104];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<1764>;
	.reg .b64 	%rd<291>;


	mov.u64 	%SPL, __local_depot1;
	ld.param.u64 	%rd48, [m11600_loop_param_0];
	ld.param.u64 	%rd49, [m11600_loop_param_4];
	ld.param.u64 	%rd50, [m11600_loop_param_24];
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd2, %SPL, 32;
	mov.u32 	%r142, %ctaid.x;
	mov.u32 	%r143, %ntid.x;
	mov.u32 	%r144, %tid.x;
	mov.b32 	%r145, %envreg3;
	add.s32 	%r146, %r144, %r145;
	mad.lo.s32 	%r147, %r143, %r142, %r146;
	cvt.s64.s32 	%rd3, %r147;
	add.s64 	%rd4, %rd50, 56;
	ld.global.u64 	%rd53, [%rd50+56];
	setp.le.u64 	%p1, %rd53, %rd3;
	@%p1 bra 	$L__BB1_14;

	mul.lo.s64 	%rd54, %rd3, 260;
	add.s64 	%rd55, %rd48, %rd54;
	ld.global.u32 	%r150, [%rd55];
	st.local.u32 	[%rd1], %r150;
	ld.global.u32 	%r151, [%rd55+4];
	st.local.u32 	[%rd1+4], %r151;
	ld.global.u32 	%r152, [%rd55+8];
	st.local.u32 	[%rd1+8], %r152;
	ld.global.u32 	%r153, [%rd55+12];
	st.local.u32 	[%rd1+12], %r153;
	ld.global.u32 	%r154, [%rd55+16];
	st.local.u32 	[%rd1+16], %r154;
	ld.global.u32 	%r155, [%rd55+256];
	min.u32 	%r1, %r155, 20;
	mov.u32 	%r1709, 0;
	st.local.v4.u32 	[%rd2], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+16], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+32], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+48], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+64], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+80], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+96], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+112], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+128], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+144], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+160], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+176], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+192], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+208], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+224], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+240], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+256], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+272], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+288], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+304], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+320], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+336], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+352], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+368], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+384], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+400], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+416], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+432], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+448], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+464], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+480], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+496], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+512], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+528], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+544], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+560], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+576], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+592], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+608], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+624], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+640], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+656], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+672], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+688], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+704], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+720], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+736], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+752], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+768], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+784], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+800], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+816], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+832], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+848], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+864], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+880], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+896], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+912], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+928], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+944], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+960], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+976], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+992], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1008], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1024], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1040], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1056], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1072], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1088], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1104], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1120], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1136], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1152], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1168], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1184], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1200], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1216], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1232], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1248], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1264], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1280], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1296], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1312], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1328], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1344], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1360], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1376], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1392], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1408], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1424], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1440], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1456], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1472], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1488], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1504], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1520], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1536], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1552], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1568], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1584], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1600], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1616], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1632], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1648], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1664], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1680], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1696], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1712], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1728], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1744], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1760], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1776], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1792], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1808], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1824], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1840], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1856], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1872], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1888], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1904], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1920], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1936], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1952], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1968], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+1984], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2000], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2016], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2032], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2048], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2064], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2080], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2096], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2112], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2128], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2144], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2160], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2176], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2192], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2208], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2224], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2240], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2256], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2272], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2288], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2304], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2320], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2336], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2352], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2368], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2384], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2400], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2416], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2432], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2448], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2464], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2480], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2496], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2512], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2528], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2544], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2560], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2576], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2592], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2608], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2624], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2640], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2656], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2672], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2688], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2704], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2720], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2736], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2752], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2768], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2784], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2800], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2816], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2832], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2848], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2864], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2880], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2896], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2912], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2928], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2944], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2960], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2976], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+2992], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+3008], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+3024], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+3040], {%r1709, %r1709, %r1709, %r1709};
	st.local.v4.u32 	[%rd2+3056], {%r1709, %r1709, %r1709, %r1709};
	ld.global.u32 	%r1706, [%rd4+-40];
	mov.u32 	%r1705, %r1709;

$L__BB1_2:
	setp.eq.s32 	%p2, %r1, 0;
	@%p2 bra 	$L__BB1_5;

	mov.u32 	%r1707, 0;
	mov.u64 	%rd290, %rd1;

$L__BB1_4:
	ld.local.u8 	%rs1, [%rd290];
	xor.b32  	%r157, %r1709, 3;
	cvt.u64.u32 	%rd56, %r157;
	add.s64 	%rd57, %rd2, %rd56;
	st.local.u8 	[%rd57], %rs1;
	add.s32 	%r1709, %r1709, 2;
	add.s64 	%rd290, %rd290, 1;
	add.s32 	%r1707, %r1707, 1;
	setp.lt.u32 	%p3, %r1707, %r1;
	@%p3 bra 	$L__BB1_4;

$L__BB1_5:
	// begin inline asm
	bfe.u32 %r158, %r1706, 16, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r160, %r1706, 24, 8;
	// end inline asm
	add.s32 	%r162, %r1709, 2;
	xor.b32  	%r163, %r162, 3;
	cvt.u64.u32 	%rd58, %r163;
	add.s64 	%rd59, %rd2, %rd58;
	add.s32 	%r164, %r1709, 3;
	xor.b32  	%r165, %r164, 3;
	cvt.u64.u32 	%rd60, %r165;
	add.s64 	%rd61, %rd2, %rd60;
	st.local.u8 	[%rd59], %r158;
	st.local.u8 	[%rd61], %r160;
	add.s32 	%r1706, %r1706, 1;
	add.s32 	%r1709, %r1709, 8;
	add.s32 	%r1705, %r1705, 1;
	setp.lt.u32 	%p4, %r1705, 64;
	@%p4 bra 	$L__BB1_2;

	mul.lo.s64 	%rd62, %rd3, 100;
	add.s64 	%rd7, %rd49, %rd62;
	ld.global.u32 	%r1729, [%rd7];
	ld.global.u32 	%r1728, [%rd7+4];
	ld.global.u32 	%r1727, [%rd7+8];
	ld.global.u32 	%r1726, [%rd7+12];
	ld.global.u32 	%r1725, [%rd7+16];
	ld.global.u32 	%r1724, [%rd7+20];
	ld.global.u32 	%r1723, [%rd7+24];
	ld.global.u32 	%r1722, [%rd7+28];
	shl.b32 	%r22, %r1, 1;
	add.s32 	%r23, %r22, 8;
	ld.global.u32 	%r167, [%rd4+-36];
	setp.eq.s32 	%p5, %r167, 0;
	mov.u32 	%r1755, 0;
	@%p5 bra 	$L__BB1_13;

	ld.global.u32 	%r1711, [%rd4+-40];
	xor.b32  	%r169, %r22, 3;
	cvt.u64.u32 	%rd63, %r169;
	add.s64 	%rd8, %rd2, %rd63;
	add.s32 	%r170, %r22, 1;
	xor.b32  	%r171, %r170, 3;
	cvt.u64.u32 	%rd64, %r171;
	add.s64 	%rd9, %rd2, %rd64;
	add.s32 	%r25, %r22, %r23;
	add.s32 	%r172, %r25, %r23;
	add.s32 	%r173, %r172, %r23;
	add.s32 	%r174, %r173, %r23;
	add.s32 	%r175, %r174, %r23;
	add.s32 	%r176, %r175, %r23;
	add.s32 	%r177, %r176, %r23;
	add.s32 	%r178, %r177, %r23;
	add.s32 	%r179, %r178, %r23;
	add.s32 	%r180, %r179, %r23;
	add.s32 	%r181, %r180, %r23;
	add.s32 	%r182, %r181, %r23;
	add.s32 	%r183, %r182, %r23;
	add.s32 	%r184, %r183, %r23;
	add.s32 	%r185, %r184, %r23;
	add.s32 	%r186, %r185, %r23;
	add.s32 	%r187, %r186, %r23;
	add.s32 	%r188, %r187, %r23;
	add.s32 	%r189, %r188, %r23;
	add.s32 	%r190, %r189, %r23;
	add.s32 	%r191, %r190, %r23;
	add.s32 	%r192, %r191, %r23;
	add.s32 	%r193, %r192, %r23;
	add.s32 	%r194, %r193, %r23;
	add.s32 	%r195, %r194, %r23;
	add.s32 	%r196, %r195, %r23;
	add.s32 	%r197, %r196, %r23;
	add.s32 	%r198, %r197, %r23;
	add.s32 	%r199, %r198, %r23;
	add.s32 	%r200, %r199, %r23;
	add.s32 	%r201, %r200, %r23;
	add.s32 	%r202, %r201, %r23;
	add.s32 	%r203, %r202, %r23;
	add.s32 	%r204, %r203, %r23;
	add.s32 	%r205, %r204, %r23;
	add.s32 	%r206, %r205, %r23;
	add.s32 	%r207, %r206, %r23;
	add.s32 	%r208, %r207, %r23;
	add.s32 	%r209, %r208, %r23;
	add.s32 	%r210, %r209, %r23;
	add.s32 	%r211, %r210, %r23;
	add.s32 	%r212, %r211, %r23;
	add.s32 	%r213, %r212, %r23;
	add.s32 	%r214, %r213, %r23;
	add.s32 	%r215, %r214, %r23;
	add.s32 	%r216, %r215, 1;
	xor.b32  	%r217, %r216, 3;
	cvt.u64.u32 	%rd65, %r217;
	add.s64 	%rd10, %rd2, %rd65;
	add.s32 	%r218, %r215, %r23;
	xor.b32  	%r219, %r218, 3;
	cvt.u64.u32 	%rd66, %r219;
	add.s64 	%rd11, %rd2, %rd66;
	add.s32 	%r220, %r218, 1;
	xor.b32  	%r221, %r220, 3;
	cvt.u64.u32 	%rd67, %r221;
	add.s64 	%rd12, %rd2, %rd67;
	add.s32 	%r222, %r218, %r23;
	xor.b32  	%r223, %r222, 3;
	cvt.u64.u32 	%rd68, %r223;
	add.s64 	%rd13, %rd2, %rd68;
	add.s32 	%r224, %r222, 1;
	xor.b32  	%r225, %r224, 3;
	cvt.u64.u32 	%rd69, %r225;
	add.s64 	%rd14, %rd2, %rd69;
	add.s32 	%r226, %r222, %r23;
	xor.b32  	%r227, %r226, 3;
	cvt.u64.u32 	%rd70, %r227;
	add.s64 	%rd15, %rd2, %rd70;
	add.s32 	%r228, %r226, 1;
	xor.b32  	%r229, %r228, 3;
	cvt.u64.u32 	%rd71, %r229;
	add.s64 	%rd16, %rd2, %rd71;
	add.s32 	%r230, %r226, %r23;
	xor.b32  	%r231, %r230, 3;
	cvt.u64.u32 	%rd72, %r231;
	add.s64 	%rd17, %rd2, %rd72;
	add.s32 	%r232, %r230, 1;
	xor.b32  	%r233, %r232, 3;
	cvt.u64.u32 	%rd73, %r233;
	add.s64 	%rd18, %rd2, %rd73;
	add.s32 	%r234, %r230, %r23;
	xor.b32  	%r235, %r234, 3;
	cvt.u64.u32 	%rd74, %r235;
	add.s64 	%rd19, %rd2, %rd74;
	add.s32 	%r236, %r234, 1;
	xor.b32  	%r237, %r236, 3;
	cvt.u64.u32 	%rd75, %r237;
	add.s64 	%rd20, %rd2, %rd75;
	add.s32 	%r238, %r234, %r23;
	xor.b32  	%r239, %r238, 3;
	cvt.u64.u32 	%rd76, %r239;
	add.s64 	%rd21, %rd2, %rd76;
	add.s32 	%r240, %r238, 1;
	xor.b32  	%r241, %r240, 3;
	cvt.u64.u32 	%rd77, %r241;
	add.s64 	%rd22, %rd2, %rd77;
	add.s32 	%r242, %r238, %r23;
	xor.b32  	%r243, %r242, 3;
	cvt.u64.u32 	%rd78, %r243;
	add.s64 	%rd23, %rd2, %rd78;
	add.s32 	%r244, %r242, 1;
	xor.b32  	%r245, %r244, 3;
	cvt.u64.u32 	%rd79, %r245;
	add.s64 	%rd24, %rd2, %rd79;
	add.s32 	%r246, %r242, %r23;
	xor.b32  	%r247, %r246, 3;
	cvt.u64.u32 	%rd80, %r247;
	add.s64 	%rd25, %rd2, %rd80;
	add.s32 	%r248, %r246, 1;
	xor.b32  	%r249, %r248, 3;
	cvt.u64.u32 	%rd81, %r249;
	add.s64 	%rd26, %rd2, %rd81;
	add.s32 	%r250, %r246, %r23;
	xor.b32  	%r251, %r250, 3;
	cvt.u64.u32 	%rd82, %r251;
	add.s64 	%rd27, %rd2, %rd82;
	add.s32 	%r252, %r250, 1;
	xor.b32  	%r253, %r252, 3;
	cvt.u64.u32 	%rd83, %r253;
	add.s64 	%rd28, %rd2, %rd83;
	add.s32 	%r254, %r250, %r23;
	xor.b32  	%r255, %r254, 3;
	cvt.u64.u32 	%rd84, %r255;
	add.s64 	%rd29, %rd2, %rd84;
	add.s32 	%r256, %r254, 1;
	xor.b32  	%r257, %r256, 3;
	cvt.u64.u32 	%rd85, %r257;
	add.s64 	%rd30, %rd2, %rd85;
	add.s32 	%r258, %r254, %r23;
	xor.b32  	%r259, %r258, 3;
	cvt.u64.u32 	%rd86, %r259;
	add.s64 	%rd31, %rd2, %rd86;
	add.s32 	%r260, %r258, 1;
	xor.b32  	%r261, %r260, 3;
	cvt.u64.u32 	%rd87, %r261;
	add.s64 	%rd32, %rd2, %rd87;
	add.s32 	%r262, %r258, %r23;
	xor.b32  	%r263, %r262, 3;
	cvt.u64.u32 	%rd88, %r263;
	add.s64 	%rd33, %rd2, %rd88;
	add.s32 	%r264, %r262, 1;
	xor.b32  	%r265, %r264, 3;
	cvt.u64.u32 	%rd89, %r265;
	add.s64 	%rd34, %rd2, %rd89;
	add.s32 	%r266, %r262, %r23;
	xor.b32  	%r267, %r266, 3;
	cvt.u64.u32 	%rd90, %r267;
	add.s64 	%rd35, %rd2, %rd90;
	add.s32 	%r268, %r266, 1;
	xor.b32  	%r269, %r268, 3;
	cvt.u64.u32 	%rd91, %r269;
	add.s64 	%rd36, %rd2, %rd91;
	add.s32 	%r270, %r266, %r23;
	xor.b32  	%r271, %r270, 3;
	cvt.u64.u32 	%rd92, %r271;
	add.s64 	%rd37, %rd2, %rd92;
	add.s32 	%r272, %r270, 1;
	xor.b32  	%r273, %r272, 3;
	cvt.u64.u32 	%rd93, %r273;
	add.s64 	%rd38, %rd2, %rd93;
	add.s32 	%r274, %r270, %r23;
	xor.b32  	%r275, %r274, 3;
	cvt.u64.u32 	%rd94, %r275;
	add.s64 	%rd39, %rd2, %rd94;
	add.s32 	%r276, %r274, 1;
	xor.b32  	%r277, %r276, 3;
	cvt.u64.u32 	%rd95, %r277;
	add.s64 	%rd40, %rd2, %rd95;
	add.s32 	%r278, %r274, %r23;
	xor.b32  	%r279, %r278, 3;
	cvt.u64.u32 	%rd96, %r279;
	add.s64 	%rd41, %rd2, %rd96;
	add.s32 	%r280, %r278, 1;
	xor.b32  	%r281, %r280, 3;
	cvt.u64.u32 	%rd97, %r281;
	add.s64 	%rd42, %rd2, %rd97;
	add.s32 	%r282, %r278, %r23;
	xor.b32  	%r283, %r282, 3;
	cvt.u64.u32 	%rd98, %r283;
	add.s64 	%rd43, %rd2, %rd98;
	add.s32 	%r284, %r282, 1;
	xor.b32  	%r285, %r284, 3;
	cvt.u64.u32 	%rd99, %r285;
	add.s64 	%rd44, %rd2, %rd99;
	add.s32 	%r286, %r282, %r23;
	xor.b32  	%r287, %r286, 3;
	cvt.u64.u32 	%rd100, %r287;
	add.s64 	%rd45, %rd2, %rd100;
	add.s32 	%r288, %r286, 1;
	xor.b32  	%r289, %r288, 3;
	cvt.u64.u32 	%rd101, %r289;
	add.s64 	%rd46, %rd2, %rd101;
	mov.u32 	%r168, 0;
	mov.u32 	%r1710, %r168;

$L__BB1_8:
	// begin inline asm
	bfe.u32 %r290, %r1711, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r292, %r1711, 8, 8;
	// end inline asm
	st.local.u8 	[%rd8], %r290;
	st.local.u8 	[%rd9], %r292;
	add.s32 	%r297, %r1711, 1;
	// begin inline asm
	bfe.u32 %r294, %r297, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r296, %r297, 8, 8;
	// end inline asm
	xor.b32  	%r548, %r25, 3;
	cvt.u64.u32 	%rd102, %r548;
	add.s64 	%rd105, %rd2, %rd102;
	add.s32 	%r549, %r25, 1;
	xor.b32  	%r550, %r549, 3;
	cvt.u64.u32 	%rd106, %r550;
	add.s64 	%rd107, %rd2, %rd106;
	st.local.u8 	[%rd105], %r294;
	st.local.u8 	[%rd107], %r296;
	add.s32 	%r301, %r1711, 2;
	// begin inline asm
	bfe.u32 %r298, %r301, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r300, %r301, 8, 8;
	// end inline asm
	xor.b32  	%r552, %r172, 3;
	cvt.u64.u32 	%rd108, %r552;
	add.s64 	%rd109, %rd2, %rd108;
	add.s32 	%r553, %r172, 1;
	xor.b32  	%r554, %r553, 3;
	cvt.u64.u32 	%rd110, %r554;
	add.s64 	%rd111, %rd2, %rd110;
	st.local.u8 	[%rd109], %r298;
	st.local.u8 	[%rd111], %r300;
	add.s32 	%r305, %r1711, 3;
	// begin inline asm
	bfe.u32 %r302, %r305, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r304, %r305, 8, 8;
	// end inline asm
	xor.b32  	%r556, %r173, 3;
	cvt.u64.u32 	%rd112, %r556;
	add.s64 	%rd113, %rd2, %rd112;
	add.s32 	%r557, %r173, 1;
	xor.b32  	%r558, %r557, 3;
	cvt.u64.u32 	%rd114, %r558;
	add.s64 	%rd115, %rd2, %rd114;
	st.local.u8 	[%rd113], %r302;
	st.local.u8 	[%rd115], %r304;
	add.s32 	%r309, %r1711, 4;
	// begin inline asm
	bfe.u32 %r306, %r309, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r308, %r309, 8, 8;
	// end inline asm
	xor.b32  	%r560, %r174, 3;
	cvt.u64.u32 	%rd116, %r560;
	add.s64 	%rd117, %rd2, %rd116;
	add.s32 	%r561, %r174, 1;
	xor.b32  	%r562, %r561, 3;
	cvt.u64.u32 	%rd118, %r562;
	add.s64 	%rd119, %rd2, %rd118;
	st.local.u8 	[%rd117], %r306;
	st.local.u8 	[%rd119], %r308;
	add.s32 	%r313, %r1711, 5;
	// begin inline asm
	bfe.u32 %r310, %r313, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r312, %r313, 8, 8;
	// end inline asm
	xor.b32  	%r564, %r175, 3;
	cvt.u64.u32 	%rd120, %r564;
	add.s64 	%rd121, %rd2, %rd120;
	add.s32 	%r565, %r175, 1;
	xor.b32  	%r566, %r565, 3;
	cvt.u64.u32 	%rd122, %r566;
	add.s64 	%rd123, %rd2, %rd122;
	st.local.u8 	[%rd121], %r310;
	st.local.u8 	[%rd123], %r312;
	add.s32 	%r317, %r1711, 6;
	// begin inline asm
	bfe.u32 %r314, %r317, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r316, %r317, 8, 8;
	// end inline asm
	xor.b32  	%r568, %r176, 3;
	cvt.u64.u32 	%rd124, %r568;
	add.s64 	%rd125, %rd2, %rd124;
	add.s32 	%r569, %r176, 1;
	xor.b32  	%r570, %r569, 3;
	cvt.u64.u32 	%rd126, %r570;
	add.s64 	%rd127, %rd2, %rd126;
	st.local.u8 	[%rd125], %r314;
	st.local.u8 	[%rd127], %r316;
	add.s32 	%r321, %r1711, 7;
	// begin inline asm
	bfe.u32 %r318, %r321, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r320, %r321, 8, 8;
	// end inline asm
	xor.b32  	%r572, %r177, 3;
	cvt.u64.u32 	%rd128, %r572;
	add.s64 	%rd129, %rd2, %rd128;
	add.s32 	%r573, %r177, 1;
	xor.b32  	%r574, %r573, 3;
	cvt.u64.u32 	%rd130, %r574;
	add.s64 	%rd131, %rd2, %rd130;
	st.local.u8 	[%rd129], %r318;
	st.local.u8 	[%rd131], %r320;
	add.s32 	%r325, %r1711, 8;
	// begin inline asm
	bfe.u32 %r322, %r325, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r324, %r325, 8, 8;
	// end inline asm
	xor.b32  	%r576, %r178, 3;
	cvt.u64.u32 	%rd132, %r576;
	add.s64 	%rd133, %rd2, %rd132;
	add.s32 	%r577, %r178, 1;
	xor.b32  	%r578, %r577, 3;
	cvt.u64.u32 	%rd134, %r578;
	add.s64 	%rd135, %rd2, %rd134;
	st.local.u8 	[%rd133], %r322;
	st.local.u8 	[%rd135], %r324;
	add.s32 	%r329, %r1711, 9;
	// begin inline asm
	bfe.u32 %r326, %r329, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r328, %r329, 8, 8;
	// end inline asm
	xor.b32  	%r580, %r179, 3;
	cvt.u64.u32 	%rd136, %r580;
	add.s64 	%rd137, %rd2, %rd136;
	add.s32 	%r581, %r179, 1;
	xor.b32  	%r582, %r581, 3;
	cvt.u64.u32 	%rd138, %r582;
	add.s64 	%rd139, %rd2, %rd138;
	st.local.u8 	[%rd137], %r326;
	st.local.u8 	[%rd139], %r328;
	add.s32 	%r333, %r1711, 10;
	// begin inline asm
	bfe.u32 %r330, %r333, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r332, %r333, 8, 8;
	// end inline asm
	xor.b32  	%r584, %r180, 3;
	cvt.u64.u32 	%rd140, %r584;
	add.s64 	%rd141, %rd2, %rd140;
	add.s32 	%r585, %r180, 1;
	xor.b32  	%r586, %r585, 3;
	cvt.u64.u32 	%rd142, %r586;
	add.s64 	%rd143, %rd2, %rd142;
	st.local.u8 	[%rd141], %r330;
	st.local.u8 	[%rd143], %r332;
	add.s32 	%r337, %r1711, 11;
	// begin inline asm
	bfe.u32 %r334, %r337, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r336, %r337, 8, 8;
	// end inline asm
	xor.b32  	%r588, %r181, 3;
	cvt.u64.u32 	%rd144, %r588;
	add.s64 	%rd145, %rd2, %rd144;
	add.s32 	%r589, %r181, 1;
	xor.b32  	%r590, %r589, 3;
	cvt.u64.u32 	%rd146, %r590;
	add.s64 	%rd147, %rd2, %rd146;
	st.local.u8 	[%rd145], %r334;
	st.local.u8 	[%rd147], %r336;
	add.s32 	%r341, %r1711, 12;
	// begin inline asm
	bfe.u32 %r338, %r341, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r340, %r341, 8, 8;
	// end inline asm
	xor.b32  	%r592, %r182, 3;
	cvt.u64.u32 	%rd148, %r592;
	add.s64 	%rd149, %rd2, %rd148;
	add.s32 	%r593, %r182, 1;
	xor.b32  	%r594, %r593, 3;
	cvt.u64.u32 	%rd150, %r594;
	add.s64 	%rd151, %rd2, %rd150;
	st.local.u8 	[%rd149], %r338;
	st.local.u8 	[%rd151], %r340;
	add.s32 	%r345, %r1711, 13;
	// begin inline asm
	bfe.u32 %r342, %r345, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r344, %r345, 8, 8;
	// end inline asm
	xor.b32  	%r596, %r183, 3;
	cvt.u64.u32 	%rd152, %r596;
	add.s64 	%rd153, %rd2, %rd152;
	add.s32 	%r597, %r183, 1;
	xor.b32  	%r598, %r597, 3;
	cvt.u64.u32 	%rd154, %r598;
	add.s64 	%rd155, %rd2, %rd154;
	st.local.u8 	[%rd153], %r342;
	st.local.u8 	[%rd155], %r344;
	add.s32 	%r349, %r1711, 14;
	// begin inline asm
	bfe.u32 %r346, %r349, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r348, %r349, 8, 8;
	// end inline asm
	xor.b32  	%r600, %r184, 3;
	cvt.u64.u32 	%rd156, %r600;
	add.s64 	%rd157, %rd2, %rd156;
	add.s32 	%r601, %r184, 1;
	xor.b32  	%r602, %r601, 3;
	cvt.u64.u32 	%rd158, %r602;
	add.s64 	%rd159, %rd2, %rd158;
	st.local.u8 	[%rd157], %r346;
	st.local.u8 	[%rd159], %r348;
	add.s32 	%r353, %r1711, 15;
	// begin inline asm
	bfe.u32 %r350, %r353, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r352, %r353, 8, 8;
	// end inline asm
	xor.b32  	%r604, %r185, 3;
	cvt.u64.u32 	%rd160, %r604;
	add.s64 	%rd161, %rd2, %rd160;
	add.s32 	%r605, %r185, 1;
	xor.b32  	%r606, %r605, 3;
	cvt.u64.u32 	%rd162, %r606;
	add.s64 	%rd163, %rd2, %rd162;
	st.local.u8 	[%rd161], %r350;
	st.local.u8 	[%rd163], %r352;
	add.s32 	%r357, %r1711, 16;
	// begin inline asm
	bfe.u32 %r354, %r357, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r356, %r357, 8, 8;
	// end inline asm
	xor.b32  	%r608, %r186, 3;
	cvt.u64.u32 	%rd164, %r608;
	add.s64 	%rd165, %rd2, %rd164;
	add.s32 	%r609, %r186, 1;
	xor.b32  	%r610, %r609, 3;
	cvt.u64.u32 	%rd166, %r610;
	add.s64 	%rd167, %rd2, %rd166;
	st.local.u8 	[%rd165], %r354;
	st.local.u8 	[%rd167], %r356;
	add.s32 	%r361, %r1711, 17;
	// begin inline asm
	bfe.u32 %r358, %r361, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r360, %r361, 8, 8;
	// end inline asm
	xor.b32  	%r612, %r187, 3;
	cvt.u64.u32 	%rd168, %r612;
	add.s64 	%rd169, %rd2, %rd168;
	add.s32 	%r613, %r187, 1;
	xor.b32  	%r614, %r613, 3;
	cvt.u64.u32 	%rd170, %r614;
	add.s64 	%rd171, %rd2, %rd170;
	st.local.u8 	[%rd169], %r358;
	st.local.u8 	[%rd171], %r360;
	add.s32 	%r365, %r1711, 18;
	// begin inline asm
	bfe.u32 %r362, %r365, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r364, %r365, 8, 8;
	// end inline asm
	xor.b32  	%r616, %r188, 3;
	cvt.u64.u32 	%rd172, %r616;
	add.s64 	%rd173, %rd2, %rd172;
	add.s32 	%r617, %r188, 1;
	xor.b32  	%r618, %r617, 3;
	cvt.u64.u32 	%rd174, %r618;
	add.s64 	%rd175, %rd2, %rd174;
	st.local.u8 	[%rd173], %r362;
	st.local.u8 	[%rd175], %r364;
	add.s32 	%r369, %r1711, 19;
	// begin inline asm
	bfe.u32 %r366, %r369, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r368, %r369, 8, 8;
	// end inline asm
	xor.b32  	%r620, %r189, 3;
	cvt.u64.u32 	%rd176, %r620;
	add.s64 	%rd177, %rd2, %rd176;
	add.s32 	%r621, %r189, 1;
	xor.b32  	%r622, %r621, 3;
	cvt.u64.u32 	%rd178, %r622;
	add.s64 	%rd179, %rd2, %rd178;
	st.local.u8 	[%rd177], %r366;
	st.local.u8 	[%rd179], %r368;
	add.s32 	%r373, %r1711, 20;
	// begin inline asm
	bfe.u32 %r370, %r373, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r372, %r373, 8, 8;
	// end inline asm
	xor.b32  	%r624, %r190, 3;
	cvt.u64.u32 	%rd180, %r624;
	add.s64 	%rd181, %rd2, %rd180;
	add.s32 	%r625, %r190, 1;
	xor.b32  	%r626, %r625, 3;
	cvt.u64.u32 	%rd182, %r626;
	add.s64 	%rd183, %rd2, %rd182;
	st.local.u8 	[%rd181], %r370;
	st.local.u8 	[%rd183], %r372;
	add.s32 	%r377, %r1711, 21;
	// begin inline asm
	bfe.u32 %r374, %r377, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r376, %r377, 8, 8;
	// end inline asm
	xor.b32  	%r628, %r191, 3;
	cvt.u64.u32 	%rd184, %r628;
	add.s64 	%rd185, %rd2, %rd184;
	add.s32 	%r629, %r191, 1;
	xor.b32  	%r630, %r629, 3;
	cvt.u64.u32 	%rd186, %r630;
	add.s64 	%rd187, %rd2, %rd186;
	st.local.u8 	[%rd185], %r374;
	st.local.u8 	[%rd187], %r376;
	add.s32 	%r381, %r1711, 22;
	// begin inline asm
	bfe.u32 %r378, %r381, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r380, %r381, 8, 8;
	// end inline asm
	xor.b32  	%r632, %r192, 3;
	cvt.u64.u32 	%rd188, %r632;
	add.s64 	%rd189, %rd2, %rd188;
	add.s32 	%r633, %r192, 1;
	xor.b32  	%r634, %r633, 3;
	cvt.u64.u32 	%rd190, %r634;
	add.s64 	%rd191, %rd2, %rd190;
	st.local.u8 	[%rd189], %r378;
	st.local.u8 	[%rd191], %r380;
	add.s32 	%r385, %r1711, 23;
	// begin inline asm
	bfe.u32 %r382, %r385, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r384, %r385, 8, 8;
	// end inline asm
	xor.b32  	%r636, %r193, 3;
	cvt.u64.u32 	%rd192, %r636;
	add.s64 	%rd193, %rd2, %rd192;
	add.s32 	%r637, %r193, 1;
	xor.b32  	%r638, %r637, 3;
	cvt.u64.u32 	%rd194, %r638;
	add.s64 	%rd195, %rd2, %rd194;
	st.local.u8 	[%rd193], %r382;
	st.local.u8 	[%rd195], %r384;
	add.s32 	%r389, %r1711, 24;
	// begin inline asm
	bfe.u32 %r386, %r389, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r388, %r389, 8, 8;
	// end inline asm
	xor.b32  	%r640, %r194, 3;
	cvt.u64.u32 	%rd196, %r640;
	add.s64 	%rd197, %rd2, %rd196;
	add.s32 	%r641, %r194, 1;
	xor.b32  	%r642, %r641, 3;
	cvt.u64.u32 	%rd198, %r642;
	add.s64 	%rd199, %rd2, %rd198;
	st.local.u8 	[%rd197], %r386;
	st.local.u8 	[%rd199], %r388;
	add.s32 	%r393, %r1711, 25;
	// begin inline asm
	bfe.u32 %r390, %r393, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r392, %r393, 8, 8;
	// end inline asm
	xor.b32  	%r644, %r195, 3;
	cvt.u64.u32 	%rd200, %r644;
	add.s64 	%rd201, %rd2, %rd200;
	add.s32 	%r645, %r195, 1;
	xor.b32  	%r646, %r645, 3;
	cvt.u64.u32 	%rd202, %r646;
	add.s64 	%rd203, %rd2, %rd202;
	st.local.u8 	[%rd201], %r390;
	st.local.u8 	[%rd203], %r392;
	add.s32 	%r397, %r1711, 26;
	// begin inline asm
	bfe.u32 %r394, %r397, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r396, %r397, 8, 8;
	// end inline asm
	xor.b32  	%r648, %r196, 3;
	cvt.u64.u32 	%rd204, %r648;
	add.s64 	%rd205, %rd2, %rd204;
	add.s32 	%r649, %r196, 1;
	xor.b32  	%r650, %r649, 3;
	cvt.u64.u32 	%rd206, %r650;
	add.s64 	%rd207, %rd2, %rd206;
	st.local.u8 	[%rd205], %r394;
	st.local.u8 	[%rd207], %r396;
	add.s32 	%r401, %r1711, 27;
	// begin inline asm
	bfe.u32 %r398, %r401, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r400, %r401, 8, 8;
	// end inline asm
	xor.b32  	%r652, %r197, 3;
	cvt.u64.u32 	%rd208, %r652;
	add.s64 	%rd209, %rd2, %rd208;
	add.s32 	%r653, %r197, 1;
	xor.b32  	%r654, %r653, 3;
	cvt.u64.u32 	%rd210, %r654;
	add.s64 	%rd211, %rd2, %rd210;
	st.local.u8 	[%rd209], %r398;
	st.local.u8 	[%rd211], %r400;
	add.s32 	%r405, %r1711, 28;
	// begin inline asm
	bfe.u32 %r402, %r405, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r404, %r405, 8, 8;
	// end inline asm
	xor.b32  	%r656, %r198, 3;
	cvt.u64.u32 	%rd212, %r656;
	add.s64 	%rd213, %rd2, %rd212;
	add.s32 	%r657, %r198, 1;
	xor.b32  	%r658, %r657, 3;
	cvt.u64.u32 	%rd214, %r658;
	add.s64 	%rd215, %rd2, %rd214;
	st.local.u8 	[%rd213], %r402;
	st.local.u8 	[%rd215], %r404;
	add.s32 	%r409, %r1711, 29;
	// begin inline asm
	bfe.u32 %r406, %r409, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r408, %r409, 8, 8;
	// end inline asm
	xor.b32  	%r660, %r199, 3;
	cvt.u64.u32 	%rd216, %r660;
	add.s64 	%rd217, %rd2, %rd216;
	add.s32 	%r661, %r199, 1;
	xor.b32  	%r662, %r661, 3;
	cvt.u64.u32 	%rd218, %r662;
	add.s64 	%rd219, %rd2, %rd218;
	st.local.u8 	[%rd217], %r406;
	st.local.u8 	[%rd219], %r408;
	add.s32 	%r413, %r1711, 30;
	// begin inline asm
	bfe.u32 %r410, %r413, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r412, %r413, 8, 8;
	// end inline asm
	xor.b32  	%r664, %r200, 3;
	cvt.u64.u32 	%rd220, %r664;
	add.s64 	%rd221, %rd2, %rd220;
	add.s32 	%r665, %r200, 1;
	xor.b32  	%r666, %r665, 3;
	cvt.u64.u32 	%rd222, %r666;
	add.s64 	%rd223, %rd2, %rd222;
	st.local.u8 	[%rd221], %r410;
	st.local.u8 	[%rd223], %r412;
	add.s32 	%r417, %r1711, 31;
	// begin inline asm
	bfe.u32 %r414, %r417, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r416, %r417, 8, 8;
	// end inline asm
	xor.b32  	%r668, %r201, 3;
	cvt.u64.u32 	%rd224, %r668;
	add.s64 	%rd225, %rd2, %rd224;
	add.s32 	%r669, %r201, 1;
	xor.b32  	%r670, %r669, 3;
	cvt.u64.u32 	%rd226, %r670;
	add.s64 	%rd227, %rd2, %rd226;
	st.local.u8 	[%rd225], %r414;
	st.local.u8 	[%rd227], %r416;
	add.s32 	%r421, %r1711, 32;
	// begin inline asm
	bfe.u32 %r418, %r421, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r420, %r421, 8, 8;
	// end inline asm
	xor.b32  	%r672, %r202, 3;
	cvt.u64.u32 	%rd228, %r672;
	add.s64 	%rd229, %rd2, %rd228;
	add.s32 	%r673, %r202, 1;
	xor.b32  	%r674, %r673, 3;
	cvt.u64.u32 	%rd230, %r674;
	add.s64 	%rd231, %rd2, %rd230;
	st.local.u8 	[%rd229], %r418;
	st.local.u8 	[%rd231], %r420;
	add.s32 	%r425, %r1711, 33;
	// begin inline asm
	bfe.u32 %r422, %r425, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r424, %r425, 8, 8;
	// end inline asm
	xor.b32  	%r676, %r203, 3;
	cvt.u64.u32 	%rd232, %r676;
	add.s64 	%rd233, %rd2, %rd232;
	add.s32 	%r677, %r203, 1;
	xor.b32  	%r678, %r677, 3;
	cvt.u64.u32 	%rd234, %r678;
	add.s64 	%rd235, %rd2, %rd234;
	st.local.u8 	[%rd233], %r422;
	st.local.u8 	[%rd235], %r424;
	add.s32 	%r429, %r1711, 34;
	// begin inline asm
	bfe.u32 %r426, %r429, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r428, %r429, 8, 8;
	// end inline asm
	xor.b32  	%r680, %r204, 3;
	cvt.u64.u32 	%rd236, %r680;
	add.s64 	%rd237, %rd2, %rd236;
	add.s32 	%r681, %r204, 1;
	xor.b32  	%r682, %r681, 3;
	cvt.u64.u32 	%rd238, %r682;
	add.s64 	%rd239, %rd2, %rd238;
	st.local.u8 	[%rd237], %r426;
	st.local.u8 	[%rd239], %r428;
	add.s32 	%r433, %r1711, 35;
	// begin inline asm
	bfe.u32 %r430, %r433, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r432, %r433, 8, 8;
	// end inline asm
	xor.b32  	%r684, %r205, 3;
	cvt.u64.u32 	%rd240, %r684;
	add.s64 	%rd241, %rd2, %rd240;
	add.s32 	%r685, %r205, 1;
	xor.b32  	%r686, %r685, 3;
	cvt.u64.u32 	%rd242, %r686;
	add.s64 	%rd243, %rd2, %rd242;
	st.local.u8 	[%rd241], %r430;
	st.local.u8 	[%rd243], %r432;
	add.s32 	%r437, %r1711, 36;
	// begin inline asm
	bfe.u32 %r434, %r437, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r436, %r437, 8, 8;
	// end inline asm
	xor.b32  	%r688, %r206, 3;
	cvt.u64.u32 	%rd244, %r688;
	add.s64 	%rd245, %rd2, %rd244;
	add.s32 	%r689, %r206, 1;
	xor.b32  	%r690, %r689, 3;
	cvt.u64.u32 	%rd246, %r690;
	add.s64 	%rd247, %rd2, %rd246;
	st.local.u8 	[%rd245], %r434;
	st.local.u8 	[%rd247], %r436;
	add.s32 	%r441, %r1711, 37;
	// begin inline asm
	bfe.u32 %r438, %r441, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r440, %r441, 8, 8;
	// end inline asm
	xor.b32  	%r692, %r207, 3;
	cvt.u64.u32 	%rd248, %r692;
	add.s64 	%rd249, %rd2, %rd248;
	add.s32 	%r693, %r207, 1;
	xor.b32  	%r694, %r693, 3;
	cvt.u64.u32 	%rd250, %r694;
	add.s64 	%rd251, %rd2, %rd250;
	st.local.u8 	[%rd249], %r438;
	st.local.u8 	[%rd251], %r440;
	add.s32 	%r445, %r1711, 38;
	// begin inline asm
	bfe.u32 %r442, %r445, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r444, %r445, 8, 8;
	// end inline asm
	xor.b32  	%r696, %r208, 3;
	cvt.u64.u32 	%rd252, %r696;
	add.s64 	%rd253, %rd2, %rd252;
	add.s32 	%r697, %r208, 1;
	xor.b32  	%r698, %r697, 3;
	cvt.u64.u32 	%rd254, %r698;
	add.s64 	%rd255, %rd2, %rd254;
	st.local.u8 	[%rd253], %r442;
	st.local.u8 	[%rd255], %r444;
	add.s32 	%r449, %r1711, 39;
	// begin inline asm
	bfe.u32 %r446, %r449, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r448, %r449, 8, 8;
	// end inline asm
	xor.b32  	%r700, %r209, 3;
	cvt.u64.u32 	%rd256, %r700;
	add.s64 	%rd257, %rd2, %rd256;
	add.s32 	%r701, %r209, 1;
	xor.b32  	%r702, %r701, 3;
	cvt.u64.u32 	%rd258, %r702;
	add.s64 	%rd259, %rd2, %rd258;
	st.local.u8 	[%rd257], %r446;
	st.local.u8 	[%rd259], %r448;
	add.s32 	%r453, %r1711, 40;
	// begin inline asm
	bfe.u32 %r450, %r453, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r452, %r453, 8, 8;
	// end inline asm
	xor.b32  	%r704, %r210, 3;
	cvt.u64.u32 	%rd260, %r704;
	add.s64 	%rd261, %rd2, %rd260;
	add.s32 	%r705, %r210, 1;
	xor.b32  	%r706, %r705, 3;
	cvt.u64.u32 	%rd262, %r706;
	add.s64 	%rd263, %rd2, %rd262;
	st.local.u8 	[%rd261], %r450;
	st.local.u8 	[%rd263], %r452;
	add.s32 	%r457, %r1711, 41;
	// begin inline asm
	bfe.u32 %r454, %r457, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r456, %r457, 8, 8;
	// end inline asm
	xor.b32  	%r708, %r211, 3;
	cvt.u64.u32 	%rd264, %r708;
	add.s64 	%rd265, %rd2, %rd264;
	add.s32 	%r709, %r211, 1;
	xor.b32  	%r710, %r709, 3;
	cvt.u64.u32 	%rd266, %r710;
	add.s64 	%rd267, %rd2, %rd266;
	st.local.u8 	[%rd265], %r454;
	st.local.u8 	[%rd267], %r456;
	add.s32 	%r461, %r1711, 42;
	// begin inline asm
	bfe.u32 %r458, %r461, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r460, %r461, 8, 8;
	// end inline asm
	xor.b32  	%r712, %r212, 3;
	cvt.u64.u32 	%rd268, %r712;
	add.s64 	%rd269, %rd2, %rd268;
	add.s32 	%r713, %r212, 1;
	xor.b32  	%r714, %r713, 3;
	cvt.u64.u32 	%rd270, %r714;
	add.s64 	%rd271, %rd2, %rd270;
	st.local.u8 	[%rd269], %r458;
	st.local.u8 	[%rd271], %r460;
	add.s32 	%r465, %r1711, 43;
	// begin inline asm
	bfe.u32 %r462, %r465, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r464, %r465, 8, 8;
	// end inline asm
	xor.b32  	%r716, %r213, 3;
	cvt.u64.u32 	%rd272, %r716;
	add.s64 	%rd273, %rd2, %rd272;
	add.s32 	%r717, %r213, 1;
	xor.b32  	%r718, %r717, 3;
	cvt.u64.u32 	%rd274, %r718;
	add.s64 	%rd275, %rd2, %rd274;
	st.local.u8 	[%rd273], %r462;
	st.local.u8 	[%rd275], %r464;
	add.s32 	%r469, %r1711, 44;
	// begin inline asm
	bfe.u32 %r466, %r469, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r468, %r469, 8, 8;
	// end inline asm
	xor.b32  	%r720, %r214, 3;
	cvt.u64.u32 	%rd276, %r720;
	add.s64 	%rd277, %rd2, %rd276;
	add.s32 	%r721, %r214, 1;
	xor.b32  	%r722, %r721, 3;
	cvt.u64.u32 	%rd278, %r722;
	add.s64 	%rd279, %rd2, %rd278;
	st.local.u8 	[%rd277], %r466;
	st.local.u8 	[%rd279], %r468;
	add.s32 	%r473, %r1711, 45;
	// begin inline asm
	bfe.u32 %r470, %r473, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r472, %r473, 8, 8;
	// end inline asm
	xor.b32  	%r724, %r215, 3;
	cvt.u64.u32 	%rd280, %r724;
	add.s64 	%rd281, %rd2, %rd280;
	st.local.u8 	[%rd281], %r470;
	st.local.u8 	[%rd10], %r472;
	add.s32 	%r477, %r1711, 46;
	// begin inline asm
	bfe.u32 %r474, %r477, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r476, %r477, 8, 8;
	// end inline asm
	st.local.u8 	[%rd11], %r474;
	st.local.u8 	[%rd12], %r476;
	add.s32 	%r481, %r1711, 47;
	// begin inline asm
	bfe.u32 %r478, %r481, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r480, %r481, 8, 8;
	// end inline asm
	st.local.u8 	[%rd13], %r478;
	st.local.u8 	[%rd14], %r480;
	add.s32 	%r485, %r1711, 48;
	// begin inline asm
	bfe.u32 %r482, %r485, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r484, %r485, 8, 8;
	// end inline asm
	st.local.u8 	[%rd15], %r482;
	st.local.u8 	[%rd16], %r484;
	add.s32 	%r489, %r1711, 49;
	// begin inline asm
	bfe.u32 %r486, %r489, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r488, %r489, 8, 8;
	// end inline asm
	st.local.u8 	[%rd17], %r486;
	st.local.u8 	[%rd18], %r488;
	add.s32 	%r493, %r1711, 50;
	// begin inline asm
	bfe.u32 %r490, %r493, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r492, %r493, 8, 8;
	// end inline asm
	st.local.u8 	[%rd19], %r490;
	st.local.u8 	[%rd20], %r492;
	add.s32 	%r497, %r1711, 51;
	// begin inline asm
	bfe.u32 %r494, %r497, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r496, %r497, 8, 8;
	// end inline asm
	st.local.u8 	[%rd21], %r494;
	st.local.u8 	[%rd22], %r496;
	add.s32 	%r501, %r1711, 52;
	// begin inline asm
	bfe.u32 %r498, %r501, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r500, %r501, 8, 8;
	// end inline asm
	st.local.u8 	[%rd23], %r498;
	st.local.u8 	[%rd24], %r500;
	add.s32 	%r505, %r1711, 53;
	// begin inline asm
	bfe.u32 %r502, %r505, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r504, %r505, 8, 8;
	// end inline asm
	st.local.u8 	[%rd25], %r502;
	st.local.u8 	[%rd26], %r504;
	add.s32 	%r509, %r1711, 54;
	// begin inline asm
	bfe.u32 %r506, %r509, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r508, %r509, 8, 8;
	// end inline asm
	st.local.u8 	[%rd27], %r506;
	st.local.u8 	[%rd28], %r508;
	add.s32 	%r513, %r1711, 55;
	// begin inline asm
	bfe.u32 %r510, %r513, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r512, %r513, 8, 8;
	// end inline asm
	st.local.u8 	[%rd29], %r510;
	st.local.u8 	[%rd30], %r512;
	add.s32 	%r517, %r1711, 56;
	// begin inline asm
	bfe.u32 %r514, %r517, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r516, %r517, 8, 8;
	// end inline asm
	st.local.u8 	[%rd31], %r514;
	st.local.u8 	[%rd32], %r516;
	add.s32 	%r521, %r1711, 57;
	// begin inline asm
	bfe.u32 %r518, %r521, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r520, %r521, 8, 8;
	// end inline asm
	st.local.u8 	[%rd33], %r518;
	st.local.u8 	[%rd34], %r520;
	add.s32 	%r525, %r1711, 58;
	// begin inline asm
	bfe.u32 %r522, %r525, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r524, %r525, 8, 8;
	// end inline asm
	st.local.u8 	[%rd35], %r522;
	st.local.u8 	[%rd36], %r524;
	add.s32 	%r529, %r1711, 59;
	// begin inline asm
	bfe.u32 %r526, %r529, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r528, %r529, 8, 8;
	// end inline asm
	st.local.u8 	[%rd37], %r526;
	st.local.u8 	[%rd38], %r528;
	add.s32 	%r533, %r1711, 60;
	// begin inline asm
	bfe.u32 %r530, %r533, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r532, %r533, 8, 8;
	// end inline asm
	st.local.u8 	[%rd39], %r530;
	st.local.u8 	[%rd40], %r532;
	add.s32 	%r537, %r1711, 61;
	// begin inline asm
	bfe.u32 %r534, %r537, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r536, %r537, 8, 8;
	// end inline asm
	st.local.u8 	[%rd41], %r534;
	st.local.u8 	[%rd42], %r536;
	add.s32 	%r541, %r1711, 62;
	// begin inline asm
	bfe.u32 %r538, %r541, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r540, %r541, 8, 8;
	// end inline asm
	st.local.u8 	[%rd43], %r538;
	st.local.u8 	[%rd44], %r540;
	add.s32 	%r545, %r1711, 63;
	// begin inline asm
	bfe.u32 %r542, %r545, 0, 8;
	// end inline asm
	// begin inline asm
	bfe.u32 %r544, %r545, 8, 8;
	// end inline asm
	st.local.u8 	[%rd45], %r542;
	st.local.u8 	[%rd46], %r544;
	add.s32 	%r1711, %r1711, 64;
	mov.u32 	%r1720, %r168;
	mov.u32 	%r1721, %r168;

$L__BB1_9:
	mul.wide.s32 	%rd284, %r1720, 4;
	add.s64 	%rd285, %rd2, %rd284;
	ld.local.v4.u32 	{%r1743, %r1744, %r1745, %r1746}, [%rd285];
	ld.local.v4.u32 	{%r1747, %r1748, %r1749, %r1750}, [%rd285+16];
	ld.local.v4.u32 	{%r1751, %r1752, %r1753, %r1754}, [%rd285+32];
	ld.local.v4.u32 	{%r1734, %r1733, %r1732, %r1731}, [%rd285+48];
	shf.l.wrap.b32 	%r742, %r1725, %r1725, 26;
	shf.l.wrap.b32 	%r743, %r1725, %r1725, 21;
	xor.b32  	%r744, %r742, %r743;
	shf.l.wrap.b32 	%r745, %r1725, %r1725, 7;
	xor.b32  	%r746, %r744, %r745;
	xor.b32  	%r747, %r1723, %r1724;
	and.b32  	%r748, %r747, %r1725;
	xor.b32  	%r749, %r748, %r1723;
	add.s32 	%r750, %r1722, %r746;
	add.s32 	%r751, %r750, %r749;
	add.s32 	%r752, %r751, %r1743;
	add.s32 	%r753, %r752, 1116352408;
	add.s32 	%r754, %r753, %r1726;
	shf.l.wrap.b32 	%r755, %r1729, %r1729, 30;
	shf.l.wrap.b32 	%r756, %r1729, %r1729, 19;
	xor.b32  	%r757, %r755, %r756;
	shf.l.wrap.b32 	%r758, %r1729, %r1729, 10;
	xor.b32  	%r759, %r757, %r758;
	xor.b32  	%r760, %r1728, %r1729;
	and.b32  	%r761, %r1727, %r760;
	and.b32  	%r762, %r1728, %r1729;
	or.b32  	%r763, %r761, %r762;
	add.s32 	%r764, %r763, %r759;
	add.s32 	%r765, %r764, %r753;
	add.s32 	%r766, %r1723, %r1744;
	xor.b32  	%r767, %r1724, %r1725;
	and.b32  	%r768, %r754, %r767;
	xor.b32  	%r769, %r768, %r1724;
	add.s32 	%r770, %r766, %r769;
	shf.l.wrap.b32 	%r771, %r754, %r754, 26;
	shf.l.wrap.b32 	%r772, %r754, %r754, 21;
	xor.b32  	%r773, %r771, %r772;
	shf.l.wrap.b32 	%r774, %r754, %r754, 7;
	xor.b32  	%r775, %r773, %r774;
	add.s32 	%r776, %r770, %r775;
	add.s32 	%r777, %r776, 1899447441;
	add.s32 	%r778, %r777, %r1727;
	shf.l.wrap.b32 	%r779, %r765, %r765, 30;
	shf.l.wrap.b32 	%r780, %r765, %r765, 19;
	xor.b32  	%r781, %r779, %r780;
	shf.l.wrap.b32 	%r782, %r765, %r765, 10;
	xor.b32  	%r783, %r781, %r782;
	and.b32  	%r784, %r765, %r1729;
	xor.b32  	%r785, %r765, %r1729;
	and.b32  	%r786, %r785, %r1728;
	or.b32  	%r787, %r786, %r784;
	add.s32 	%r788, %r783, %r787;
	add.s32 	%r789, %r788, %r777;
	add.s32 	%r790, %r1724, %r1745;
	xor.b32  	%r791, %r754, %r1725;
	and.b32  	%r792, %r778, %r791;
	xor.b32  	%r793, %r792, %r1725;
	add.s32 	%r794, %r790, %r793;
	shf.l.wrap.b32 	%r795, %r778, %r778, 26;
	shf.l.wrap.b32 	%r796, %r778, %r778, 21;
	xor.b32  	%r797, %r795, %r796;
	shf.l.wrap.b32 	%r798, %r778, %r778, 7;
	xor.b32  	%r799, %r797, %r798;
	add.s32 	%r800, %r794, %r799;
	add.s32 	%r801, %r800, -1245643825;
	add.s32 	%r802, %r801, %r1728;
	shf.l.wrap.b32 	%r803, %r789, %r789, 30;
	shf.l.wrap.b32 	%r804, %r789, %r789, 19;
	xor.b32  	%r805, %r803, %r804;
	shf.l.wrap.b32 	%r806, %r789, %r789, 10;
	xor.b32  	%r807, %r805, %r806;
	and.b32  	%r808, %r789, %r765;
	xor.b32  	%r809, %r789, %r765;
	and.b32  	%r810, %r809, %r1729;
	or.b32  	%r811, %r810, %r808;
	add.s32 	%r812, %r807, %r811;
	add.s32 	%r813, %r812, %r801;
	add.s32 	%r814, %r1725, %r1746;
	xor.b32  	%r815, %r778, %r754;
	and.b32  	%r816, %r802, %r815;
	xor.b32  	%r817, %r816, %r754;
	add.s32 	%r818, %r814, %r817;
	shf.l.wrap.b32 	%r819, %r802, %r802, 26;
	shf.l.wrap.b32 	%r820, %r802, %r802, 21;
	xor.b32  	%r821, %r819, %r820;
	shf.l.wrap.b32 	%r822, %r802, %r802, 7;
	xor.b32  	%r823, %r821, %r822;
	add.s32 	%r824, %r818, %r823;
	add.s32 	%r825, %r824, -373957723;
	add.s32 	%r826, %r825, %r1729;
	shf.l.wrap.b32 	%r827, %r813, %r813, 30;
	shf.l.wrap.b32 	%r828, %r813, %r813, 19;
	xor.b32  	%r829, %r827, %r828;
	shf.l.wrap.b32 	%r830, %r813, %r813, 10;
	xor.b32  	%r831, %r829, %r830;
	and.b32  	%r832, %r813, %r789;
	xor.b32  	%r833, %r813, %r789;
	and.b32  	%r834, %r833, %r765;
	or.b32  	%r835, %r834, %r832;
	add.s32 	%r836, %r831, %r835;
	add.s32 	%r837, %r836, %r825;
	add.s32 	%r838, %r754, %r1747;
	xor.b32  	%r839, %r802, %r778;
	and.b32  	%r840, %r826, %r839;
	xor.b32  	%r841, %r840, %r778;
	add.s32 	%r842, %r838, %r841;
	shf.l.wrap.b32 	%r843, %r826, %r826, 26;
	shf.l.wrap.b32 	%r844, %r826, %r826, 21;
	xor.b32  	%r845, %r843, %r844;
	shf.l.wrap.b32 	%r846, %r826, %r826, 7;
	xor.b32  	%r847, %r845, %r846;
	add.s32 	%r848, %r842, %r847;
	add.s32 	%r849, %r848, 961987163;
	add.s32 	%r850, %r849, %r765;
	shf.l.wrap.b32 	%r851, %r837, %r837, 30;
	shf.l.wrap.b32 	%r852, %r837, %r837, 19;
	xor.b32  	%r853, %r851, %r852;
	shf.l.wrap.b32 	%r854, %r837, %r837, 10;
	xor.b32  	%r855, %r853, %r854;
	and.b32  	%r856, %r837, %r813;
	xor.b32  	%r857, %r837, %r813;
	and.b32  	%r858, %r857, %r789;
	or.b32  	%r859, %r858, %r856;
	add.s32 	%r860, %r855, %r859;
	add.s32 	%r861, %r860, %r849;
	shf.l.wrap.b32 	%r862, %r850, %r850, 26;
	shf.l.wrap.b32 	%r863, %r850, %r850, 21;
	xor.b32  	%r864, %r862, %r863;
	shf.l.wrap.b32 	%r865, %r850, %r850, 7;
	xor.b32  	%r866, %r864, %r865;
	xor.b32  	%r867, %r826, %r802;
	and.b32  	%r868, %r850, %r867;
	xor.b32  	%r869, %r868, %r802;
	add.s32 	%r870, %r1748, %r778;
	add.s32 	%r871, %r870, %r869;
	add.s32 	%r872, %r871, %r866;
	add.s32 	%r873, %r872, 1508970993;
	add.s32 	%r874, %r873, %r789;
	shf.l.wrap.b32 	%r875, %r861, %r861, 30;
	shf.l.wrap.b32 	%r876, %r861, %r861, 19;
	xor.b32  	%r877, %r875, %r876;
	shf.l.wrap.b32 	%r878, %r861, %r861, 10;
	xor.b32  	%r879, %r877, %r878;
	and.b32  	%r880, %r861, %r837;
	xor.b32  	%r881, %r861, %r837;
	and.b32  	%r882, %r881, %r813;
	or.b32  	%r883, %r882, %r880;
	add.s32 	%r884, %r879, %r883;
	add.s32 	%r885, %r884, %r873;
	shf.l.wrap.b32 	%r886, %r874, %r874, 26;
	shf.l.wrap.b32 	%r887, %r874, %r874, 21;
	xor.b32  	%r888, %r886, %r887;
	shf.l.wrap.b32 	%r889, %r874, %r874, 7;
	xor.b32  	%r890, %r888, %r889;
	xor.b32  	%r891, %r850, %r826;
	and.b32  	%r892, %r874, %r891;
	xor.b32  	%r893, %r892, %r826;
	add.s32 	%r894, %r1749, %r802;
	add.s32 	%r895, %r894, %r893;
	add.s32 	%r896, %r895, %r890;
	add.s32 	%r897, %r896, -1841331548;
	add.s32 	%r898, %r897, %r813;
	shf.l.wrap.b32 	%r899, %r885, %r885, 30;
	shf.l.wrap.b32 	%r900, %r885, %r885, 19;
	xor.b32  	%r901, %r899, %r900;
	shf.l.wrap.b32 	%r902, %r885, %r885, 10;
	xor.b32  	%r903, %r901, %r902;
	and.b32  	%r904, %r885, %r861;
	xor.b32  	%r905, %r885, %r861;
	and.b32  	%r906, %r905, %r837;
	or.b32  	%r907, %r906, %r904;
	add.s32 	%r908, %r903, %r907;
	add.s32 	%r909, %r908, %r897;
	shf.l.wrap.b32 	%r910, %r898, %r898, 26;
	shf.l.wrap.b32 	%r911, %r898, %r898, 21;
	xor.b32  	%r912, %r910, %r911;
	shf.l.wrap.b32 	%r913, %r898, %r898, 7;
	xor.b32  	%r914, %r912, %r913;
	xor.b32  	%r915, %r874, %r850;
	and.b32  	%r916, %r898, %r915;
	xor.b32  	%r917, %r916, %r850;
	add.s32 	%r918, %r1750, %r826;
	add.s32 	%r919, %r918, %r917;
	add.s32 	%r920, %r919, %r914;
	add.s32 	%r921, %r920, -1424204075;
	add.s32 	%r922, %r921, %r837;
	shf.l.wrap.b32 	%r923, %r909, %r909, 30;
	shf.l.wrap.b32 	%r924, %r909, %r909, 19;
	xor.b32  	%r925, %r923, %r924;
	shf.l.wrap.b32 	%r926, %r909, %r909, 10;
	xor.b32  	%r927, %r925, %r926;
	and.b32  	%r928, %r909, %r885;
	xor.b32  	%r929, %r909, %r885;
	and.b32  	%r930, %r929, %r861;
	or.b32  	%r931, %r930, %r928;
	add.s32 	%r932, %r927, %r931;
	add.s32 	%r933, %r932, %r921;
	shf.l.wrap.b32 	%r934, %r922, %r922, 26;
	shf.l.wrap.b32 	%r935, %r922, %r922, 21;
	xor.b32  	%r936, %r934, %r935;
	shf.l.wrap.b32 	%r937, %r922, %r922, 7;
	xor.b32  	%r938, %r936, %r937;
	xor.b32  	%r939, %r898, %r874;
	and.b32  	%r940, %r922, %r939;
	xor.b32  	%r941, %r940, %r874;
	add.s32 	%r942, %r1751, %r850;
	add.s32 	%r943, %r942, %r941;
	add.s32 	%r944, %r943, %r938;
	add.s32 	%r945, %r944, -670586216;
	add.s32 	%r946, %r945, %r861;
	shf.l.wrap.b32 	%r947, %r933, %r933, 30;
	shf.l.wrap.b32 	%r948, %r933, %r933, 19;
	xor.b32  	%r949, %r947, %r948;
	shf.l.wrap.b32 	%r950, %r933, %r933, 10;
	xor.b32  	%r951, %r949, %r950;
	and.b32  	%r952, %r933, %r909;
	xor.b32  	%r953, %r933, %r909;
	and.b32  	%r954, %r953, %r885;
	or.b32  	%r955, %r954, %r952;
	add.s32 	%r956, %r951, %r955;
	add.s32 	%r957, %r956, %r945;
	shf.l.wrap.b32 	%r958, %r946, %r946, 26;
	shf.l.wrap.b32 	%r959, %r946, %r946, 21;
	xor.b32  	%r960, %r958, %r959;
	shf.l.wrap.b32 	%r961, %r946, %r946, 7;
	xor.b32  	%r962, %r960, %r961;
	xor.b32  	%r963, %r922, %r898;
	and.b32  	%r964, %r946, %r963;
	xor.b32  	%r965, %r964, %r898;
	add.s32 	%r966, %r1752, %r874;
	add.s32 	%r967, %r966, %r965;
	add.s32 	%r968, %r967, %r962;
	add.s32 	%r969, %r968, 310598401;
	add.s32 	%r970, %r969, %r885;
	shf.l.wrap.b32 	%r971, %r957, %r957, 30;
	shf.l.wrap.b32 	%r972, %r957, %r957, 19;
	xor.b32  	%r973, %r971, %r972;
	shf.l.wrap.b32 	%r974, %r957, %r957, 10;
	xor.b32  	%r975, %r973, %r974;
	and.b32  	%r976, %r957, %r933;
	xor.b32  	%r977, %r957, %r933;
	and.b32  	%r978, %r977, %r909;
	or.b32  	%r979, %r978, %r976;
	add.s32 	%r980, %r975, %r979;
	add.s32 	%r981, %r980, %r969;
	shf.l.wrap.b32 	%r982, %r970, %r970, 26;
	shf.l.wrap.b32 	%r983, %r970, %r970, 21;
	xor.b32  	%r984, %r982, %r983;
	shf.l.wrap.b32 	%r985, %r970, %r970, 7;
	xor.b32  	%r986, %r984, %r985;
	xor.b32  	%r987, %r946, %r922;
	and.b32  	%r988, %r970, %r987;
	xor.b32  	%r989, %r988, %r922;
	add.s32 	%r990, %r1753, %r898;
	add.s32 	%r991, %r990, %r989;
	add.s32 	%r992, %r991, %r986;
	add.s32 	%r993, %r992, 607225278;
	add.s32 	%r994, %r993, %r909;
	shf.l.wrap.b32 	%r995, %r981, %r981, 30;
	shf.l.wrap.b32 	%r996, %r981, %r981, 19;
	xor.b32  	%r997, %r995, %r996;
	shf.l.wrap.b32 	%r998, %r981, %r981, 10;
	xor.b32  	%r999, %r997, %r998;
	and.b32  	%r1000, %r981, %r957;
	xor.b32  	%r1001, %r981, %r957;
	and.b32  	%r1002, %r1001, %r933;
	or.b32  	%r1003, %r1002, %r1000;
	add.s32 	%r1004, %r999, %r1003;
	add.s32 	%r1005, %r1004, %r993;
	shf.l.wrap.b32 	%r1006, %r994, %r994, 26;
	shf.l.wrap.b32 	%r1007, %r994, %r994, 21;
	xor.b32  	%r1008, %r1006, %r1007;
	shf.l.wrap.b32 	%r1009, %r994, %r994, 7;
	xor.b32  	%r1010, %r1008, %r1009;
	xor.b32  	%r1011, %r970, %r946;
	and.b32  	%r1012, %r994, %r1011;
	xor.b32  	%r1013, %r1012, %r946;
	add.s32 	%r1014, %r1754, %r922;
	add.s32 	%r1015, %r1014, %r1013;
	add.s32 	%r1016, %r1015, %r1010;
	add.s32 	%r1017, %r1016, 1426881987;
	add.s32 	%r1018, %r1017, %r933;
	shf.l.wrap.b32 	%r1019, %r1005, %r1005, 30;
	shf.l.wrap.b32 	%r1020, %r1005, %r1005, 19;
	xor.b32  	%r1021, %r1019, %r1020;
	shf.l.wrap.b32 	%r1022, %r1005, %r1005, 10;
	xor.b32  	%r1023, %r1021, %r1022;
	and.b32  	%r1024, %r1005, %r981;
	xor.b32  	%r1025, %r1005, %r981;
	and.b32  	%r1026, %r1025, %r957;
	or.b32  	%r1027, %r1026, %r1024;
	add.s32 	%r1028, %r1023, %r1027;
	add.s32 	%r1029, %r1028, %r1017;
	shf.l.wrap.b32 	%r1030, %r1018, %r1018, 26;
	shf.l.wrap.b32 	%r1031, %r1018, %r1018, 21;
	xor.b32  	%r1032, %r1030, %r1031;
	shf.l.wrap.b32 	%r1033, %r1018, %r1018, 7;
	xor.b32  	%r1034, %r1032, %r1033;
	xor.b32  	%r1035, %r994, %r970;
	and.b32  	%r1036, %r1018, %r1035;
	xor.b32  	%r1037, %r1036, %r970;
	add.s32 	%r1038, %r1734, %r946;
	add.s32 	%r1039, %r1038, %r1037;
	add.s32 	%r1040, %r1039, %r1034;
	add.s32 	%r1041, %r1040, 1925078388;
	add.s32 	%r1742, %r1041, %r957;
	shf.l.wrap.b32 	%r1042, %r1029, %r1029, 30;
	shf.l.wrap.b32 	%r1043, %r1029, %r1029, 19;
	xor.b32  	%r1044, %r1042, %r1043;
	shf.l.wrap.b32 	%r1045, %r1029, %r1029, 10;
	xor.b32  	%r1046, %r1044, %r1045;
	and.b32  	%r1047, %r1029, %r1005;
	xor.b32  	%r1048, %r1029, %r1005;
	and.b32  	%r1049, %r1048, %r981;
	or.b32  	%r1050, %r1049, %r1047;
	add.s32 	%r1051, %r1046, %r1050;
	add.s32 	%r1738, %r1051, %r1041;
	shf.l.wrap.b32 	%r1052, %r1742, %r1742, 26;
	shf.l.wrap.b32 	%r1053, %r1742, %r1742, 21;
	xor.b32  	%r1054, %r1052, %r1053;
	shf.l.wrap.b32 	%r1055, %r1742, %r1742, 7;
	xor.b32  	%r1056, %r1054, %r1055;
	xor.b32  	%r1057, %r1018, %r994;
	and.b32  	%r1058, %r1742, %r1057;
	xor.b32  	%r1059, %r1058, %r994;
	add.s32 	%r1060, %r1733, %r970;
	add.s32 	%r1061, %r1060, %r1059;
	add.s32 	%r1062, %r1061, %r1056;
	add.s32 	%r1063, %r1062, -2132889090;
	add.s32 	%r1741, %r1063, %r981;
	shf.l.wrap.b32 	%r1064, %r1738, %r1738, 30;
	shf.l.wrap.b32 	%r1065, %r1738, %r1738, 19;
	xor.b32  	%r1066, %r1064, %r1065;
	shf.l.wrap.b32 	%r1067, %r1738, %r1738, 10;
	xor.b32  	%r1068, %r1066, %r1067;
	and.b32  	%r1069, %r1738, %r1029;
	xor.b32  	%r1070, %r1738, %r1029;
	and.b32  	%r1071, %r1070, %r1005;
	or.b32  	%r1072, %r1071, %r1069;
	add.s32 	%r1073, %r1068, %r1072;
	add.s32 	%r1737, %r1073, %r1063;
	shf.l.wrap.b32 	%r1074, %r1741, %r1741, 26;
	shf.l.wrap.b32 	%r1075, %r1741, %r1741, 21;
	xor.b32  	%r1076, %r1074, %r1075;
	shf.l.wrap.b32 	%r1077, %r1741, %r1741, 7;
	xor.b32  	%r1078, %r1076, %r1077;
	xor.b32  	%r1079, %r1742, %r1018;
	and.b32  	%r1080, %r1741, %r1079;
	xor.b32  	%r1081, %r1080, %r1018;
	add.s32 	%r1082, %r1732, %r994;
	add.s32 	%r1083, %r1082, %r1081;
	add.s32 	%r1084, %r1083, %r1078;
	add.s32 	%r1085, %r1084, -1680079193;
	add.s32 	%r1740, %r1085, %r1005;
	shf.l.wrap.b32 	%r1086, %r1737, %r1737, 30;
	shf.l.wrap.b32 	%r1087, %r1737, %r1737, 19;
	xor.b32  	%r1088, %r1086, %r1087;
	shf.l.wrap.b32 	%r1089, %r1737, %r1737, 10;
	xor.b32  	%r1090, %r1088, %r1089;
	and.b32  	%r1091, %r1737, %r1738;
	xor.b32  	%r1092, %r1737, %r1738;
	and.b32  	%r1093, %r1092, %r1029;
	or.b32  	%r1094, %r1093, %r1091;
	add.s32 	%r1095, %r1090, %r1094;
	add.s32 	%r1736, %r1095, %r1085;
	shf.l.wrap.b32 	%r1096, %r1740, %r1740, 26;
	shf.l.wrap.b32 	%r1097, %r1740, %r1740, 21;
	xor.b32  	%r1098, %r1096, %r1097;
	shf.l.wrap.b32 	%r1099, %r1740, %r1740, 7;
	xor.b32  	%r1100, %r1098, %r1099;
	xor.b32  	%r1101, %r1741, %r1742;
	and.b32  	%r1102, %r1740, %r1101;
	xor.b32  	%r1103, %r1102, %r1742;
	add.s32 	%r1104, %r1731, %r1018;
	add.s32 	%r1105, %r1104, %r1103;
	add.s32 	%r1106, %r1105, %r1100;
	add.s32 	%r1107, %r1106, -1046744716;
	add.s32 	%r1739, %r1107, %r1029;
	shf.l.wrap.b32 	%r1108, %r1736, %r1736, 30;
	shf.l.wrap.b32 	%r1109, %r1736, %r1736, 19;
	xor.b32  	%r1110, %r1108, %r1109;
	shf.l.wrap.b32 	%r1111, %r1736, %r1736, 10;
	xor.b32  	%r1112, %r1110, %r1111;
	and.b32  	%r1113, %r1736, %r1737;
	xor.b32  	%r1114, %r1736, %r1737;
	and.b32  	%r1115, %r1114, %r1738;
	or.b32  	%r1116, %r1115, %r1113;
	add.s32 	%r1117, %r1112, %r1116;
	add.s32 	%r1735, %r1117, %r1107;
	mov.u32 	%r1730, 16;

$L__BB1_10:
	shf.l.wrap.b32 	%r1118, %r1732, %r1732, 15;
	shf.l.wrap.b32 	%r1119, %r1732, %r1732, 13;
	shr.u32 	%r1120, %r1732, 10;
	xor.b32  	%r1121, %r1119, %r1120;
	xor.b32  	%r1122, %r1121, %r1118;
	shf.l.wrap.b32 	%r1123, %r1744, %r1744, 25;
	shf.l.wrap.b32 	%r1124, %r1744, %r1744, 14;
	shr.u32 	%r1125, %r1744, 3;
	xor.b32  	%r1126, %r1124, %r1125;
	xor.b32  	%r1127, %r1126, %r1123;
	add.s32 	%r1128, %r1743, %r1752;
	add.s32 	%r1129, %r1128, %r1127;
	add.s32 	%r1743, %r1129, %r1122;
	shf.l.wrap.b32 	%r1130, %r1731, %r1731, 15;
	shf.l.wrap.b32 	%r1131, %r1731, %r1731, 13;
	shr.u32 	%r1132, %r1731, 10;
	xor.b32  	%r1133, %r1131, %r1132;
	xor.b32  	%r1134, %r1133, %r1130;
	shf.l.wrap.b32 	%r1135, %r1745, %r1745, 25;
	shf.l.wrap.b32 	%r1136, %r1745, %r1745, 14;
	shr.u32 	%r1137, %r1745, 3;
	xor.b32  	%r1138, %r1136, %r1137;
	xor.b32  	%r1139, %r1138, %r1135;
	add.s32 	%r1140, %r1744, %r1753;
	add.s32 	%r1141, %r1140, %r1139;
	add.s32 	%r1744, %r1141, %r1134;
	shf.l.wrap.b32 	%r1142, %r1743, %r1743, 15;
	shf.l.wrap.b32 	%r1143, %r1743, %r1743, 13;
	shr.u32 	%r1144, %r1743, 10;
	xor.b32  	%r1145, %r1143, %r1144;
	xor.b32  	%r1146, %r1145, %r1142;
	shf.l.wrap.b32 	%r1147, %r1746, %r1746, 25;
	shf.l.wrap.b32 	%r1148, %r1746, %r1746, 14;
	shr.u32 	%r1149, %r1746, 3;
	xor.b32  	%r1150, %r1148, %r1149;
	xor.b32  	%r1151, %r1150, %r1147;
	add.s32 	%r1152, %r1745, %r1754;
	add.s32 	%r1153, %r1152, %r1151;
	add.s32 	%r1745, %r1153, %r1146;
	shf.l.wrap.b32 	%r1154, %r1744, %r1744, 15;
	shf.l.wrap.b32 	%r1155, %r1744, %r1744, 13;
	shr.u32 	%r1156, %r1744, 10;
	xor.b32  	%r1157, %r1155, %r1156;
	xor.b32  	%r1158, %r1157, %r1154;
	shf.l.wrap.b32 	%r1159, %r1747, %r1747, 25;
	shf.l.wrap.b32 	%r1160, %r1747, %r1747, 14;
	shr.u32 	%r1161, %r1747, 3;
	xor.b32  	%r1162, %r1160, %r1161;
	xor.b32  	%r1163, %r1162, %r1159;
	add.s32 	%r1164, %r1163, %r1746;
	add.s32 	%r1165, %r1164, %r1734;
	add.s32 	%r1746, %r1165, %r1158;
	shf.l.wrap.b32 	%r1166, %r1745, %r1745, 15;
	shf.l.wrap.b32 	%r1167, %r1745, %r1745, 13;
	shr.u32 	%r1168, %r1745, 10;
	xor.b32  	%r1169, %r1167, %r1168;
	xor.b32  	%r1170, %r1169, %r1166;
	shf.l.wrap.b32 	%r1171, %r1748, %r1748, 25;
	shf.l.wrap.b32 	%r1172, %r1748, %r1748, 14;
	shr.u32 	%r1173, %r1748, 3;
	xor.b32  	%r1174, %r1172, %r1173;
	xor.b32  	%r1175, %r1174, %r1171;
	add.s32 	%r1176, %r1175, %r1747;
	add.s32 	%r1177, %r1176, %r1733;
	add.s32 	%r1747, %r1177, %r1170;
	shf.l.wrap.b32 	%r1178, %r1746, %r1746, 15;
	shf.l.wrap.b32 	%r1179, %r1746, %r1746, 13;
	shr.u32 	%r1180, %r1746, 10;
	xor.b32  	%r1181, %r1179, %r1180;
	xor.b32  	%r1182, %r1181, %r1178;
	shf.l.wrap.b32 	%r1183, %r1749, %r1749, 25;
	shf.l.wrap.b32 	%r1184, %r1749, %r1749, 14;
	shr.u32 	%r1185, %r1749, 3;
	xor.b32  	%r1186, %r1184, %r1185;
	xor.b32  	%r1187, %r1186, %r1183;
	add.s32 	%r1188, %r1187, %r1748;
	add.s32 	%r1189, %r1188, %r1732;
	add.s32 	%r1748, %r1189, %r1182;
	shf.l.wrap.b32 	%r1190, %r1747, %r1747, 15;
	shf.l.wrap.b32 	%r1191, %r1747, %r1747, 13;
	shr.u32 	%r1192, %r1747, 10;
	xor.b32  	%r1193, %r1191, %r1192;
	xor.b32  	%r1194, %r1193, %r1190;
	shf.l.wrap.b32 	%r1195, %r1750, %r1750, 25;
	shf.l.wrap.b32 	%r1196, %r1750, %r1750, 14;
	shr.u32 	%r1197, %r1750, 3;
	xor.b32  	%r1198, %r1196, %r1197;
	xor.b32  	%r1199, %r1198, %r1195;
	add.s32 	%r1200, %r1199, %r1749;
	add.s32 	%r1201, %r1200, %r1731;
	add.s32 	%r1749, %r1201, %r1194;
	shf.l.wrap.b32 	%r1202, %r1748, %r1748, 15;
	shf.l.wrap.b32 	%r1203, %r1748, %r1748, 13;
	shr.u32 	%r1204, %r1748, 10;
	xor.b32  	%r1205, %r1203, %r1204;
	xor.b32  	%r1206, %r1205, %r1202;
	shf.l.wrap.b32 	%r1207, %r1751, %r1751, 25;
	shf.l.wrap.b32 	%r1208, %r1751, %r1751, 14;
	shr.u32 	%r1209, %r1751, 3;
	xor.b32  	%r1210, %r1208, %r1209;
	xor.b32  	%r1211, %r1210, %r1207;
	add.s32 	%r1212, %r1211, %r1750;
	add.s32 	%r1213, %r1212, %r1743;
	add.s32 	%r1750, %r1213, %r1206;
	shf.l.wrap.b32 	%r1214, %r1749, %r1749, 15;
	shf.l.wrap.b32 	%r1215, %r1749, %r1749, 13;
	shr.u32 	%r1216, %r1749, 10;
	xor.b32  	%r1217, %r1215, %r1216;
	xor.b32  	%r1218, %r1217, %r1214;
	shf.l.wrap.b32 	%r1219, %r1752, %r1752, 25;
	shf.l.wrap.b32 	%r1220, %r1752, %r1752, 14;
	shr.u32 	%r1221, %r1752, 3;
	xor.b32  	%r1222, %r1220, %r1221;
	xor.b32  	%r1223, %r1222, %r1219;
	add.s32 	%r1224, %r1223, %r1751;
	add.s32 	%r1225, %r1224, %r1744;
	add.s32 	%r1751, %r1225, %r1218;
	shf.l.wrap.b32 	%r1226, %r1750, %r1750, 15;
	shf.l.wrap.b32 	%r1227, %r1750, %r1750, 13;
	shr.u32 	%r1228, %r1750, 10;
	xor.b32  	%r1229, %r1227, %r1228;
	xor.b32  	%r1230, %r1229, %r1226;
	shf.l.wrap.b32 	%r1231, %r1753, %r1753, 25;
	shf.l.wrap.b32 	%r1232, %r1753, %r1753, 14;
	shr.u32 	%r1233, %r1753, 3;
	xor.b32  	%r1234, %r1232, %r1233;
	xor.b32  	%r1235, %r1234, %r1231;
	add.s32 	%r1236, %r1235, %r1752;
	add.s32 	%r1237, %r1236, %r1745;
	add.s32 	%r1752, %r1237, %r1230;
	shf.l.wrap.b32 	%r1238, %r1751, %r1751, 15;
	shf.l.wrap.b32 	%r1239, %r1751, %r1751, 13;
	shr.u32 	%r1240, %r1751, 10;
	xor.b32  	%r1241, %r1239, %r1240;
	xor.b32  	%r1242, %r1241, %r1238;
	shf.l.wrap.b32 	%r1243, %r1754, %r1754, 25;
	shf.l.wrap.b32 	%r1244, %r1754, %r1754, 14;
	shr.u32 	%r1245, %r1754, 3;
	xor.b32  	%r1246, %r1244, %r1245;
	xor.b32  	%r1247, %r1246, %r1243;
	add.s32 	%r1248, %r1247, %r1753;
	add.s32 	%r1249, %r1248, %r1746;
	add.s32 	%r1753, %r1249, %r1242;
	shf.l.wrap.b32 	%r1250, %r1752, %r1752, 15;
	shf.l.wrap.b32 	%r1251, %r1752, %r1752, 13;
	shr.u32 	%r1252, %r1752, 10;
	xor.b32  	%r1253, %r1251, %r1252;
	xor.b32  	%r1254, %r1253, %r1250;
	shf.l.wrap.b32 	%r1255, %r1734, %r1734, 25;
	shf.l.wrap.b32 	%r1256, %r1734, %r1734, 14;
	shr.u32 	%r1257, %r1734, 3;
	xor.b32  	%r1258, %r1256, %r1257;
	xor.b32  	%r1259, %r1258, %r1255;
	add.s32 	%r1260, %r1259, %r1754;
	add.s32 	%r1261, %r1260, %r1747;
	add.s32 	%r1754, %r1261, %r1254;
	shf.l.wrap.b32 	%r1262, %r1753, %r1753, 15;
	shf.l.wrap.b32 	%r1263, %r1753, %r1753, 13;
	shr.u32 	%r1264, %r1753, 10;
	xor.b32  	%r1265, %r1263, %r1264;
	xor.b32  	%r1266, %r1265, %r1262;
	shf.l.wrap.b32 	%r1267, %r1733, %r1733, 25;
	shf.l.wrap.b32 	%r1268, %r1733, %r1733, 14;
	shr.u32 	%r1269, %r1733, 3;
	xor.b32  	%r1270, %r1268, %r1269;
	xor.b32  	%r1271, %r1270, %r1267;
	add.s32 	%r1272, %r1271, %r1734;
	add.s32 	%r1273, %r1272, %r1748;
	add.s32 	%r1734, %r1273, %r1266;
	shf.l.wrap.b32 	%r1274, %r1754, %r1754, 15;
	shf.l.wrap.b32 	%r1275, %r1754, %r1754, 13;
	shr.u32 	%r1276, %r1754, 10;
	xor.b32  	%r1277, %r1275, %r1276;
	xor.b32  	%r1278, %r1277, %r1274;
	shf.l.wrap.b32 	%r1279, %r1732, %r1732, 25;
	shf.l.wrap.b32 	%r1280, %r1732, %r1732, 14;
	shr.u32 	%r1281, %r1732, 3;
	xor.b32  	%r1282, %r1280, %r1281;
	xor.b32  	%r1283, %r1282, %r1279;
	add.s32 	%r1284, %r1283, %r1733;
	add.s32 	%r1285, %r1284, %r1749;
	add.s32 	%r1733, %r1285, %r1278;
	shf.l.wrap.b32 	%r1286, %r1734, %r1734, 15;
	shf.l.wrap.b32 	%r1287, %r1734, %r1734, 13;
	shr.u32 	%r1288, %r1734, 10;
	xor.b32  	%r1289, %r1287, %r1288;
	xor.b32  	%r1290, %r1289, %r1286;
	shf.l.wrap.b32 	%r1291, %r1731, %r1731, 25;
	shf.l.wrap.b32 	%r1292, %r1731, %r1731, 14;
	shr.u32 	%r1293, %r1731, 3;
	xor.b32  	%r1294, %r1292, %r1293;
	xor.b32  	%r1295, %r1294, %r1291;
	add.s32 	%r1296, %r1295, %r1732;
	add.s32 	%r1297, %r1296, %r1750;
	add.s32 	%r1732, %r1297, %r1290;
	shf.l.wrap.b32 	%r1298, %r1733, %r1733, 15;
	shf.l.wrap.b32 	%r1299, %r1733, %r1733, 13;
	shr.u32 	%r1300, %r1733, 10;
	xor.b32  	%r1301, %r1299, %r1300;
	xor.b32  	%r1302, %r1301, %r1298;
	shf.l.wrap.b32 	%r1303, %r1743, %r1743, 25;
	shf.l.wrap.b32 	%r1304, %r1743, %r1743, 14;
	shr.u32 	%r1305, %r1743, 3;
	xor.b32  	%r1306, %r1304, %r1305;
	xor.b32  	%r1307, %r1306, %r1303;
	add.s32 	%r1308, %r1307, %r1731;
	add.s32 	%r1309, %r1308, %r1751;
	add.s32 	%r1731, %r1309, %r1302;
	mul.wide.s32 	%rd286, %r1730, 4;
	mov.u64 	%rd287, k_sha256;
	add.s64 	%rd288, %rd287, %rd286;
	shf.l.wrap.b32 	%r1310, %r1739, %r1739, 26;
	shf.l.wrap.b32 	%r1311, %r1739, %r1739, 21;
	xor.b32  	%r1312, %r1310, %r1311;
	shf.l.wrap.b32 	%r1313, %r1739, %r1739, 7;
	xor.b32  	%r1314, %r1312, %r1313;
	xor.b32  	%r1315, %r1740, %r1741;
	and.b32  	%r1316, %r1739, %r1315;
	xor.b32  	%r1317, %r1316, %r1741;
	add.s32 	%r1318, %r1317, %r1742;
	add.s32 	%r1319, %r1318, %r1314;
	add.s32 	%r1320, %r1319, %r1743;
	ld.const.u32 	%r1321, [%rd288];
	add.s32 	%r1322, %r1320, %r1321;
	add.s32 	%r1323, %r1322, %r1738;
	shf.l.wrap.b32 	%r1324, %r1735, %r1735, 30;
	shf.l.wrap.b32 	%r1325, %r1735, %r1735, 19;
	xor.b32  	%r1326, %r1324, %r1325;
	shf.l.wrap.b32 	%r1327, %r1735, %r1735, 10;
	xor.b32  	%r1328, %r1326, %r1327;
	xor.b32  	%r1329, %r1735, %r1736;
	and.b32  	%r1330, %r1329, %r1737;
	and.b32  	%r1331, %r1735, %r1736;
	or.b32  	%r1332, %r1330, %r1331;
	add.s32 	%r1333, %r1328, %r1332;
	add.s32 	%r1334, %r1333, %r1322;
	shf.l.wrap.b32 	%r1335, %r1323, %r1323, 26;
	shf.l.wrap.b32 	%r1336, %r1323, %r1323, 21;
	xor.b32  	%r1337, %r1335, %r1336;
	shf.l.wrap.b32 	%r1338, %r1323, %r1323, 7;
	xor.b32  	%r1339, %r1337, %r1338;
	xor.b32  	%r1340, %r1739, %r1740;
	and.b32  	%r1341, %r1323, %r1340;
	xor.b32  	%r1342, %r1341, %r1740;
	add.s32 	%r1343, %r1744, %r1741;
	ld.const.u32 	%r1344, [%rd288+4];
	add.s32 	%r1345, %r1343, %r1344;
	add.s32 	%r1346, %r1345, %r1342;
	add.s32 	%r1347, %r1346, %r1339;
	add.s32 	%r1348, %r1347, %r1737;
	shf.l.wrap.b32 	%r1349, %r1334, %r1334, 30;
	shf.l.wrap.b32 	%r1350, %r1334, %r1334, 19;
	xor.b32  	%r1351, %r1349, %r1350;
	shf.l.wrap.b32 	%r1352, %r1334, %r1334, 10;
	xor.b32  	%r1353, %r1351, %r1352;
	and.b32  	%r1354, %r1334, %r1735;
	xor.b32  	%r1355, %r1334, %r1735;
	and.b32  	%r1356, %r1355, %r1736;
	or.b32  	%r1357, %r1356, %r1354;
	add.s32 	%r1358, %r1353, %r1357;
	add.s32 	%r1359, %r1358, %r1347;
	shf.l.wrap.b32 	%r1360, %r1348, %r1348, 26;
	shf.l.wrap.b32 	%r1361, %r1348, %r1348, 21;
	xor.b32  	%r1362, %r1360, %r1361;
	shf.l.wrap.b32 	%r1363, %r1348, %r1348, 7;
	xor.b32  	%r1364, %r1362, %r1363;
	xor.b32  	%r1365, %r1323, %r1739;
	and.b32  	%r1366, %r1348, %r1365;
	xor.b32  	%r1367, %r1366, %r1739;
	add.s32 	%r1368, %r1745, %r1740;
	ld.const.u32 	%r1369, [%rd288+8];
	add.s32 	%r1370, %r1368, %r1369;
	add.s32 	%r1371, %r1370, %r1367;
	add.s32 	%r1372, %r1371, %r1364;
	add.s32 	%r1373, %r1372, %r1736;
	shf.l.wrap.b32 	%r1374, %r1359, %r1359, 30;
	shf.l.wrap.b32 	%r1375, %r1359, %r1359, 19;
	xor.b32  	%r1376, %r1374, %r1375;
	shf.l.wrap.b32 	%r1377, %r1359, %r1359, 10;
	xor.b32  	%r1378, %r1376, %r1377;
	and.b32  	%r1379, %r1359, %r1334;
	xor.b32  	%r1380, %r1359, %r1334;
	and.b32  	%r1381, %r1380, %r1735;
	or.b32  	%r1382, %r1381, %r1379;
	add.s32 	%r1383, %r1378, %r1382;
	add.s32 	%r1384, %r1383, %r1372;
	shf.l.wrap.b32 	%r1385, %r1373, %r1373, 26;
	shf.l.wrap.b32 	%r1386, %r1373, %r1373, 21;
	xor.b32  	%r1387, %r1385, %r1386;
	shf.l.wrap.b32 	%r1388, %r1373, %r1373, 7;
	xor.b32  	%r1389, %r1387, %r1388;
	xor.b32  	%r1390, %r1348, %r1323;
	and.b32  	%r1391, %r1373, %r1390;
	xor.b32  	%r1392, %r1391, %r1323;
	add.s32 	%r1393, %r1746, %r1739;
	ld.const.u32 	%r1394, [%rd288+12];
	add.s32 	%r1395, %r1393, %r1394;
	add.s32 	%r1396, %r1395, %r1392;
	add.s32 	%r1397, %r1396, %r1389;
	add.s32 	%r1398, %r1397, %r1735;
	shf.l.wrap.b32 	%r1399, %r1384, %r1384, 30;
	shf.l.wrap.b32 	%r1400, %r1384, %r1384, 19;
	xor.b32  	%r1401, %r1399, %r1400;
	shf.l.wrap.b32 	%r1402, %r1384, %r1384, 10;
	xor.b32  	%r1403, %r1401, %r1402;
	and.b32  	%r1404, %r1384, %r1359;
	xor.b32  	%r1405, %r1384, %r1359;
	and.b32  	%r1406, %r1405, %r1334;
	or.b32  	%r1407, %r1406, %r1404;
	add.s32 	%r1408, %r1403, %r1407;
	add.s32 	%r1409, %r1408, %r1397;
	shf.l.wrap.b32 	%r1410, %r1398, %r1398, 26;
	shf.l.wrap.b32 	%r1411, %r1398, %r1398, 21;
	xor.b32  	%r1412, %r1410, %r1411;
	shf.l.wrap.b32 	%r1413, %r1398, %r1398, 7;
	xor.b32  	%r1414, %r1412, %r1413;
	xor.b32  	%r1415, %r1373, %r1348;
	and.b32  	%r1416, %r1398, %r1415;
	xor.b32  	%r1417, %r1416, %r1348;
	ld.const.u32 	%r1418, [%rd288+16];
	add.s32 	%r1419, %r1418, %r1747;
	add.s32 	%r1420, %r1419, %r1323;
	add.s32 	%r1421, %r1420, %r1417;
	add.s32 	%r1422, %r1421, %r1414;
	add.s32 	%r1423, %r1422, %r1334;
	shf.l.wrap.b32 	%r1424, %r1409, %r1409, 30;
	shf.l.wrap.b32 	%r1425, %r1409, %r1409, 19;
	xor.b32  	%r1426, %r1424, %r1425;
	shf.l.wrap.b32 	%r1427, %r1409, %r1409, 10;
	xor.b32  	%r1428, %r1426, %r1427;
	and.b32  	%r1429, %r1409, %r1384;
	xor.b32  	%r1430, %r1409, %r1384;
	and.b32  	%r1431, %r1430, %r1359;
	or.b32  	%r1432, %r1431, %r1429;
	add.s32 	%r1433, %r1428, %r1432;
	add.s32 	%r1434, %r1433, %r1422;
	shf.l.wrap.b32 	%r1435, %r1423, %r1423, 26;
	shf.l.wrap.b32 	%r1436, %r1423, %r1423, 21;
	xor.b32  	%r1437, %r1435, %r1436;
	shf.l.wrap.b32 	%r1438, %r1423, %r1423, 7;
	xor.b32  	%r1439, %r1437, %r1438;
	xor.b32  	%r1440, %r1398, %r1373;
	and.b32  	%r1441, %r1423, %r1440;
	xor.b32  	%r1442, %r1441, %r1373;
	ld.const.u32 	%r1443, [%rd288+20];
	add.s32 	%r1444, %r1443, %r1748;
	add.s32 	%r1445, %r1444, %r1348;
	add.s32 	%r1446, %r1445, %r1442;
	add.s32 	%r1447, %r1446, %r1439;
	add.s32 	%r1448, %r1447, %r1359;
	shf.l.wrap.b32 	%r1449, %r1434, %r1434, 30;
	shf.l.wrap.b32 	%r1450, %r1434, %r1434, 19;
	xor.b32  	%r1451, %r1449, %r1450;
	shf.l.wrap.b32 	%r1452, %r1434, %r1434, 10;
	xor.b32  	%r1453, %r1451, %r1452;
	and.b32  	%r1454, %r1434, %r1409;
	xor.b32  	%r1455, %r1434, %r1409;
	and.b32  	%r1456, %r1455, %r1384;
	or.b32  	%r1457, %r1456, %r1454;
	add.s32 	%r1458, %r1453, %r1457;
	add.s32 	%r1459, %r1458, %r1447;
	shf.l.wrap.b32 	%r1460, %r1448, %r1448, 26;
	shf.l.wrap.b32 	%r1461, %r1448, %r1448, 21;
	xor.b32  	%r1462, %r1460, %r1461;
	shf.l.wrap.b32 	%r1463, %r1448, %r1448, 7;
	xor.b32  	%r1464, %r1462, %r1463;
	xor.b32  	%r1465, %r1423, %r1398;
	and.b32  	%r1466, %r1448, %r1465;
	xor.b32  	%r1467, %r1466, %r1398;
	ld.const.u32 	%r1468, [%rd288+24];
	add.s32 	%r1469, %r1468, %r1749;
	add.s32 	%r1470, %r1469, %r1373;
	add.s32 	%r1471, %r1470, %r1467;
	add.s32 	%r1472, %r1471, %r1464;
	add.s32 	%r1473, %r1472, %r1384;
	shf.l.wrap.b32 	%r1474, %r1459, %r1459, 30;
	shf.l.wrap.b32 	%r1475, %r1459, %r1459, 19;
	xor.b32  	%r1476, %r1474, %r1475;
	shf.l.wrap.b32 	%r1477, %r1459, %r1459, 10;
	xor.b32  	%r1478, %r1476, %r1477;
	and.b32  	%r1479, %r1459, %r1434;
	xor.b32  	%r1480, %r1459, %r1434;
	and.b32  	%r1481, %r1480, %r1409;
	or.b32  	%r1482, %r1481, %r1479;
	add.s32 	%r1483, %r1478, %r1482;
	add.s32 	%r1484, %r1483, %r1472;
	shf.l.wrap.b32 	%r1485, %r1473, %r1473, 26;
	shf.l.wrap.b32 	%r1486, %r1473, %r1473, 21;
	xor.b32  	%r1487, %r1485, %r1486;
	shf.l.wrap.b32 	%r1488, %r1473, %r1473, 7;
	xor.b32  	%r1489, %r1487, %r1488;
	xor.b32  	%r1490, %r1448, %r1423;
	and.b32  	%r1491, %r1473, %r1490;
	xor.b32  	%r1492, %r1491, %r1423;
	ld.const.u32 	%r1493, [%rd288+28];
	add.s32 	%r1494, %r1493, %r1750;
	add.s32 	%r1495, %r1494, %r1398;
	add.s32 	%r1496, %r1495, %r1492;
	add.s32 	%r1497, %r1496, %r1489;
	add.s32 	%r1498, %r1497, %r1409;
	shf.l.wrap.b32 	%r1499, %r1484, %r1484, 30;
	shf.l.wrap.b32 	%r1500, %r1484, %r1484, 19;
	xor.b32  	%r1501, %r1499, %r1500;
	shf.l.wrap.b32 	%r1502, %r1484, %r1484, 10;
	xor.b32  	%r1503, %r1501, %r1502;
	and.b32  	%r1504, %r1484, %r1459;
	xor.b32  	%r1505, %r1484, %r1459;
	and.b32  	%r1506, %r1505, %r1434;
	or.b32  	%r1507, %r1506, %r1504;
	add.s32 	%r1508, %r1503, %r1507;
	add.s32 	%r1509, %r1508, %r1497;
	shf.l.wrap.b32 	%r1510, %r1498, %r1498, 26;
	shf.l.wrap.b32 	%r1511, %r1498, %r1498, 21;
	xor.b32  	%r1512, %r1510, %r1511;
	shf.l.wrap.b32 	%r1513, %r1498, %r1498, 7;
	xor.b32  	%r1514, %r1512, %r1513;
	xor.b32  	%r1515, %r1473, %r1448;
	and.b32  	%r1516, %r1498, %r1515;
	xor.b32  	%r1517, %r1516, %r1448;
	ld.const.u32 	%r1518, [%rd288+32];
	add.s32 	%r1519, %r1518, %r1751;
	add.s32 	%r1520, %r1519, %r1423;
	add.s32 	%r1521, %r1520, %r1517;
	add.s32 	%r1522, %r1521, %r1514;
	add.s32 	%r1523, %r1522, %r1434;
	shf.l.wrap.b32 	%r1524, %r1509, %r1509, 30;
	shf.l.wrap.b32 	%r1525, %r1509, %r1509, 19;
	xor.b32  	%r1526, %r1524, %r1525;
	shf.l.wrap.b32 	%r1527, %r1509, %r1509, 10;
	xor.b32  	%r1528, %r1526, %r1527;
	and.b32  	%r1529, %r1509, %r1484;
	xor.b32  	%r1530, %r1509, %r1484;
	and.b32  	%r1531, %r1530, %r1459;
	or.b32  	%r1532, %r1531, %r1529;
	add.s32 	%r1533, %r1528, %r1532;
	add.s32 	%r1534, %r1533, %r1522;
	shf.l.wrap.b32 	%r1535, %r1523, %r1523, 26;
	shf.l.wrap.b32 	%r1536, %r1523, %r1523, 21;
	xor.b32  	%r1537, %r1535, %r1536;
	shf.l.wrap.b32 	%r1538, %r1523, %r1523, 7;
	xor.b32  	%r1539, %r1537, %r1538;
	xor.b32  	%r1540, %r1498, %r1473;
	and.b32  	%r1541, %r1523, %r1540;
	xor.b32  	%r1542, %r1541, %r1473;
	ld.const.u32 	%r1543, [%rd288+36];
	add.s32 	%r1544, %r1543, %r1752;
	add.s32 	%r1545, %r1544, %r1448;
	add.s32 	%r1546, %r1545, %r1542;
	add.s32 	%r1547, %r1546, %r1539;
	add.s32 	%r1548, %r1547, %r1459;
	shf.l.wrap.b32 	%r1549, %r1534, %r1534, 30;
	shf.l.wrap.b32 	%r1550, %r1534, %r1534, 19;
	xor.b32  	%r1551, %r1549, %r1550;
	shf.l.wrap.b32 	%r1552, %r1534, %r1534, 10;
	xor.b32  	%r1553, %r1551, %r1552;
	and.b32  	%r1554, %r1534, %r1509;
	xor.b32  	%r1555, %r1534, %r1509;
	and.b32  	%r1556, %r1555, %r1484;
	or.b32  	%r1557, %r1556, %r1554;
	add.s32 	%r1558, %r1553, %r1557;
	add.s32 	%r1559, %r1558, %r1547;
	shf.l.wrap.b32 	%r1560, %r1548, %r1548, 26;
	shf.l.wrap.b32 	%r1561, %r1548, %r1548, 21;
	xor.b32  	%r1562, %r1560, %r1561;
	shf.l.wrap.b32 	%r1563, %r1548, %r1548, 7;
	xor.b32  	%r1564, %r1562, %r1563;
	xor.b32  	%r1565, %r1523, %r1498;
	and.b32  	%r1566, %r1548, %r1565;
	xor.b32  	%r1567, %r1566, %r1498;
	ld.const.u32 	%r1568, [%rd288+40];
	add.s32 	%r1569, %r1568, %r1753;
	add.s32 	%r1570, %r1569, %r1473;
	add.s32 	%r1571, %r1570, %r1567;
	add.s32 	%r1572, %r1571, %r1564;
	add.s32 	%r1573, %r1572, %r1484;
	shf.l.wrap.b32 	%r1574, %r1559, %r1559, 30;
	shf.l.wrap.b32 	%r1575, %r1559, %r1559, 19;
	xor.b32  	%r1576, %r1574, %r1575;
	shf.l.wrap.b32 	%r1577, %r1559, %r1559, 10;
	xor.b32  	%r1578, %r1576, %r1577;
	and.b32  	%r1579, %r1559, %r1534;
	xor.b32  	%r1580, %r1559, %r1534;
	and.b32  	%r1581, %r1580, %r1509;
	or.b32  	%r1582, %r1581, %r1579;
	add.s32 	%r1583, %r1578, %r1582;
	add.s32 	%r1584, %r1583, %r1572;
	shf.l.wrap.b32 	%r1585, %r1573, %r1573, 26;
	shf.l.wrap.b32 	%r1586, %r1573, %r1573, 21;
	xor.b32  	%r1587, %r1585, %r1586;
	shf.l.wrap.b32 	%r1588, %r1573, %r1573, 7;
	xor.b32  	%r1589, %r1587, %r1588;
	xor.b32  	%r1590, %r1548, %r1523;
	and.b32  	%r1591, %r1573, %r1590;
	xor.b32  	%r1592, %r1591, %r1523;
	ld.const.u32 	%r1593, [%rd288+44];
	add.s32 	%r1594, %r1593, %r1754;
	add.s32 	%r1595, %r1594, %r1498;
	add.s32 	%r1596, %r1595, %r1592;
	add.s32 	%r1597, %r1596, %r1589;
	add.s32 	%r1598, %r1597, %r1509;
	shf.l.wrap.b32 	%r1599, %r1584, %r1584, 30;
	shf.l.wrap.b32 	%r1600, %r1584, %r1584, 19;
	xor.b32  	%r1601, %r1599, %r1600;
	shf.l.wrap.b32 	%r1602, %r1584, %r1584, 10;
	xor.b32  	%r1603, %r1601, %r1602;
	and.b32  	%r1604, %r1584, %r1559;
	xor.b32  	%r1605, %r1584, %r1559;
	and.b32  	%r1606, %r1605, %r1534;
	or.b32  	%r1607, %r1606, %r1604;
	add.s32 	%r1608, %r1603, %r1607;
	add.s32 	%r1609, %r1608, %r1597;
	shf.l.wrap.b32 	%r1610, %r1598, %r1598, 26;
	shf.l.wrap.b32 	%r1611, %r1598, %r1598, 21;
	xor.b32  	%r1612, %r1610, %r1611;
	shf.l.wrap.b32 	%r1613, %r1598, %r1598, 7;
	xor.b32  	%r1614, %r1612, %r1613;
	xor.b32  	%r1615, %r1573, %r1548;
	and.b32  	%r1616, %r1598, %r1615;
	xor.b32  	%r1617, %r1616, %r1548;
	ld.const.u32 	%r1618, [%rd288+48];
	add.s32 	%r1619, %r1618, %r1734;
	add.s32 	%r1620, %r1619, %r1523;
	add.s32 	%r1621, %r1620, %r1617;
	add.s32 	%r1622, %r1621, %r1614;
	add.s32 	%r1742, %r1622, %r1534;
	shf.l.wrap.b32 	%r1623, %r1609, %r1609, 30;
	shf.l.wrap.b32 	%r1624, %r1609, %r1609, 19;
	xor.b32  	%r1625, %r1623, %r1624;
	shf.l.wrap.b32 	%r1626, %r1609, %r1609, 10;
	xor.b32  	%r1627, %r1625, %r1626;
	and.b32  	%r1628, %r1609, %r1584;
	xor.b32  	%r1629, %r1609, %r1584;
	and.b32  	%r1630, %r1629, %r1559;
	or.b32  	%r1631, %r1630, %r1628;
	add.s32 	%r1632, %r1627, %r1631;
	add.s32 	%r1738, %r1632, %r1622;
	shf.l.wrap.b32 	%r1633, %r1742, %r1742, 26;
	shf.l.wrap.b32 	%r1634, %r1742, %r1742, 21;
	xor.b32  	%r1635, %r1633, %r1634;
	shf.l.wrap.b32 	%r1636, %r1742, %r1742, 7;
	xor.b32  	%r1637, %r1635, %r1636;
	xor.b32  	%r1638, %r1598, %r1573;
	and.b32  	%r1639, %r1742, %r1638;
	xor.b32  	%r1640, %r1639, %r1573;
	ld.const.u32 	%r1641, [%rd288+52];
	add.s32 	%r1642, %r1641, %r1733;
	add.s32 	%r1643, %r1642, %r1548;
	add.s32 	%r1644, %r1643, %r1640;
	add.s32 	%r1645, %r1644, %r1637;
	add.s32 	%r1741, %r1645, %r1559;
	shf.l.wrap.b32 	%r1646, %r1738, %r1738, 30;
	shf.l.wrap.b32 	%r1647, %r1738, %r1738, 19;
	xor.b32  	%r1648, %r1646, %r1647;
	shf.l.wrap.b32 	%r1649, %r1738, %r1738, 10;
	xor.b32  	%r1650, %r1648, %r1649;
	and.b32  	%r1651, %r1738, %r1609;
	xor.b32  	%r1652, %r1738, %r1609;
	and.b32  	%r1653, %r1652, %r1584;
	or.b32  	%r1654, %r1653, %r1651;
	add.s32 	%r1655, %r1650, %r1654;
	add.s32 	%r1737, %r1655, %r1645;
	shf.l.wrap.b32 	%r1656, %r1741, %r1741, 26;
	shf.l.wrap.b32 	%r1657, %r1741, %r1741, 21;
	xor.b32  	%r1658, %r1656, %r1657;
	shf.l.wrap.b32 	%r1659, %r1741, %r1741, 7;
	xor.b32  	%r1660, %r1658, %r1659;
	xor.b32  	%r1661, %r1742, %r1598;
	and.b32  	%r1662, %r1741, %r1661;
	xor.b32  	%r1663, %r1662, %r1598;
	ld.const.u32 	%r1664, [%rd288+56];
	add.s32 	%r1665, %r1664, %r1732;
	add.s32 	%r1666, %r1665, %r1573;
	add.s32 	%r1667, %r1666, %r1663;
	add.s32 	%r1668, %r1667, %r1660;
	add.s32 	%r1740, %r1668, %r1584;
	shf.l.wrap.b32 	%r1669, %r1737, %r1737, 30;
	shf.l.wrap.b32 	%r1670, %r1737, %r1737, 19;
	xor.b32  	%r1671, %r1669, %r1670;
	shf.l.wrap.b32 	%r1672, %r1737, %r1737, 10;
	xor.b32  	%r1673, %r1671, %r1672;
	and.b32  	%r1674, %r1737, %r1738;
	xor.b32  	%r1675, %r1737, %r1738;
	and.b32  	%r1676, %r1675, %r1609;
	or.b32  	%r1677, %r1676, %r1674;
	add.s32 	%r1678, %r1673, %r1677;
	add.s32 	%r1736, %r1678, %r1668;
	shf.l.wrap.b32 	%r1679, %r1740, %r1740, 26;
	shf.l.wrap.b32 	%r1680, %r1740, %r1740, 21;
	xor.b32  	%r1681, %r1679, %r1680;
	shf.l.wrap.b32 	%r1682, %r1740, %r1740, 7;
	xor.b32  	%r1683, %r1681, %r1682;
	xor.b32  	%r1684, %r1741, %r1742;
	and.b32  	%r1685, %r1740, %r1684;
	xor.b32  	%r1686, %r1685, %r1742;
	ld.const.u32 	%r1687, [%rd288+60];
	add.s32 	%r1688, %r1687, %r1731;
	add.s32 	%r1689, %r1688, %r1598;
	add.s32 	%r1690, %r1689, %r1686;
	add.s32 	%r1691, %r1690, %r1683;
	add.s32 	%r1739, %r1691, %r1609;
	shf.l.wrap.b32 	%r1692, %r1736, %r1736, 30;
	shf.l.wrap.b32 	%r1693, %r1736, %r1736, 19;
	xor.b32  	%r1694, %r1692, %r1693;
	shf.l.wrap.b32 	%r1695, %r1736, %r1736, 10;
	xor.b32  	%r1696, %r1694, %r1695;
	and.b32  	%r1697, %r1736, %r1737;
	xor.b32  	%r1698, %r1736, %r1737;
	and.b32  	%r1699, %r1698, %r1738;
	or.b32  	%r1700, %r1699, %r1697;
	add.s32 	%r1701, %r1696, %r1700;
	add.s32 	%r1735, %r1701, %r1691;
	add.s32 	%r1730, %r1730, 16;
	setp.lt.u32 	%p6, %r1730, 64;
	@%p6 bra 	$L__BB1_10;

	ld.param.u64 	%rd289, [m11600_loop_param_24];
	add.s32 	%r1729, %r1735, %r1729;
	add.s32 	%r1728, %r1736, %r1728;
	add.s32 	%r1727, %r1737, %r1727;
	add.s32 	%r1726, %r1738, %r1726;
	add.s32 	%r1725, %r1739, %r1725;
	add.s32 	%r1724, %r1740, %r1724;
	add.s32 	%r1723, %r1741, %r1723;
	add.s32 	%r1722, %r1742, %r1722;
	add.s32 	%r1720, %r1720, 16;
	add.s32 	%r1721, %r1721, 1;
	setp.lt.u32 	%p7, %r1721, %r23;
	add.s64 	%rd47, %rd289, 24;
	@%p7 bra 	$L__BB1_9;

	add.s32 	%r1710, %r1710, 64;
	ld.global.u32 	%r1755, [%rd47+-4];
	setp.lt.u32 	%p8, %r1710, %r1755;
	@%p8 bra 	$L__BB1_8;

$L__BB1_13:
	ld.global.u32 	%r1702, [%rd7+96];
	mad.lo.s32 	%r1703, %r1755, %r23, %r1702;
	st.global.u32 	[%rd7+96], %r1703;
	st.global.u32 	[%rd7], %r1729;
	st.global.u32 	[%rd7+4], %r1728;
	st.global.u32 	[%rd7+8], %r1727;
	st.global.u32 	[%rd7+12], %r1726;
	st.global.u32 	[%rd7+16], %r1725;
	st.global.u32 	[%rd7+20], %r1724;
	st.global.u32 	[%rd7+24], %r1723;
	st.global.u32 	[%rd7+28], %r1722;

$L__BB1_14:
	ret;

}
	// .globl	m11600_hook23
.entry m11600_hook23(
	.param .u64 .ptr .global .align 4 m11600_hook23_param_0,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_1,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_2,
	.param .u64 .ptr .const .align 4 m11600_hook23_param_3,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_4,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_5,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_6,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_7,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_8,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_9,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_10,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_11,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_12,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_13,
	.param .u64 .ptr .global .align 8 m11600_hook23_param_14,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_15,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_16,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_17,
	.param .u64 .ptr .global .align 1 m11600_hook23_param_18,
	.param .u64 .ptr .global .align 4 m11600_hook23_param_19,
	.param .u64 .ptr .global .align 1 m11600_hook23_param_20,
	.param .u64 .ptr .global .align 1 m11600_hook23_param_21,
	.param .u64 .ptr .global .align 1 m11600_hook23_param_22,
	.param .u64 .ptr .global .align 1 m11600_hook23_param_23,
	.param .u64 .ptr .global .align 8 m11600_hook23_param_24
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<1077>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd4, [m11600_hook23_param_4];
	ld.param.u64 	%rd6, [m11600_hook23_param_24];
	mov.b32 	%r68, %envreg3;
	mov.u32 	%r69, %ctaid.x;
	mov.u32 	%r70, %ntid.x;
	mov.u32 	%r71, %tid.x;
	add.s32 	%r72, %r71, %r68;
	mad.lo.s32 	%r73, %r70, %r69, %r72;
	cvt.s64.s32 	%rd1, %r73;
	ld.global.u64 	%rd7, [%rd6+56];
	setp.le.u64 	%p1, %rd7, %rd1;
	@%p1 bra 	$L__BB2_4;

	mul.lo.s64 	%rd9, %rd1, 100;
	add.s64 	%rd10, %rd4, %rd9;
	ld.global.u32 	%r90, [%rd10+96];
	shl.b32 	%r1053, %r90, 3;
	ld.global.u32 	%r2, [%rd10+16];
	shf.l.wrap.b32 	%r91, %r2, %r2, 26;
	shf.l.wrap.b32 	%r92, %r2, %r2, 21;
	xor.b32  	%r93, %r91, %r92;
	shf.l.wrap.b32 	%r94, %r2, %r2, 7;
	xor.b32  	%r95, %r93, %r94;
	ld.global.u32 	%r3, [%rd10+24];
	ld.global.u32 	%r4, [%rd10+20];
	xor.b32  	%r96, %r3, %r4;
	and.b32  	%r97, %r96, %r2;
	xor.b32  	%r98, %r97, %r3;
	ld.global.u32 	%r5, [%rd10+28];
	add.s32 	%r99, %r5, %r95;
	add.s32 	%r100, %r99, %r98;
	add.s32 	%r101, %r100, -1031131240;
	ld.global.u32 	%r6, [%rd10+12];
	add.s32 	%r102, %r101, %r6;
	ld.global.u32 	%r7, [%rd10];
	shf.l.wrap.b32 	%r103, %r7, %r7, 30;
	shf.l.wrap.b32 	%r104, %r7, %r7, 19;
	xor.b32  	%r105, %r103, %r104;
	shf.l.wrap.b32 	%r106, %r7, %r7, 10;
	xor.b32  	%r107, %r105, %r106;
	ld.global.u32 	%r8, [%rd10+4];
	and.b32  	%r108, %r8, %r7;
	xor.b32  	%r109, %r8, %r7;
	ld.global.u32 	%r9, [%rd10+8];
	and.b32  	%r110, %r9, %r109;
	or.b32  	%r111, %r110, %r108;
	add.s32 	%r112, %r111, %r107;
	add.s32 	%r113, %r112, %r101;
	xor.b32  	%r114, %r4, %r2;
	and.b32  	%r115, %r102, %r114;
	xor.b32  	%r116, %r115, %r4;
	add.s32 	%r117, %r3, %r116;
	shf.l.wrap.b32 	%r118, %r102, %r102, 26;
	shf.l.wrap.b32 	%r119, %r102, %r102, 21;
	xor.b32  	%r120, %r118, %r119;
	shf.l.wrap.b32 	%r121, %r102, %r102, 7;
	xor.b32  	%r122, %r120, %r121;
	add.s32 	%r123, %r117, %r122;
	add.s32 	%r124, %r123, 1899447441;
	add.s32 	%r125, %r124, %r9;
	shf.l.wrap.b32 	%r126, %r113, %r113, 30;
	shf.l.wrap.b32 	%r127, %r113, %r113, 19;
	xor.b32  	%r128, %r126, %r127;
	shf.l.wrap.b32 	%r129, %r113, %r113, 10;
	xor.b32  	%r130, %r128, %r129;
	and.b32  	%r131, %r113, %r7;
	xor.b32  	%r132, %r113, %r7;
	and.b32  	%r133, %r132, %r8;
	or.b32  	%r134, %r133, %r131;
	add.s32 	%r135, %r130, %r134;
	add.s32 	%r136, %r135, %r124;
	xor.b32  	%r137, %r102, %r2;
	and.b32  	%r138, %r125, %r137;
	xor.b32  	%r139, %r138, %r2;
	add.s32 	%r140, %r4, %r139;
	shf.l.wrap.b32 	%r141, %r125, %r125, 26;
	shf.l.wrap.b32 	%r142, %r125, %r125, 21;
	xor.b32  	%r143, %r141, %r142;
	shf.l.wrap.b32 	%r144, %r125, %r125, 7;
	xor.b32  	%r145, %r143, %r144;
	add.s32 	%r146, %r140, %r145;
	add.s32 	%r147, %r146, -1245643825;
	add.s32 	%r148, %r147, %r8;
	shf.l.wrap.b32 	%r149, %r136, %r136, 30;
	shf.l.wrap.b32 	%r150, %r136, %r136, 19;
	xor.b32  	%r151, %r149, %r150;
	shf.l.wrap.b32 	%r152, %r136, %r136, 10;
	xor.b32  	%r153, %r151, %r152;
	and.b32  	%r154, %r136, %r113;
	xor.b32  	%r155, %r136, %r113;
	and.b32  	%r156, %r155, %r7;
	or.b32  	%r157, %r156, %r154;
	add.s32 	%r158, %r153, %r157;
	add.s32 	%r159, %r158, %r147;
	xor.b32  	%r160, %r125, %r102;
	and.b32  	%r161, %r148, %r160;
	xor.b32  	%r162, %r161, %r102;
	add.s32 	%r163, %r2, %r162;
	shf.l.wrap.b32 	%r164, %r148, %r148, 26;
	shf.l.wrap.b32 	%r165, %r148, %r148, 21;
	xor.b32  	%r166, %r164, %r165;
	shf.l.wrap.b32 	%r167, %r148, %r148, 7;
	xor.b32  	%r168, %r166, %r167;
	add.s32 	%r169, %r163, %r168;
	add.s32 	%r170, %r169, -373957723;
	add.s32 	%r171, %r170, %r7;
	shf.l.wrap.b32 	%r172, %r159, %r159, 30;
	shf.l.wrap.b32 	%r173, %r159, %r159, 19;
	xor.b32  	%r174, %r172, %r173;
	shf.l.wrap.b32 	%r175, %r159, %r159, 10;
	xor.b32  	%r176, %r174, %r175;
	and.b32  	%r177, %r159, %r136;
	xor.b32  	%r178, %r159, %r136;
	and.b32  	%r179, %r178, %r113;
	or.b32  	%r180, %r179, %r177;
	add.s32 	%r181, %r176, %r180;
	add.s32 	%r182, %r181, %r170;
	xor.b32  	%r183, %r148, %r125;
	and.b32  	%r184, %r171, %r183;
	xor.b32  	%r185, %r184, %r125;
	add.s32 	%r186, %r102, %r185;
	shf.l.wrap.b32 	%r187, %r171, %r171, 26;
	shf.l.wrap.b32 	%r188, %r171, %r171, 21;
	xor.b32  	%r189, %r187, %r188;
	shf.l.wrap.b32 	%r190, %r171, %r171, 7;
	xor.b32  	%r191, %r189, %r190;
	add.s32 	%r192, %r186, %r191;
	add.s32 	%r193, %r192, 961987163;
	add.s32 	%r194, %r193, %r113;
	shf.l.wrap.b32 	%r195, %r182, %r182, 30;
	shf.l.wrap.b32 	%r196, %r182, %r182, 19;
	xor.b32  	%r197, %r195, %r196;
	shf.l.wrap.b32 	%r198, %r182, %r182, 10;
	xor.b32  	%r199, %r197, %r198;
	and.b32  	%r200, %r182, %r159;
	xor.b32  	%r201, %r182, %r159;
	and.b32  	%r202, %r201, %r136;
	or.b32  	%r203, %r202, %r200;
	add.s32 	%r204, %r199, %r203;
	add.s32 	%r205, %r204, %r193;
	xor.b32  	%r206, %r171, %r148;
	and.b32  	%r207, %r194, %r206;
	xor.b32  	%r208, %r207, %r148;
	add.s32 	%r209, %r125, %r208;
	shf.l.wrap.b32 	%r210, %r194, %r194, 26;
	shf.l.wrap.b32 	%r211, %r194, %r194, 21;
	xor.b32  	%r212, %r210, %r211;
	shf.l.wrap.b32 	%r213, %r194, %r194, 7;
	xor.b32  	%r214, %r212, %r213;
	add.s32 	%r215, %r209, %r214;
	add.s32 	%r216, %r215, 1508970993;
	add.s32 	%r217, %r216, %r136;
	shf.l.wrap.b32 	%r218, %r205, %r205, 30;
	shf.l.wrap.b32 	%r219, %r205, %r205, 19;
	xor.b32  	%r220, %r218, %r219;
	shf.l.wrap.b32 	%r221, %r205, %r205, 10;
	xor.b32  	%r222, %r220, %r221;
	and.b32  	%r223, %r205, %r182;
	xor.b32  	%r224, %r205, %r182;
	and.b32  	%r225, %r224, %r159;
	or.b32  	%r226, %r225, %r223;
	add.s32 	%r227, %r222, %r226;
	add.s32 	%r228, %r227, %r216;
	xor.b32  	%r229, %r194, %r171;
	and.b32  	%r230, %r217, %r229;
	xor.b32  	%r231, %r230, %r171;
	add.s32 	%r232, %r148, %r231;
	shf.l.wrap.b32 	%r233, %r217, %r217, 26;
	shf.l.wrap.b32 	%r234, %r217, %r217, 21;
	xor.b32  	%r235, %r233, %r234;
	shf.l.wrap.b32 	%r236, %r217, %r217, 7;
	xor.b32  	%r237, %r235, %r236;
	add.s32 	%r238, %r232, %r237;
	add.s32 	%r239, %r238, -1841331548;
	add.s32 	%r240, %r239, %r159;
	shf.l.wrap.b32 	%r241, %r228, %r228, 30;
	shf.l.wrap.b32 	%r242, %r228, %r228, 19;
	xor.b32  	%r243, %r241, %r242;
	shf.l.wrap.b32 	%r244, %r228, %r228, 10;
	xor.b32  	%r245, %r243, %r244;
	and.b32  	%r246, %r228, %r205;
	xor.b32  	%r247, %r228, %r205;
	and.b32  	%r248, %r247, %r182;
	or.b32  	%r249, %r248, %r246;
	add.s32 	%r250, %r245, %r249;
	add.s32 	%r251, %r250, %r239;
	xor.b32  	%r252, %r217, %r194;
	and.b32  	%r253, %r240, %r252;
	xor.b32  	%r254, %r253, %r194;
	add.s32 	%r255, %r171, %r254;
	shf.l.wrap.b32 	%r256, %r240, %r240, 26;
	shf.l.wrap.b32 	%r257, %r240, %r240, 21;
	xor.b32  	%r258, %r256, %r257;
	shf.l.wrap.b32 	%r259, %r240, %r240, 7;
	xor.b32  	%r260, %r258, %r259;
	add.s32 	%r261, %r255, %r260;
	add.s32 	%r262, %r261, -1424204075;
	add.s32 	%r263, %r262, %r182;
	shf.l.wrap.b32 	%r264, %r251, %r251, 30;
	shf.l.wrap.b32 	%r265, %r251, %r251, 19;
	xor.b32  	%r266, %r264, %r265;
	shf.l.wrap.b32 	%r267, %r251, %r251, 10;
	xor.b32  	%r268, %r266, %r267;
	and.b32  	%r269, %r251, %r228;
	xor.b32  	%r270, %r251, %r228;
	and.b32  	%r271, %r270, %r205;
	or.b32  	%r272, %r271, %r269;
	add.s32 	%r273, %r268, %r272;
	add.s32 	%r274, %r273, %r262;
	xor.b32  	%r275, %r240, %r217;
	and.b32  	%r276, %r263, %r275;
	xor.b32  	%r277, %r276, %r217;
	add.s32 	%r278, %r194, %r277;
	shf.l.wrap.b32 	%r279, %r263, %r263, 26;
	shf.l.wrap.b32 	%r280, %r263, %r263, 21;
	xor.b32  	%r281, %r279, %r280;
	shf.l.wrap.b32 	%r282, %r263, %r263, 7;
	xor.b32  	%r283, %r281, %r282;
	add.s32 	%r284, %r278, %r283;
	add.s32 	%r285, %r284, -670586216;
	add.s32 	%r286, %r285, %r205;
	shf.l.wrap.b32 	%r287, %r274, %r274, 30;
	shf.l.wrap.b32 	%r288, %r274, %r274, 19;
	xor.b32  	%r289, %r287, %r288;
	shf.l.wrap.b32 	%r290, %r274, %r274, 10;
	xor.b32  	%r291, %r289, %r290;
	and.b32  	%r292, %r274, %r251;
	xor.b32  	%r293, %r274, %r251;
	and.b32  	%r294, %r293, %r228;
	or.b32  	%r295, %r294, %r292;
	add.s32 	%r296, %r291, %r295;
	add.s32 	%r297, %r296, %r285;
	xor.b32  	%r298, %r263, %r240;
	and.b32  	%r299, %r286, %r298;
	xor.b32  	%r300, %r299, %r240;
	add.s32 	%r301, %r217, %r300;
	shf.l.wrap.b32 	%r302, %r286, %r286, 26;
	shf.l.wrap.b32 	%r303, %r286, %r286, 21;
	xor.b32  	%r304, %r302, %r303;
	shf.l.wrap.b32 	%r305, %r286, %r286, 7;
	xor.b32  	%r306, %r304, %r305;
	add.s32 	%r307, %r301, %r306;
	add.s32 	%r308, %r307, 310598401;
	add.s32 	%r309, %r308, %r228;
	shf.l.wrap.b32 	%r310, %r297, %r297, 30;
	shf.l.wrap.b32 	%r311, %r297, %r297, 19;
	xor.b32  	%r312, %r310, %r311;
	shf.l.wrap.b32 	%r313, %r297, %r297, 10;
	xor.b32  	%r314, %r312, %r313;
	and.b32  	%r315, %r297, %r274;
	xor.b32  	%r316, %r297, %r274;
	and.b32  	%r317, %r316, %r251;
	or.b32  	%r318, %r317, %r315;
	add.s32 	%r319, %r314, %r318;
	add.s32 	%r320, %r319, %r308;
	xor.b32  	%r321, %r286, %r263;
	and.b32  	%r322, %r309, %r321;
	xor.b32  	%r323, %r322, %r263;
	add.s32 	%r324, %r240, %r323;
	shf.l.wrap.b32 	%r325, %r309, %r309, 26;
	shf.l.wrap.b32 	%r326, %r309, %r309, 21;
	xor.b32  	%r327, %r325, %r326;
	shf.l.wrap.b32 	%r328, %r309, %r309, 7;
	xor.b32  	%r329, %r327, %r328;
	add.s32 	%r330, %r324, %r329;
	add.s32 	%r331, %r330, 607225278;
	add.s32 	%r332, %r331, %r251;
	shf.l.wrap.b32 	%r333, %r320, %r320, 30;
	shf.l.wrap.b32 	%r334, %r320, %r320, 19;
	xor.b32  	%r335, %r333, %r334;
	shf.l.wrap.b32 	%r336, %r320, %r320, 10;
	xor.b32  	%r337, %r335, %r336;
	and.b32  	%r338, %r320, %r297;
	xor.b32  	%r339, %r320, %r297;
	and.b32  	%r340, %r339, %r274;
	or.b32  	%r341, %r340, %r338;
	add.s32 	%r342, %r337, %r341;
	add.s32 	%r343, %r342, %r331;
	xor.b32  	%r344, %r309, %r286;
	and.b32  	%r345, %r332, %r344;
	xor.b32  	%r346, %r345, %r286;
	add.s32 	%r347, %r263, %r346;
	shf.l.wrap.b32 	%r348, %r332, %r332, 26;
	shf.l.wrap.b32 	%r349, %r332, %r332, 21;
	xor.b32  	%r350, %r348, %r349;
	shf.l.wrap.b32 	%r351, %r332, %r332, 7;
	xor.b32  	%r352, %r350, %r351;
	add.s32 	%r353, %r347, %r352;
	add.s32 	%r354, %r353, 1426881987;
	add.s32 	%r355, %r354, %r274;
	shf.l.wrap.b32 	%r356, %r343, %r343, 30;
	shf.l.wrap.b32 	%r357, %r343, %r343, 19;
	xor.b32  	%r358, %r356, %r357;
	shf.l.wrap.b32 	%r359, %r343, %r343, 10;
	xor.b32  	%r360, %r358, %r359;
	and.b32  	%r361, %r343, %r320;
	xor.b32  	%r362, %r343, %r320;
	and.b32  	%r363, %r362, %r297;
	or.b32  	%r364, %r363, %r361;
	add.s32 	%r365, %r360, %r364;
	add.s32 	%r366, %r365, %r354;
	xor.b32  	%r367, %r332, %r309;
	and.b32  	%r368, %r355, %r367;
	xor.b32  	%r369, %r368, %r309;
	add.s32 	%r370, %r286, %r369;
	shf.l.wrap.b32 	%r371, %r355, %r355, 26;
	shf.l.wrap.b32 	%r372, %r355, %r355, 21;
	xor.b32  	%r373, %r371, %r372;
	shf.l.wrap.b32 	%r374, %r355, %r355, 7;
	xor.b32  	%r375, %r373, %r374;
	add.s32 	%r376, %r370, %r375;
	add.s32 	%r377, %r376, 1925078388;
	add.s32 	%r1064, %r377, %r297;
	shf.l.wrap.b32 	%r378, %r366, %r366, 30;
	shf.l.wrap.b32 	%r379, %r366, %r366, 19;
	xor.b32  	%r380, %r378, %r379;
	shf.l.wrap.b32 	%r381, %r366, %r366, 10;
	xor.b32  	%r382, %r380, %r381;
	and.b32  	%r383, %r366, %r343;
	xor.b32  	%r384, %r366, %r343;
	and.b32  	%r385, %r384, %r320;
	or.b32  	%r386, %r385, %r383;
	add.s32 	%r387, %r382, %r386;
	add.s32 	%r1060, %r387, %r377;
	xor.b32  	%r388, %r355, %r332;
	and.b32  	%r389, %r1064, %r388;
	xor.b32  	%r390, %r389, %r332;
	add.s32 	%r391, %r309, %r390;
	shf.l.wrap.b32 	%r392, %r1064, %r1064, 26;
	shf.l.wrap.b32 	%r393, %r1064, %r1064, 21;
	xor.b32  	%r394, %r392, %r393;
	shf.l.wrap.b32 	%r395, %r1064, %r1064, 7;
	xor.b32  	%r396, %r394, %r395;
	add.s32 	%r397, %r391, %r396;
	add.s32 	%r398, %r397, -2132889090;
	add.s32 	%r1063, %r398, %r320;
	shf.l.wrap.b32 	%r399, %r1060, %r1060, 30;
	shf.l.wrap.b32 	%r400, %r1060, %r1060, 19;
	xor.b32  	%r401, %r399, %r400;
	shf.l.wrap.b32 	%r402, %r1060, %r1060, 10;
	xor.b32  	%r403, %r401, %r402;
	and.b32  	%r404, %r1060, %r366;
	xor.b32  	%r405, %r1060, %r366;
	and.b32  	%r406, %r405, %r343;
	or.b32  	%r407, %r406, %r404;
	add.s32 	%r408, %r403, %r407;
	add.s32 	%r1059, %r408, %r398;
	xor.b32  	%r409, %r1064, %r355;
	and.b32  	%r410, %r1063, %r409;
	xor.b32  	%r411, %r410, %r355;
	add.s32 	%r412, %r332, %r411;
	shf.l.wrap.b32 	%r413, %r1063, %r1063, 26;
	shf.l.wrap.b32 	%r414, %r1063, %r1063, 21;
	xor.b32  	%r415, %r413, %r414;
	shf.l.wrap.b32 	%r416, %r1063, %r1063, 7;
	xor.b32  	%r417, %r415, %r416;
	add.s32 	%r418, %r412, %r417;
	add.s32 	%r419, %r418, -1680079193;
	add.s32 	%r1062, %r419, %r343;
	shf.l.wrap.b32 	%r420, %r1059, %r1059, 30;
	shf.l.wrap.b32 	%r421, %r1059, %r1059, 19;
	xor.b32  	%r422, %r420, %r421;
	shf.l.wrap.b32 	%r423, %r1059, %r1059, 10;
	xor.b32  	%r424, %r422, %r423;
	and.b32  	%r425, %r1059, %r1060;
	xor.b32  	%r426, %r1059, %r1060;
	and.b32  	%r427, %r426, %r366;
	or.b32  	%r428, %r427, %r425;
	add.s32 	%r429, %r424, %r428;
	add.s32 	%r1058, %r429, %r419;
	shf.l.wrap.b32 	%r430, %r1062, %r1062, 26;
	shf.l.wrap.b32 	%r431, %r1062, %r1062, 21;
	xor.b32  	%r432, %r430, %r431;
	shf.l.wrap.b32 	%r433, %r1062, %r1062, 7;
	xor.b32  	%r434, %r432, %r433;
	xor.b32  	%r435, %r1063, %r1064;
	and.b32  	%r436, %r1062, %r435;
	xor.b32  	%r437, %r436, %r1064;
	add.s32 	%r438, %r1053, %r355;
	add.s32 	%r439, %r438, %r437;
	add.s32 	%r440, %r439, %r434;
	add.s32 	%r441, %r440, -1046744716;
	add.s32 	%r1061, %r441, %r366;
	shf.l.wrap.b32 	%r442, %r1058, %r1058, 30;
	shf.l.wrap.b32 	%r443, %r1058, %r1058, 19;
	xor.b32  	%r444, %r442, %r443;
	shf.l.wrap.b32 	%r445, %r1058, %r1058, 10;
	xor.b32  	%r446, %r444, %r445;
	and.b32  	%r447, %r1058, %r1059;
	xor.b32  	%r448, %r1058, %r1059;
	and.b32  	%r449, %r448, %r1060;
	or.b32  	%r450, %r449, %r447;
	add.s32 	%r451, %r446, %r450;
	add.s32 	%r1057, %r451, %r441;
	mov.u32 	%r1054, 0;
	mov.u32 	%r1065, -2147483648;
	mov.u32 	%r1052, 16;
	mov.u64 	%rd14, k_sha256;
	mov.u32 	%r1055, %r1054;
	mov.u32 	%r1056, %r1054;
	mov.u32 	%r1066, %r1054;
	mov.u32 	%r1067, %r1054;
	mov.u32 	%r1068, %r1054;
	mov.u32 	%r1069, %r1054;
	mov.u32 	%r1070, %r1054;
	mov.u32 	%r1071, %r1054;
	mov.u32 	%r1072, %r1054;
	mov.u32 	%r1073, %r1054;
	mov.u32 	%r1074, %r1054;
	mov.u32 	%r1075, %r1054;
	mov.u32 	%r1076, %r1054;

$L__BB2_2:
	shf.l.wrap.b32 	%r452, %r1054, %r1054, 15;
	shf.l.wrap.b32 	%r453, %r1054, %r1054, 13;
	shr.u32 	%r454, %r1054, 10;
	xor.b32  	%r455, %r453, %r454;
	xor.b32  	%r456, %r455, %r452;
	shf.l.wrap.b32 	%r457, %r1066, %r1066, 25;
	shf.l.wrap.b32 	%r458, %r1066, %r1066, 14;
	shr.u32 	%r459, %r1066, 3;
	xor.b32  	%r460, %r458, %r459;
	xor.b32  	%r461, %r460, %r457;
	add.s32 	%r462, %r1065, %r1074;
	add.s32 	%r463, %r462, %r461;
	add.s32 	%r1065, %r463, %r456;
	shf.l.wrap.b32 	%r464, %r1053, %r1053, 15;
	shf.l.wrap.b32 	%r465, %r1053, %r1053, 13;
	shr.u32 	%r466, %r1053, 10;
	xor.b32  	%r467, %r465, %r466;
	xor.b32  	%r468, %r467, %r464;
	shf.l.wrap.b32 	%r469, %r1067, %r1067, 25;
	shf.l.wrap.b32 	%r470, %r1067, %r1067, 14;
	shr.u32 	%r471, %r1067, 3;
	xor.b32  	%r472, %r470, %r471;
	xor.b32  	%r473, %r472, %r469;
	add.s32 	%r474, %r1066, %r1075;
	add.s32 	%r475, %r474, %r473;
	add.s32 	%r1066, %r475, %r468;
	shf.l.wrap.b32 	%r476, %r1065, %r1065, 15;
	shf.l.wrap.b32 	%r477, %r1065, %r1065, 13;
	shr.u32 	%r478, %r1065, 10;
	xor.b32  	%r479, %r477, %r478;
	xor.b32  	%r480, %r479, %r476;
	shf.l.wrap.b32 	%r481, %r1068, %r1068, 25;
	shf.l.wrap.b32 	%r482, %r1068, %r1068, 14;
	shr.u32 	%r483, %r1068, 3;
	xor.b32  	%r484, %r482, %r483;
	xor.b32  	%r485, %r484, %r481;
	add.s32 	%r486, %r1067, %r1076;
	add.s32 	%r487, %r486, %r485;
	add.s32 	%r1067, %r487, %r480;
	shf.l.wrap.b32 	%r488, %r1066, %r1066, 15;
	shf.l.wrap.b32 	%r489, %r1066, %r1066, 13;
	shr.u32 	%r490, %r1066, 10;
	xor.b32  	%r491, %r489, %r490;
	xor.b32  	%r492, %r491, %r488;
	shf.l.wrap.b32 	%r493, %r1069, %r1069, 25;
	shf.l.wrap.b32 	%r494, %r1069, %r1069, 14;
	shr.u32 	%r495, %r1069, 3;
	xor.b32  	%r496, %r494, %r495;
	xor.b32  	%r497, %r496, %r493;
	add.s32 	%r498, %r497, %r1068;
	add.s32 	%r499, %r498, %r1056;
	add.s32 	%r1068, %r499, %r492;
	shf.l.wrap.b32 	%r500, %r1067, %r1067, 15;
	shf.l.wrap.b32 	%r501, %r1067, %r1067, 13;
	shr.u32 	%r502, %r1067, 10;
	xor.b32  	%r503, %r501, %r502;
	xor.b32  	%r504, %r503, %r500;
	shf.l.wrap.b32 	%r505, %r1070, %r1070, 25;
	shf.l.wrap.b32 	%r506, %r1070, %r1070, 14;
	shr.u32 	%r507, %r1070, 3;
	xor.b32  	%r508, %r506, %r507;
	xor.b32  	%r509, %r508, %r505;
	add.s32 	%r510, %r509, %r1069;
	add.s32 	%r511, %r510, %r1055;
	add.s32 	%r1069, %r511, %r504;
	shf.l.wrap.b32 	%r512, %r1068, %r1068, 15;
	shf.l.wrap.b32 	%r513, %r1068, %r1068, 13;
	shr.u32 	%r514, %r1068, 10;
	xor.b32  	%r515, %r513, %r514;
	xor.b32  	%r516, %r515, %r512;
	shf.l.wrap.b32 	%r517, %r1071, %r1071, 25;
	shf.l.wrap.b32 	%r518, %r1071, %r1071, 14;
	shr.u32 	%r519, %r1071, 3;
	xor.b32  	%r520, %r518, %r519;
	xor.b32  	%r521, %r520, %r517;
	add.s32 	%r522, %r521, %r1070;
	add.s32 	%r523, %r522, %r1054;
	add.s32 	%r1070, %r523, %r516;
	shf.l.wrap.b32 	%r524, %r1069, %r1069, 15;
	shf.l.wrap.b32 	%r525, %r1069, %r1069, 13;
	shr.u32 	%r526, %r1069, 10;
	xor.b32  	%r527, %r525, %r526;
	xor.b32  	%r528, %r527, %r524;
	shf.l.wrap.b32 	%r529, %r1072, %r1072, 25;
	shf.l.wrap.b32 	%r530, %r1072, %r1072, 14;
	shr.u32 	%r531, %r1072, 3;
	xor.b32  	%r532, %r530, %r531;
	xor.b32  	%r533, %r532, %r529;
	add.s32 	%r534, %r533, %r1071;
	add.s32 	%r535, %r534, %r1053;
	add.s32 	%r1071, %r535, %r528;
	shf.l.wrap.b32 	%r536, %r1070, %r1070, 15;
	shf.l.wrap.b32 	%r537, %r1070, %r1070, 13;
	shr.u32 	%r538, %r1070, 10;
	xor.b32  	%r539, %r537, %r538;
	xor.b32  	%r540, %r539, %r536;
	shf.l.wrap.b32 	%r541, %r1073, %r1073, 25;
	shf.l.wrap.b32 	%r542, %r1073, %r1073, 14;
	shr.u32 	%r543, %r1073, 3;
	xor.b32  	%r544, %r542, %r543;
	xor.b32  	%r545, %r544, %r541;
	add.s32 	%r546, %r545, %r1072;
	add.s32 	%r547, %r546, %r1065;
	add.s32 	%r1072, %r547, %r540;
	shf.l.wrap.b32 	%r548, %r1071, %r1071, 15;
	shf.l.wrap.b32 	%r549, %r1071, %r1071, 13;
	shr.u32 	%r550, %r1071, 10;
	xor.b32  	%r551, %r549, %r550;
	xor.b32  	%r552, %r551, %r548;
	shf.l.wrap.b32 	%r553, %r1074, %r1074, 25;
	shf.l.wrap.b32 	%r554, %r1074, %r1074, 14;
	shr.u32 	%r555, %r1074, 3;
	xor.b32  	%r556, %r554, %r555;
	xor.b32  	%r557, %r556, %r553;
	add.s32 	%r558, %r557, %r1073;
	add.s32 	%r559, %r558, %r1066;
	add.s32 	%r1073, %r559, %r552;
	shf.l.wrap.b32 	%r560, %r1072, %r1072, 15;
	shf.l.wrap.b32 	%r561, %r1072, %r1072, 13;
	shr.u32 	%r562, %r1072, 10;
	xor.b32  	%r563, %r561, %r562;
	xor.b32  	%r564, %r563, %r560;
	shf.l.wrap.b32 	%r565, %r1075, %r1075, 25;
	shf.l.wrap.b32 	%r566, %r1075, %r1075, 14;
	shr.u32 	%r567, %r1075, 3;
	xor.b32  	%r568, %r566, %r567;
	xor.b32  	%r569, %r568, %r565;
	add.s32 	%r570, %r569, %r1074;
	add.s32 	%r571, %r570, %r1067;
	add.s32 	%r1074, %r571, %r564;
	shf.l.wrap.b32 	%r572, %r1073, %r1073, 15;
	shf.l.wrap.b32 	%r573, %r1073, %r1073, 13;
	shr.u32 	%r574, %r1073, 10;
	xor.b32  	%r575, %r573, %r574;
	xor.b32  	%r576, %r575, %r572;
	shf.l.wrap.b32 	%r577, %r1076, %r1076, 25;
	shf.l.wrap.b32 	%r578, %r1076, %r1076, 14;
	shr.u32 	%r579, %r1076, 3;
	xor.b32  	%r580, %r578, %r579;
	xor.b32  	%r581, %r580, %r577;
	add.s32 	%r582, %r581, %r1075;
	add.s32 	%r583, %r582, %r1068;
	add.s32 	%r1075, %r583, %r576;
	shf.l.wrap.b32 	%r584, %r1074, %r1074, 15;
	shf.l.wrap.b32 	%r585, %r1074, %r1074, 13;
	shr.u32 	%r586, %r1074, 10;
	xor.b32  	%r587, %r585, %r586;
	xor.b32  	%r588, %r587, %r584;
	shf.l.wrap.b32 	%r589, %r1056, %r1056, 25;
	shf.l.wrap.b32 	%r590, %r1056, %r1056, 14;
	shr.u32 	%r591, %r1056, 3;
	xor.b32  	%r592, %r590, %r591;
	xor.b32  	%r593, %r592, %r589;
	add.s32 	%r594, %r593, %r1076;
	add.s32 	%r595, %r594, %r1069;
	add.s32 	%r1076, %r595, %r588;
	shf.l.wrap.b32 	%r596, %r1075, %r1075, 15;
	shf.l.wrap.b32 	%r597, %r1075, %r1075, 13;
	shr.u32 	%r598, %r1075, 10;
	xor.b32  	%r599, %r597, %r598;
	xor.b32  	%r600, %r599, %r596;
	shf.l.wrap.b32 	%r601, %r1055, %r1055, 25;
	shf.l.wrap.b32 	%r602, %r1055, %r1055, 14;
	shr.u32 	%r603, %r1055, 3;
	xor.b32  	%r604, %r602, %r603;
	xor.b32  	%r605, %r604, %r601;
	add.s32 	%r606, %r605, %r1056;
	add.s32 	%r607, %r606, %r1070;
	add.s32 	%r1056, %r607, %r600;
	shf.l.wrap.b32 	%r608, %r1076, %r1076, 15;
	shf.l.wrap.b32 	%r609, %r1076, %r1076, 13;
	shr.u32 	%r610, %r1076, 10;
	xor.b32  	%r611, %r609, %r610;
	xor.b32  	%r612, %r611, %r608;
	shf.l.wrap.b32 	%r613, %r1054, %r1054, 25;
	shf.l.wrap.b32 	%r614, %r1054, %r1054, 14;
	shr.u32 	%r615, %r1054, 3;
	xor.b32  	%r616, %r614, %r615;
	xor.b32  	%r617, %r616, %r613;
	add.s32 	%r618, %r617, %r1055;
	add.s32 	%r619, %r618, %r1071;
	add.s32 	%r1055, %r619, %r612;
	shf.l.wrap.b32 	%r620, %r1056, %r1056, 15;
	shf.l.wrap.b32 	%r621, %r1056, %r1056, 13;
	shr.u32 	%r622, %r1056, 10;
	xor.b32  	%r623, %r621, %r622;
	xor.b32  	%r624, %r623, %r620;
	shf.l.wrap.b32 	%r625, %r1053, %r1053, 25;
	shf.l.wrap.b32 	%r626, %r1053, %r1053, 14;
	shr.u32 	%r627, %r1053, 3;
	xor.b32  	%r628, %r626, %r627;
	xor.b32  	%r629, %r628, %r625;
	add.s32 	%r630, %r629, %r1054;
	add.s32 	%r631, %r630, %r1072;
	add.s32 	%r1054, %r631, %r624;
	shf.l.wrap.b32 	%r632, %r1055, %r1055, 15;
	shf.l.wrap.b32 	%r633, %r1055, %r1055, 13;
	shr.u32 	%r634, %r1055, 10;
	xor.b32  	%r635, %r633, %r634;
	xor.b32  	%r636, %r635, %r632;
	shf.l.wrap.b32 	%r637, %r1065, %r1065, 25;
	shf.l.wrap.b32 	%r638, %r1065, %r1065, 14;
	shr.u32 	%r639, %r1065, 3;
	xor.b32  	%r640, %r638, %r639;
	xor.b32  	%r641, %r640, %r637;
	add.s32 	%r642, %r641, %r1053;
	add.s32 	%r643, %r642, %r1073;
	add.s32 	%r1053, %r643, %r636;
	add.s64 	%rd3, %rd14, 64;
	shf.l.wrap.b32 	%r644, %r1061, %r1061, 26;
	shf.l.wrap.b32 	%r645, %r1061, %r1061, 21;
	xor.b32  	%r646, %r644, %r645;
	shf.l.wrap.b32 	%r647, %r1061, %r1061, 7;
	xor.b32  	%r648, %r646, %r647;
	xor.b32  	%r649, %r1062, %r1063;
	and.b32  	%r650, %r1061, %r649;
	xor.b32  	%r651, %r650, %r1063;
	add.s32 	%r652, %r651, %r1064;
	add.s32 	%r653, %r652, %r648;
	add.s32 	%r654, %r653, %r1065;
	ld.const.u32 	%r655, [%rd14+64];
	add.s32 	%r656, %r654, %r655;
	add.s32 	%r657, %r656, %r1060;
	shf.l.wrap.b32 	%r658, %r1057, %r1057, 30;
	shf.l.wrap.b32 	%r659, %r1057, %r1057, 19;
	xor.b32  	%r660, %r658, %r659;
	shf.l.wrap.b32 	%r661, %r1057, %r1057, 10;
	xor.b32  	%r662, %r660, %r661;
	xor.b32  	%r663, %r1057, %r1058;
	and.b32  	%r664, %r663, %r1059;
	and.b32  	%r665, %r1057, %r1058;
	or.b32  	%r666, %r664, %r665;
	add.s32 	%r667, %r662, %r666;
	add.s32 	%r668, %r667, %r656;
	shf.l.wrap.b32 	%r669, %r657, %r657, 26;
	shf.l.wrap.b32 	%r670, %r657, %r657, 21;
	xor.b32  	%r671, %r669, %r670;
	shf.l.wrap.b32 	%r672, %r657, %r657, 7;
	xor.b32  	%r673, %r671, %r672;
	xor.b32  	%r674, %r1061, %r1062;
	and.b32  	%r675, %r657, %r674;
	xor.b32  	%r676, %r675, %r1062;
	add.s32 	%r677, %r1066, %r1063;
	ld.const.u32 	%r678, [%rd14+68];
	add.s32 	%r679, %r677, %r678;
	add.s32 	%r680, %r679, %r676;
	add.s32 	%r681, %r680, %r673;
	add.s32 	%r682, %r681, %r1059;
	shf.l.wrap.b32 	%r683, %r668, %r668, 30;
	shf.l.wrap.b32 	%r684, %r668, %r668, 19;
	xor.b32  	%r685, %r683, %r684;
	shf.l.wrap.b32 	%r686, %r668, %r668, 10;
	xor.b32  	%r687, %r685, %r686;
	and.b32  	%r688, %r668, %r1057;
	xor.b32  	%r689, %r668, %r1057;
	and.b32  	%r690, %r689, %r1058;
	or.b32  	%r691, %r690, %r688;
	add.s32 	%r692, %r687, %r691;
	add.s32 	%r693, %r692, %r681;
	shf.l.wrap.b32 	%r694, %r682, %r682, 26;
	shf.l.wrap.b32 	%r695, %r682, %r682, 21;
	xor.b32  	%r696, %r694, %r695;
	shf.l.wrap.b32 	%r697, %r682, %r682, 7;
	xor.b32  	%r698, %r696, %r697;
	xor.b32  	%r699, %r657, %r1061;
	and.b32  	%r700, %r682, %r699;
	xor.b32  	%r701, %r700, %r1061;
	add.s32 	%r702, %r1067, %r1062;
	ld.const.u32 	%r703, [%rd14+72];
	add.s32 	%r704, %r702, %r703;
	add.s32 	%r705, %r704, %r701;
	add.s32 	%r706, %r705, %r698;
	add.s32 	%r707, %r706, %r1058;
	shf.l.wrap.b32 	%r708, %r693, %r693, 30;
	shf.l.wrap.b32 	%r709, %r693, %r693, 19;
	xor.b32  	%r710, %r708, %r709;
	shf.l.wrap.b32 	%r711, %r693, %r693, 10;
	xor.b32  	%r712, %r710, %r711;
	and.b32  	%r713, %r693, %r668;
	xor.b32  	%r714, %r693, %r668;
	and.b32  	%r715, %r714, %r1057;
	or.b32  	%r716, %r715, %r713;
	add.s32 	%r717, %r712, %r716;
	add.s32 	%r718, %r717, %r706;
	shf.l.wrap.b32 	%r719, %r707, %r707, 26;
	shf.l.wrap.b32 	%r720, %r707, %r707, 21;
	xor.b32  	%r721, %r719, %r720;
	shf.l.wrap.b32 	%r722, %r707, %r707, 7;
	xor.b32  	%r723, %r721, %r722;
	xor.b32  	%r724, %r682, %r657;
	and.b32  	%r725, %r707, %r724;
	xor.b32  	%r726, %r725, %r657;
	add.s32 	%r727, %r1068, %r1061;
	ld.const.u32 	%r728, [%rd14+76];
	add.s32 	%r729, %r727, %r728;
	add.s32 	%r730, %r729, %r726;
	add.s32 	%r731, %r730, %r723;
	add.s32 	%r732, %r731, %r1057;
	shf.l.wrap.b32 	%r733, %r718, %r718, 30;
	shf.l.wrap.b32 	%r734, %r718, %r718, 19;
	xor.b32  	%r735, %r733, %r734;
	shf.l.wrap.b32 	%r736, %r718, %r718, 10;
	xor.b32  	%r737, %r735, %r736;
	and.b32  	%r738, %r718, %r693;
	xor.b32  	%r739, %r718, %r693;
	and.b32  	%r740, %r739, %r668;
	or.b32  	%r741, %r740, %r738;
	add.s32 	%r742, %r737, %r741;
	add.s32 	%r743, %r742, %r731;
	shf.l.wrap.b32 	%r744, %r732, %r732, 26;
	shf.l.wrap.b32 	%r745, %r732, %r732, 21;
	xor.b32  	%r746, %r744, %r745;
	shf.l.wrap.b32 	%r747, %r732, %r732, 7;
	xor.b32  	%r748, %r746, %r747;
	xor.b32  	%r749, %r707, %r682;
	and.b32  	%r750, %r732, %r749;
	xor.b32  	%r751, %r750, %r682;
	ld.const.u32 	%r752, [%rd14+80];
	add.s32 	%r753, %r752, %r1069;
	add.s32 	%r754, %r753, %r657;
	add.s32 	%r755, %r754, %r751;
	add.s32 	%r756, %r755, %r748;
	add.s32 	%r757, %r756, %r668;
	shf.l.wrap.b32 	%r758, %r743, %r743, 30;
	shf.l.wrap.b32 	%r759, %r743, %r743, 19;
	xor.b32  	%r760, %r758, %r759;
	shf.l.wrap.b32 	%r761, %r743, %r743, 10;
	xor.b32  	%r762, %r760, %r761;
	and.b32  	%r763, %r743, %r718;
	xor.b32  	%r764, %r743, %r718;
	and.b32  	%r765, %r764, %r693;
	or.b32  	%r766, %r765, %r763;
	add.s32 	%r767, %r762, %r766;
	add.s32 	%r768, %r767, %r756;
	shf.l.wrap.b32 	%r769, %r757, %r757, 26;
	shf.l.wrap.b32 	%r770, %r757, %r757, 21;
	xor.b32  	%r771, %r769, %r770;
	shf.l.wrap.b32 	%r772, %r757, %r757, 7;
	xor.b32  	%r773, %r771, %r772;
	xor.b32  	%r774, %r732, %r707;
	and.b32  	%r775, %r757, %r774;
	xor.b32  	%r776, %r775, %r707;
	ld.const.u32 	%r777, [%rd14+84];
	add.s32 	%r778, %r777, %r1070;
	add.s32 	%r779, %r778, %r682;
	add.s32 	%r780, %r779, %r776;
	add.s32 	%r781, %r780, %r773;
	add.s32 	%r782, %r781, %r693;
	shf.l.wrap.b32 	%r783, %r768, %r768, 30;
	shf.l.wrap.b32 	%r784, %r768, %r768, 19;
	xor.b32  	%r785, %r783, %r784;
	shf.l.wrap.b32 	%r786, %r768, %r768, 10;
	xor.b32  	%r787, %r785, %r786;
	and.b32  	%r788, %r768, %r743;
	xor.b32  	%r789, %r768, %r743;
	and.b32  	%r790, %r789, %r718;
	or.b32  	%r791, %r790, %r788;
	add.s32 	%r792, %r787, %r791;
	add.s32 	%r793, %r792, %r781;
	shf.l.wrap.b32 	%r794, %r782, %r782, 26;
	shf.l.wrap.b32 	%r795, %r782, %r782, 21;
	xor.b32  	%r796, %r794, %r795;
	shf.l.wrap.b32 	%r797, %r782, %r782, 7;
	xor.b32  	%r798, %r796, %r797;
	xor.b32  	%r799, %r757, %r732;
	and.b32  	%r800, %r782, %r799;
	xor.b32  	%r801, %r800, %r732;
	ld.const.u32 	%r802, [%rd14+88];
	add.s32 	%r803, %r802, %r1071;
	add.s32 	%r804, %r803, %r707;
	add.s32 	%r805, %r804, %r801;
	add.s32 	%r806, %r805, %r798;
	add.s32 	%r807, %r806, %r718;
	shf.l.wrap.b32 	%r808, %r793, %r793, 30;
	shf.l.wrap.b32 	%r809, %r793, %r793, 19;
	xor.b32  	%r810, %r808, %r809;
	shf.l.wrap.b32 	%r811, %r793, %r793, 10;
	xor.b32  	%r812, %r810, %r811;
	and.b32  	%r813, %r793, %r768;
	xor.b32  	%r814, %r793, %r768;
	and.b32  	%r815, %r814, %r743;
	or.b32  	%r816, %r815, %r813;
	add.s32 	%r817, %r812, %r816;
	add.s32 	%r818, %r817, %r806;
	shf.l.wrap.b32 	%r819, %r807, %r807, 26;
	shf.l.wrap.b32 	%r820, %r807, %r807, 21;
	xor.b32  	%r821, %r819, %r820;
	shf.l.wrap.b32 	%r822, %r807, %r807, 7;
	xor.b32  	%r823, %r821, %r822;
	xor.b32  	%r824, %r782, %r757;
	and.b32  	%r825, %r807, %r824;
	xor.b32  	%r826, %r825, %r757;
	ld.const.u32 	%r827, [%rd14+92];
	add.s32 	%r828, %r827, %r1072;
	add.s32 	%r829, %r828, %r732;
	add.s32 	%r830, %r829, %r826;
	add.s32 	%r831, %r830, %r823;
	add.s32 	%r832, %r831, %r743;
	shf.l.wrap.b32 	%r833, %r818, %r818, 30;
	shf.l.wrap.b32 	%r834, %r818, %r818, 19;
	xor.b32  	%r835, %r833, %r834;
	shf.l.wrap.b32 	%r836, %r818, %r818, 10;
	xor.b32  	%r837, %r835, %r836;
	and.b32  	%r838, %r818, %r793;
	xor.b32  	%r839, %r818, %r793;
	and.b32  	%r840, %r839, %r768;
	or.b32  	%r841, %r840, %r838;
	add.s32 	%r842, %r837, %r841;
	add.s32 	%r843, %r842, %r831;
	shf.l.wrap.b32 	%r844, %r832, %r832, 26;
	shf.l.wrap.b32 	%r845, %r832, %r832, 21;
	xor.b32  	%r846, %r844, %r845;
	shf.l.wrap.b32 	%r847, %r832, %r832, 7;
	xor.b32  	%r848, %r846, %r847;
	xor.b32  	%r849, %r807, %r782;
	and.b32  	%r850, %r832, %r849;
	xor.b32  	%r851, %r850, %r782;
	ld.const.u32 	%r852, [%rd14+96];
	add.s32 	%r853, %r852, %r1073;
	add.s32 	%r854, %r853, %r757;
	add.s32 	%r855, %r854, %r851;
	add.s32 	%r856, %r855, %r848;
	add.s32 	%r857, %r856, %r768;
	shf.l.wrap.b32 	%r858, %r843, %r843, 30;
	shf.l.wrap.b32 	%r859, %r843, %r843, 19;
	xor.b32  	%r860, %r858, %r859;
	shf.l.wrap.b32 	%r861, %r843, %r843, 10;
	xor.b32  	%r862, %r860, %r861;
	and.b32  	%r863, %r843, %r818;
	xor.b32  	%r864, %r843, %r818;
	and.b32  	%r865, %r864, %r793;
	or.b32  	%r866, %r865, %r863;
	add.s32 	%r867, %r862, %r866;
	add.s32 	%r868, %r867, %r856;
	shf.l.wrap.b32 	%r869, %r857, %r857, 26;
	shf.l.wrap.b32 	%r870, %r857, %r857, 21;
	xor.b32  	%r871, %r869, %r870;
	shf.l.wrap.b32 	%r872, %r857, %r857, 7;
	xor.b32  	%r873, %r871, %r872;
	xor.b32  	%r874, %r832, %r807;
	and.b32  	%r875, %r857, %r874;
	xor.b32  	%r876, %r875, %r807;
	ld.const.u32 	%r877, [%rd14+100];
	add.s32 	%r878, %r877, %r1074;
	add.s32 	%r879, %r878, %r782;
	add.s32 	%r880, %r879, %r876;
	add.s32 	%r881, %r880, %r873;
	add.s32 	%r882, %r881, %r793;
	shf.l.wrap.b32 	%r883, %r868, %r868, 30;
	shf.l.wrap.b32 	%r884, %r868, %r868, 19;
	xor.b32  	%r885, %r883, %r884;
	shf.l.wrap.b32 	%r886, %r868, %r868, 10;
	xor.b32  	%r887, %r885, %r886;
	and.b32  	%r888, %r868, %r843;
	xor.b32  	%r889, %r868, %r843;
	and.b32  	%r890, %r889, %r818;
	or.b32  	%r891, %r890, %r888;
	add.s32 	%r892, %r887, %r891;
	add.s32 	%r893, %r892, %r881;
	shf.l.wrap.b32 	%r894, %r882, %r882, 26;
	shf.l.wrap.b32 	%r895, %r882, %r882, 21;
	xor.b32  	%r896, %r894, %r895;
	shf.l.wrap.b32 	%r897, %r882, %r882, 7;
	xor.b32  	%r898, %r896, %r897;
	xor.b32  	%r899, %r857, %r832;
	and.b32  	%r900, %r882, %r899;
	xor.b32  	%r901, %r900, %r832;
	ld.const.u32 	%r902, [%rd14+104];
	add.s32 	%r903, %r902, %r1075;
	add.s32 	%r904, %r903, %r807;
	add.s32 	%r905, %r904, %r901;
	add.s32 	%r906, %r905, %r898;
	add.s32 	%r907, %r906, %r818;
	shf.l.wrap.b32 	%r908, %r893, %r893, 30;
	shf.l.wrap.b32 	%r909, %r893, %r893, 19;
	xor.b32  	%r910, %r908, %r909;
	shf.l.wrap.b32 	%r911, %r893, %r893, 10;
	xor.b32  	%r912, %r910, %r911;
	and.b32  	%r913, %r893, %r868;
	xor.b32  	%r914, %r893, %r868;
	and.b32  	%r915, %r914, %r843;
	or.b32  	%r916, %r915, %r913;
	add.s32 	%r917, %r912, %r916;
	add.s32 	%r918, %r917, %r906;
	shf.l.wrap.b32 	%r919, %r907, %r907, 26;
	shf.l.wrap.b32 	%r920, %r907, %r907, 21;
	xor.b32  	%r921, %r919, %r920;
	shf.l.wrap.b32 	%r922, %r907, %r907, 7;
	xor.b32  	%r923, %r921, %r922;
	xor.b32  	%r924, %r882, %r857;
	and.b32  	%r925, %r907, %r924;
	xor.b32  	%r926, %r925, %r857;
	ld.const.u32 	%r927, [%rd14+108];
	add.s32 	%r928, %r927, %r1076;
	add.s32 	%r929, %r928, %r832;
	add.s32 	%r930, %r929, %r926;
	add.s32 	%r931, %r930, %r923;
	add.s32 	%r932, %r931, %r843;
	shf.l.wrap.b32 	%r933, %r918, %r918, 30;
	shf.l.wrap.b32 	%r934, %r918, %r918, 19;
	xor.b32  	%r935, %r933, %r934;
	shf.l.wrap.b32 	%r936, %r918, %r918, 10;
	xor.b32  	%r937, %r935, %r936;
	and.b32  	%r938, %r918, %r893;
	xor.b32  	%r939, %r918, %r893;
	and.b32  	%r940, %r939, %r868;
	or.b32  	%r941, %r940, %r938;
	add.s32 	%r942, %r937, %r941;
	add.s32 	%r943, %r942, %r931;
	shf.l.wrap.b32 	%r944, %r932, %r932, 26;
	shf.l.wrap.b32 	%r945, %r932, %r932, 21;
	xor.b32  	%r946, %r944, %r945;
	shf.l.wrap.b32 	%r947, %r932, %r932, 7;
	xor.b32  	%r948, %r946, %r947;
	xor.b32  	%r949, %r907, %r882;
	and.b32  	%r950, %r932, %r949;
	xor.b32  	%r951, %r950, %r882;
	ld.const.u32 	%r952, [%rd14+112];
	add.s32 	%r953, %r952, %r1056;
	add.s32 	%r954, %r953, %r857;
	add.s32 	%r955, %r954, %r951;
	add.s32 	%r956, %r955, %r948;
	add.s32 	%r1064, %r956, %r868;
	shf.l.wrap.b32 	%r957, %r943, %r943, 30;
	shf.l.wrap.b32 	%r958, %r943, %r943, 19;
	xor.b32  	%r959, %r957, %r958;
	shf.l.wrap.b32 	%r960, %r943, %r943, 10;
	xor.b32  	%r961, %r959, %r960;
	and.b32  	%r962, %r943, %r918;
	xor.b32  	%r963, %r943, %r918;
	and.b32  	%r964, %r963, %r893;
	or.b32  	%r965, %r964, %r962;
	add.s32 	%r966, %r961, %r965;
	add.s32 	%r1060, %r966, %r956;
	shf.l.wrap.b32 	%r967, %r1064, %r1064, 26;
	shf.l.wrap.b32 	%r968, %r1064, %r1064, 21;
	xor.b32  	%r969, %r967, %r968;
	shf.l.wrap.b32 	%r970, %r1064, %r1064, 7;
	xor.b32  	%r971, %r969, %r970;
	xor.b32  	%r972, %r932, %r907;
	and.b32  	%r973, %r1064, %r972;
	xor.b32  	%r974, %r973, %r907;
	ld.const.u32 	%r975, [%rd14+116];
	add.s32 	%r976, %r975, %r1055;
	add.s32 	%r977, %r976, %r882;
	add.s32 	%r978, %r977, %r974;
	add.s32 	%r979, %r978, %r971;
	add.s32 	%r1063, %r979, %r893;
	shf.l.wrap.b32 	%r980, %r1060, %r1060, 30;
	shf.l.wrap.b32 	%r981, %r1060, %r1060, 19;
	xor.b32  	%r982, %r980, %r981;
	shf.l.wrap.b32 	%r983, %r1060, %r1060, 10;
	xor.b32  	%r984, %r982, %r983;
	and.b32  	%r985, %r1060, %r943;
	xor.b32  	%r986, %r1060, %r943;
	and.b32  	%r987, %r986, %r918;
	or.b32  	%r988, %r987, %r985;
	add.s32 	%r989, %r984, %r988;
	add.s32 	%r1059, %r989, %r979;
	shf.l.wrap.b32 	%r990, %r1063, %r1063, 26;
	shf.l.wrap.b32 	%r991, %r1063, %r1063, 21;
	xor.b32  	%r992, %r990, %r991;
	shf.l.wrap.b32 	%r993, %r1063, %r1063, 7;
	xor.b32  	%r994, %r992, %r993;
	xor.b32  	%r995, %r1064, %r932;
	and.b32  	%r996, %r1063, %r995;
	xor.b32  	%r997, %r996, %r932;
	ld.const.u32 	%r998, [%rd14+120];
	add.s32 	%r999, %r998, %r1054;
	add.s32 	%r1000, %r999, %r907;
	add.s32 	%r1001, %r1000, %r997;
	add.s32 	%r1002, %r1001, %r994;
	add.s32 	%r1062, %r1002, %r918;
	shf.l.wrap.b32 	%r1003, %r1059, %r1059, 30;
	shf.l.wrap.b32 	%r1004, %r1059, %r1059, 19;
	xor.b32  	%r1005, %r1003, %r1004;
	shf.l.wrap.b32 	%r1006, %r1059, %r1059, 10;
	xor.b32  	%r1007, %r1005, %r1006;
	and.b32  	%r1008, %r1059, %r1060;
	xor.b32  	%r1009, %r1059, %r1060;
	and.b32  	%r1010, %r1009, %r943;
	or.b32  	%r1011, %r1010, %r1008;
	add.s32 	%r1012, %r1007, %r1011;
	add.s32 	%r1058, %r1012, %r1002;
	shf.l.wrap.b32 	%r1013, %r1062, %r1062, 26;
	shf.l.wrap.b32 	%r1014, %r1062, %r1062, 21;
	xor.b32  	%r1015, %r1013, %r1014;
	shf.l.wrap.b32 	%r1016, %r1062, %r1062, 7;
	xor.b32  	%r1017, %r1015, %r1016;
	xor.b32  	%r1018, %r1063, %r1064;
	and.b32  	%r1019, %r1062, %r1018;
	xor.b32  	%r1020, %r1019, %r1064;
	ld.const.u32 	%r1021, [%rd14+124];
	add.s32 	%r1022, %r1021, %r1053;
	add.s32 	%r1023, %r1022, %r932;
	add.s32 	%r1024, %r1023, %r1020;
	add.s32 	%r1025, %r1024, %r1017;
	add.s32 	%r1061, %r1025, %r943;
	shf.l.wrap.b32 	%r1026, %r1058, %r1058, 30;
	shf.l.wrap.b32 	%r1027, %r1058, %r1058, 19;
	xor.b32  	%r1028, %r1026, %r1027;
	shf.l.wrap.b32 	%r1029, %r1058, %r1058, 10;
	xor.b32  	%r1030, %r1028, %r1029;
	and.b32  	%r1031, %r1058, %r1059;
	xor.b32  	%r1032, %r1058, %r1059;
	and.b32  	%r1033, %r1032, %r1060;
	or.b32  	%r1034, %r1033, %r1031;
	add.s32 	%r1035, %r1030, %r1034;
	add.s32 	%r1057, %r1035, %r1025;
	add.s32 	%r1052, %r1052, 16;
	setp.lt.u32 	%p2, %r1052, 64;
	mov.u64 	%rd14, %rd3;
	@%p2 bra 	$L__BB2_2;

	ld.param.u64 	%rd13, [m11600_hook23_param_5];
	add.s32 	%r1037, %r1057, %r7;
	// begin inline asm
	prmt.b32 %r1036, %r1037, 0, 0x0123;
	// end inline asm
	mul.lo.s64 	%rd11, %rd1, 36;
	add.s64 	%rd12, %rd13, %rd11;
	st.global.u32 	[%rd12], %r1036;
	add.s32 	%r1039, %r1058, %r8;
	// begin inline asm
	prmt.b32 %r1038, %r1039, 0, 0x0123;
	// end inline asm
	st.global.u32 	[%rd12+4], %r1038;
	add.s32 	%r1041, %r1059, %r9;
	// begin inline asm
	prmt.b32 %r1040, %r1041, 0, 0x0123;
	// end inline asm
	st.global.u32 	[%rd12+8], %r1040;
	add.s32 	%r1043, %r1060, %r6;
	// begin inline asm
	prmt.b32 %r1042, %r1043, 0, 0x0123;
	// end inline asm
	st.global.u32 	[%rd12+12], %r1042;
	add.s32 	%r1045, %r1061, %r2;
	// begin inline asm
	prmt.b32 %r1044, %r1045, 0, 0x0123;
	// end inline asm
	st.global.u32 	[%rd12+16], %r1044;
	add.s32 	%r1047, %r1062, %r4;
	// begin inline asm
	prmt.b32 %r1046, %r1047, 0, 0x0123;
	// end inline asm
	st.global.u32 	[%rd12+20], %r1046;
	add.s32 	%r1049, %r1063, %r3;
	// begin inline asm
	prmt.b32 %r1048, %r1049, 0, 0x0123;
	// end inline asm
	st.global.u32 	[%rd12+24], %r1048;
	add.s32 	%r1051, %r1064, %r5;
	// begin inline asm
	prmt.b32 %r1050, %r1051, 0, 0x0123;
	// end inline asm
	st.global.u32 	[%rd12+28], %r1050;

$L__BB2_4:
	ret;

}
	// .globl	m11600_comp
.entry m11600_comp(
	.param .u64 .ptr .global .align 4 m11600_comp_param_0,
	.param .u64 .ptr .global .align 4 m11600_comp_param_1,
	.param .u64 .ptr .global .align 4 m11600_comp_param_2,
	.param .u64 .ptr .const .align 4 m11600_comp_param_3,
	.param .u64 .ptr .global .align 4 m11600_comp_param_4,
	.param .u64 .ptr .global .align 4 m11600_comp_param_5,
	.param .u64 .ptr .global .align 4 m11600_comp_param_6,
	.param .u64 .ptr .global .align 4 m11600_comp_param_7,
	.param .u64 .ptr .global .align 4 m11600_comp_param_8,
	.param .u64 .ptr .global .align 4 m11600_comp_param_9,
	.param .u64 .ptr .global .align 4 m11600_comp_param_10,
	.param .u64 .ptr .global .align 4 m11600_comp_param_11,
	.param .u64 .ptr .global .align 4 m11600_comp_param_12,
	.param .u64 .ptr .global .align 4 m11600_comp_param_13,
	.param .u64 .ptr .global .align 8 m11600_comp_param_14,
	.param .u64 .ptr .global .align 4 m11600_comp_param_15,
	.param .u64 .ptr .global .align 4 m11600_comp_param_16,
	.param .u64 .ptr .global .align 4 m11600_comp_param_17,
	.param .u64 .ptr .global .align 1 m11600_comp_param_18,
	.param .u64 .ptr .global .align 4 m11600_comp_param_19,
	.param .u64 .ptr .global .align 1 m11600_comp_param_20,
	.param .u64 .ptr .global .align 1 m11600_comp_param_21,
	.param .u64 .ptr .global .align 1 m11600_comp_param_22,
	.param .u64 .ptr .global .align 1 m11600_comp_param_23,
	.param .u64 .ptr .global .align 8 m11600_comp_param_24
)
{
	.local .align 4 .b8 	__local_depot3[12];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<5>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<21>;


	mov.u64 	%SPL, __local_depot3;
	ld.param.u64 	%rd3, [m11600_comp_param_5];
	ld.param.u64 	%rd4, [m11600_comp_param_14];
	ld.param.u64 	%rd5, [m11600_comp_param_16];
	ld.param.u64 	%rd6, [m11600_comp_param_19];
	ld.param.u64 	%rd7, [m11600_comp_param_24];
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %tid.x;
	mov.b32 	%r7, %envreg3;
	add.s32 	%r8, %r6, %r7;
	mad.lo.s32 	%r9, %r5, %r4, %r8;
	cvt.s64.s32 	%rd1, %r9;
	add.s64 	%rd2, %rd7, 56;
	ld.global.u64 	%rd8, [%rd7+56];
	setp.le.u64 	%p1, %rd8, %rd1;
	@%p1 bra 	$L__BB3_6;

	mul.lo.s64 	%rd9, %rd1, 36;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.u32 	%r10, [%rd10+32];
	setp.ne.s32 	%p2, %r10, 1;
	@%p2 bra 	$L__BB3_6;

	add.u64 	%rd12, %SPL, 8;
	ld.global.u32 	%r11, [%rd2+-24];
	mul.wide.u32 	%rd13, %r11, 4;
	add.s64 	%rd14, %rd5, %rd13;
	mov.u32 	%r12, 1;
	st.local.u32 	[%rd12], %r12;
	ld.local.u32 	%r13, [%rd12];
	atom.global.add.u32 	%r14, [%rd14], %r13;
	setp.ne.s32 	%p3, %r14, 0;
	@%p3 bra 	$L__BB3_6;

	add.u64 	%rd16, %SPL, 4;
	ld.global.u32 	%r1, [%rd2+-44];
	ld.global.u32 	%r15, [%rd2+-28];
	ld.global.u32 	%r2, [%rd2+-24];
	st.local.u32 	[%rd16], %r12;
	ld.local.u32 	%r17, [%rd16];
	atom.global.add.u32 	%r3, [%rd6], %r17;
	setp.lt.u32 	%p4, %r3, %r15;
	@%p4 bra 	$L__BB3_5;
	bra.uni 	$L__BB3_4;

$L__BB3_5:
	mul.wide.u32 	%rd19, %r3, 32;
	mov.u32 	%r22, 0;
	add.s64 	%rd20, %rd4, %rd19;
	st.global.v2.u32 	[%rd20+16], {%r22, %r2};
	st.global.u64 	[%rd20], %rd1;
	st.global.v2.u32 	[%rd20+8], {%r22, %r1};
	st.global.v2.u32 	[%rd20+24], {%r22, %r22};
	bra.uni 	$L__BB3_6;

$L__BB3_4:
	add.u64 	%rd18, %SPL, 0;
	mov.u32 	%r18, 1;
	st.local.u32 	[%rd18], %r18;
	ld.local.u32 	%r19, [%rd18];
	neg.s32 	%r20, %r19;
	atom.global.add.u32 	%r21, [%rd6], %r20;

$L__BB3_6:
	ret;

}

  